{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiameseMitLASER",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "jTXpYPem32iM",
        "c3fiA2utZEjH",
        "Rd3drVZISrtq",
        "FVwr0z3eW_iT",
        "koat_Nz1Op49",
        "Yy6Nq9ZnlJPc"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmay5/NLP-Praktikum/blob/sentence_embedding/SiameseMitLASER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sScywYm8EJhe",
        "colab_type": "code",
        "outputId": "96a7fff6-3d4b-40a2-fe3b-ae7c422074e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wUDuuzC3knQ",
        "colab_type": "text"
      },
      "source": [
        "# This is an attempt to include the LASER multi lingual embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mngRKDEg3x2h",
        "colab_type": "code",
        "outputId": "869301b3-4160-48d1-c6b0-1f86943ff6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!git clone https://github.com/ceshine/LASER.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LASER'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 591 (delta 11), reused 24 (delta 11), pack-reused 560\u001b[K\n",
            "Receiving objects: 100% (591/591), 2.60 MiB | 2.82 MiB/s, done.\n",
            "Resolving deltas: 100% (175/175), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_8LAr8c6Wyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -rf \\\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Akm1QeP4lea",
        "colab_type": "code",
        "outputId": "4b900132-38ea-42f1-c063-4149f7169a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%env LASER=/content/LASER\n",
        "!echo $LASER\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: LASER=/content/LASER\n",
            "/content/LASER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo67QGwc7m7F",
        "colab_type": "code",
        "outputId": "ea14d79a-da6f-4a4f-f28d-d6698d66d402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxeDCC74lhZ",
        "colab_type": "code",
        "outputId": "6daddc1c-76b4-4a3f-b968-693701fdcaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd LASER"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjFh5jFf4lmg",
        "colab_type": "code",
        "outputId": "68c7873b-8297-4bfd-df9d-45a334a31274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ADRwFZ4lp8",
        "colab_type": "code",
        "outputId": "650d41ae-7849-4624-ff7c-97e9d8c431c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!bash install_models.sh"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading networks\n",
            " - creating directory /content/LASER/models\n",
            " - bilstm.93langs.2018-12-26.pt\n",
            " - 93langs.fcodes\n",
            " - 93langs.fvocab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5F_sNpe4lkm",
        "colab_type": "code",
        "outputId": "e4981d58-8279-4a6a-f600-14f4c6dec09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2221
        }
      },
      "source": [
        "!bash install_external_tools.sh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing external tools\n",
            " - creating directory /content/LASER/tools-external/moses-tokenizer/tokenizer\n",
            " - download tokenizer/tokenizer.perl\n",
            " - download tokenizer/detokenizer.perl\n",
            " - download tokenizer/normalize-punctuation.perl\n",
            " - download tokenizer/remove-non-printing-char.perl\n",
            " - download tokenizer/deescape-special-chars.perl\n",
            " - download tokenizer/lowercase.perl\n",
            " - download tokenizer/basic-protected-patterns\n",
            " - creating directory /content/LASER/tools-external/moses-tokenizer/share/nonbreaking_prefixes\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ca\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.cs\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.de\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.el\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.en\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.es\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.fi\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.fr\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ga\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.hu\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.is\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.it\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.lt\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.lv\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.nl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.pl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.pt\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ro\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ru\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sk\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sv\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ta\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.yue\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.zh\n",
            " - download fastBPE software from github\n",
            "--2019-06-21 08:01:54--  https://github.com/glample/fastBPE/archive/master.zip\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/glample/fastBPE/zip/master [following]\n",
            "--2019-06-21 08:01:55--  https://codeload.github.com/glample/fastBPE/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.253.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.253.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [ <=>                ]   8.88K  47.9KB/s    in 0.2s    \n",
            "\n",
            "2019-06-21 08:01:56 (47.9 KB/s) - ‘master.zip’ saved [9093]\n",
            "\n",
            "Archive:  master.zip\n",
            "874634b2676d091ced2aa5a2f5917c7106735fa8\n",
            "   creating: fastBPE-master/\n",
            "  inflating: fastBPE-master/LICENSE  \n",
            "  inflating: fastBPE-master/README.md  \n",
            "   creating: fastBPE-master/fastBPE/\n",
            "  inflating: fastBPE-master/fastBPE/fastBPE.hpp  \n",
            "  inflating: fastBPE-master/fastBPE/fastBPE.pyx  \n",
            "  inflating: fastBPE-master/fastBPE/main.cc  \n",
            "  inflating: fastBPE-master/setup.py  \n",
            " - compiling\n",
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "Compiling fastBPE/fastBPE.pyx because it changed.\n",
            "[1/1] Cythonizing fastBPE/fastBPE.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/LASER/tools-external/fastBPE/fastBPE/fastBPE.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating fastBPE.egg-info\n",
            "writing fastBPE.egg-info/PKG-INFO\n",
            "writing dependency_links to fastBPE.egg-info/dependency_links.txt\n",
            "writing requirements to fastBPE.egg-info/requires.txt\n",
            "writing top-level names to fastBPE.egg-info/top_level.txt\n",
            "writing manifest file 'fastBPE.egg-info/SOURCES.txt'\n",
            "package init file 'fastBPE/__init__.py' not found (or not a regular file)\n",
            "reading manifest file 'fastBPE.egg-info/SOURCES.txt'\n",
            "writing manifest file 'fastBPE.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "running build_ext\n",
            "building 'fastBPE' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/fastBPE\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -IfastBPE -I/usr/include/python3.6m -c fastBPE/fastBPE.cpp -o build/temp.linux-x86_64-3.6/fastBPE/fastBPE.o -std=c++11 -Ofast -pthread\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fastBPE/fastBPE.o -o build/lib.linux-x86_64-3.6/fastBPE.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/fastBPE.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for fastBPE.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fastBPE.py to fastBPE.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fastBPE.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.fastBPE.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/fastBPE-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing fastBPE-0.0.0-py3.6-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/fastBPE-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting fastBPE-0.0.0-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding fastBPE 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/fastBPE-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for fastBPE==0.0.0\n",
            "Searching for Cython==0.29.10\n",
            "Best match: Cython 0.29.10\n",
            "Adding Cython 0.29.10 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for fastBPE==0.0.0\n",
            "\n",
            "automatic installation of the Japanese tokenizer mecab may be tricky\n",
            "Please install it manually from https://github.com/taku910/mecab\n",
            "\n",
            "The installation directory should be /content/LASER/tools-external/mecab\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq9RVwqi8pyM",
        "colab_type": "code",
        "outputId": "887435c3-e98e-49d8-e3c9-62fccf282636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%cd /content/LASER\n",
        "%cd tools-external/fastBPE/\n",
        "! g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER\n",
            "/content/LASER/tools-external/fastBPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpraUBs38jZO",
        "colab_type": "code",
        "outputId": "ed4decca-6850-4cb5-f85b-82a843906fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%cd ../../tasks/similarity/\n",
        "! ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER/tasks/similarity\n",
            "README.md  wmt.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVjP99krE02v",
        "colab_type": "code",
        "outputId": "aad707e3-2387-4fa4-e8b9-53f41972fcb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "! apt install libopenblas-base libomp-dev"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-base is already the newest version (0.2.20+ds-4).\n",
            "libopenblas-base set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 2s (112 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 130942 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdgEtRK5AN9g",
        "colab_type": "code",
        "outputId": "d0ab1763-6b8f-4ec5-e300-d6a93eb59034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "! pip install faiss"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faiss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/1c/4ae6cb87cf0c09c25561ea48db11e25713b25c580909902a92c090b377c0/faiss-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from faiss) (1.16.4)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBPIo9wj9GSg",
        "colab_type": "code",
        "outputId": "64e0edb7-f906-4096-d77b-f312b961e8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "% cd /content/LASER/tasks/similarity\n",
        "! bash wmt.sh"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: './tasks/similarity'\n",
            "/content/LASER/tasks/similarity\n",
            " - Download WMT data\n",
            "LASER: similarity search\n",
            "\n",
            "Processing:\n",
            " - loading encoder /content/LASER/models/bilstm.93langs.2018-12-26.pt\n",
            " - transfer encoder to GPU\n",
            " - creating directory embed\n",
            " - Tokenizer: newstest2012.cs in language cs  \n",
            " - fast BPE: processing newstest2012.tok.cs\n",
            " - Encoder: newstest2012.bpe.cs to newstest2012.enc.cs\n",
            " - Encoder: 3003 sentences in 5s\n",
            " - embedding: ./embed/newstest2012.enc.cs 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            " - Tokenizer: newstest2012.de in language de  \n",
            " - fast BPE: processing newstest2012.tok.de\n",
            " - Encoder: newstest2012.bpe.de to newstest2012.enc.de\n",
            " - Encoder: 3003 sentences in 5s\n",
            " - embedding: ./embed/newstest2012.enc.de 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            " - Tokenizer: newstest2012.en in language en  \n",
            " - fast BPE: processing newstest2012.tok.en\n",
            " - Encoder: newstest2012.bpe.en to newstest2012.enc.en\n",
            " - Encoder: 3003 sentences in 4s\n",
            " - embedding: ./embed/newstest2012.enc.en 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            " - Tokenizer: newstest2012.es in language es  \n",
            " - fast BPE: processing newstest2012.tok.es\n",
            " - Encoder: newstest2012.bpe.es to newstest2012.enc.es\n",
            " - Encoder: 3003 sentences in 5s\n",
            " - embedding: ./embed/newstest2012.enc.es 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            " - Tokenizer: newstest2012.fr in language fr  \n",
            " - fast BPE: processing newstest2012.tok.fr\n",
            " - Encoder: newstest2012.bpe.fr to newstest2012.enc.fr\n",
            " - Encoder: 3003 sentences in 5s\n",
            " - embedding: ./embed/newstest2012.enc.fr 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            "Confusion matrix:\n",
            "langs   cs       de       en       es       fr       avg     \n",
            "cs     0.00%    0.70%    0.90%    0.67%    0.77%    0.76%\n",
            "de     0.83%    0.00%    1.17%    0.93%    1.03%    0.99%\n",
            "en     0.93%    1.27%    0.00%    0.83%    1.07%    1.02%\n",
            "es     0.53%    0.77%    0.97%    0.00%    0.57%    0.71%\n",
            "fr     0.50%    0.90%    1.13%    0.60%    0.00%    0.78%\n",
            "avg    0.70%    0.91%    1.04%    0.76%    0.86%    0.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sS0FP2kG-cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample feasibility check\n",
        "# % cd ../../source/\n",
        "\n",
        "import os\n",
        "import sys\n",
        "LASER = os.environ['LASER']\n",
        "# now include the extra files in the source\n",
        "sys.path.append(LASER + '/source')\n",
        "sys.path.append(LASER + '/source/lib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39VFH-l3G-l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from embed import SentenceEncoder, EncodeLoad, EncodeFile\n",
        "from text_processing import Token, BPEfastApply\n",
        "from indexing import IndexCreate, IndexSearchMultiple, IndexPrintConfusionMatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKRw4tSWb1jW",
        "colab_type": "text"
      },
      "source": [
        "## These are the steps to replicate results of the LSTM file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3ZY3F5ZbCwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = '/content/LASER/models/'\n",
        "sentence_encoder = SentenceEncoder(\n",
        "    str(MODEL_PATH + \"bilstm.93langs.2018-12-26.pt\"),\n",
        "    max_sentences=None,\n",
        "    max_tokens=10000,\n",
        "    cpu=False)\n",
        "sentence_encoder.use_cuda=True #just a guess not sure if this would actually help"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-J64A0YqMvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary for label to index, this has been pre-generated\n",
        "encoding_to_labels = {\n",
        "   0:\t\"Amazon Instant Videos\",\n",
        "   1 :\"Android Apps\",\n",
        "   2 : \"Automotive\",\n",
        "   3 :\"Baby\",\n",
        "   4 :\"Beauty\",\n",
        "   5 :\"CDs and Vinyl\",\n",
        "   6 :\"Cell Phones and Accessories\",\n",
        "   7 :\"Clothing, Shoes, Jewelry\",\n",
        "   8 :\"Digital Music\",\n",
        "   9 :\"Electronics\",\n",
        "  10 :\"Grocery and Gourmet\",\n",
        "  11 :\"Health and Personal Care\",\n",
        "  12 :\"Home and Kitchen\",\n",
        "  13 :\"Kindle\",\n",
        "  14 :\"Movies and TV\",\n",
        "  15 :\"Musical Instruments\",\n",
        "  16 :\"Office Products\",\n",
        "  17 :\"Patio Garden\",\n",
        "  18 :\"Pet Supplies\",\n",
        "  19 :\"Sports, Outdoors\",\n",
        "  20 :\"Tool and Home Improvement\",\n",
        "  21 :\"Toys_and_Games\",\n",
        "  22 :\"Video Games\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-JUCiTYsRWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lebel_from_code(code):\n",
        "  if code not in encoding_to_labels.keys():\n",
        "    raise KeyError(\"Invalid Code\")\n",
        "  return encoding_to_labels[code]\n",
        "\n",
        "def get_all_labels():\n",
        "  return list(encoding_to_labels.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBYzPcejcJnC",
        "colab_type": "text"
      },
      "source": [
        "# This is the code section for trying Triplet Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP-YgYTWcQWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class TripletDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, select_column, training_mode=True):\n",
        "         \n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.train = training_mode\n",
        "        self.select_column = select_column\n",
        "        if self.train:\n",
        "            self.train_labels = self.dataset.labels_encoded\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "            self.dataset = self.dataset.drop('labels_encoded', axis=1)\n",
        "            self.train_data = self.dataset\n",
        "            self.labels_set = set(self.train_labels.to_numpy())\n",
        "            self.label_to_indices = {label: np.where(self.train_labels.to_numpy() == label)[0]\n",
        "                                     for label in self.labels_set} # redundent in our case if we decide to use numeric labels based on certain sklearn packages\n",
        "\n",
        "        else:\n",
        "            self.test_labels = self.dataset.labels_encoded\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "            self.dataset = self.dataset.drop('labels_encoded', axis=1)\n",
        "            self.test_data = self.dataset\n",
        "            # generate fixed triplets for testing\n",
        "            self.labels_set = set(self.test_labels.to_numpy())\n",
        "            self.label_to_indices = {label: np.where(self.test_labels.to_numpy() == label)[0]\n",
        "                                     for label in self.labels_set}\n",
        "\n",
        "            random_state = np.random.RandomState(42)\n",
        "            \n",
        "            #print(\"Length of the dataset is {}\".format(len(self.test_data)))\n",
        "            \n",
        "            triplets = []\n",
        "            for i in range(len(self.test_data)):\n",
        "                  triplets.append([i,\n",
        "                           random_state.choice(self.label_to_indices[self.test_labels.iloc[i]]),\n",
        "                           random_state.choice(self.label_to_indices[\n",
        "                                                 np.random.choice(\n",
        "                                                     list(self.labels_set - set([self.test_labels.iloc[i]]))\n",
        "                                                 )\n",
        "                                             ])\n",
        "                         ]) \n",
        "                         \n",
        "            self.test_triplets = triplets\n",
        "           \n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            #print(type(self.train_data))\n",
        "            img1, label1 = self.train_data.iloc[index], self.train_labels.iloc[index]\n",
        "            positive_index = index\n",
        "            while positive_index == index:\n",
        "                positive_index = np.random.choice(self.label_to_indices[label1])\n",
        "            negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
        "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
        "            img2 = self.train_data.iloc[positive_index]\n",
        "            img3 = self.train_data.iloc[negative_index]\n",
        "        else:\n",
        "            img1 = self.test_data.iloc[self.test_triplets[index][0]]\n",
        "            img2 = self.test_data.iloc[self.test_triplets[index][1]]\n",
        "            img3 = self.test_data.iloc[self.test_triplets[index][2]]\n",
        "\n",
        "        img1 = img1[self.select_column]\n",
        "        img2 = img2[self.select_column]\n",
        "        img3 = img3[self.select_column]\n",
        "        \n",
        "        #print(\"Computation of the entities are completed\")\n",
        "\n",
        "        return (img1, img2, img3)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXpYPem32iM",
        "colab_type": "text"
      },
      "source": [
        "## Load the entire dataset in this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzVaHR7VcQlH",
        "colab_type": "code",
        "outputId": "d6609ea4-7a03-40eb-842d-60d4a8e3c821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "import pandas as pd\n",
        "%cd /content/\n",
        "input_data = pd.read_csv('actual_dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-558fcc71a521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actual_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'actual_dataset.csv' does not exist: b'actual_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ9OuN6fnEjE",
        "colab_type": "code",
        "outputId": "ab21dc29-41e6-45ed-c982-824f9ab125f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "input_data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
              "       'overall', 'summary', 'unixReviewTime', 'reviewTime',\n",
              "       'Product_Category'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImQg2ouIupGA",
        "colab_type": "code",
        "outputId": "30795c59-d967-4af0-c829-731b60a2ed08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>Product_Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1VXOAVRGKGEAK</td>\n",
              "      <td>439893577</td>\n",
              "      <td>Angie</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I like the item pricing. My granddaughter want...</td>\n",
              "      <td>5</td>\n",
              "      <td>Magnetic board</td>\n",
              "      <td>1390953600</td>\n",
              "      <td>01 29, 2014</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A8R62G708TSCM</td>\n",
              "      <td>439893577</td>\n",
              "      <td>Candace</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>Love the magnet easel... great for moving to d...</td>\n",
              "      <td>4</td>\n",
              "      <td>it works pretty good for moving to different a...</td>\n",
              "      <td>1395964800</td>\n",
              "      <td>03 28, 2014</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A21KH420DK0ICA</td>\n",
              "      <td>439893577</td>\n",
              "      <td>capemaychristy</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>Both sides are magnetic.  A real plus when you...</td>\n",
              "      <td>5</td>\n",
              "      <td>love this!</td>\n",
              "      <td>1359331200</td>\n",
              "      <td>01 28, 2013</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AR29QK6HPFYZ4</td>\n",
              "      <td>439893577</td>\n",
              "      <td>dcrm</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Bought one a few years ago for my daughter and...</td>\n",
              "      <td>5</td>\n",
              "      <td>Daughters love it</td>\n",
              "      <td>1391817600</td>\n",
              "      <td>02 8, 2014</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACCH8EOML6FN5</td>\n",
              "      <td>439893577</td>\n",
              "      <td>DoyZ</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>I have a stainless steel refrigerator therefor...</td>\n",
              "      <td>4</td>\n",
              "      <td>Great to have so he can play with his alphabet...</td>\n",
              "      <td>1399248000</td>\n",
              "      <td>05 5, 2014</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID       asin  ...   reviewTime Product_Category\n",
              "0  A1VXOAVRGKGEAK  439893577  ...  01 29, 2014   Toys_and_Games\n",
              "1   A8R62G708TSCM  439893577  ...  03 28, 2014   Toys_and_Games\n",
              "2  A21KH420DK0ICA  439893577  ...  01 28, 2013   Toys_and_Games\n",
              "3   AR29QK6HPFYZ4  439893577  ...   02 8, 2014   Toys_and_Games\n",
              "4   ACCH8EOML6FN5  439893577  ...   05 5, 2014   Toys_and_Games\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY_gevdXu8ZV",
        "colab_type": "text"
      },
      "source": [
        "### We would use review.text as the input and use it to predict review.primaryCategories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfzKSTw5vMvP",
        "colab_type": "code",
        "outputId": "ccfb7d9b-ad22-494c-c224-abf0ae4b4de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "input_data.Product_Category.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       2300\n",
              "unique        23\n",
              "top       Beauty\n",
              "freq         100\n",
              "Name: Product_Category, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbUHtUzLl-T1",
        "colab_type": "code",
        "outputId": "387d7f74-d67b-460a-8664-9e42c5978eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "input_data = input_data.rename(columns={'Product_Category':'label'})\n",
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1VXOAVRGKGEAK</td>\n",
              "      <td>439893577</td>\n",
              "      <td>Angie</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I like the item pricing. My granddaughter want...</td>\n",
              "      <td>5</td>\n",
              "      <td>Magnetic board</td>\n",
              "      <td>1390953600</td>\n",
              "      <td>01 29, 2014</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A8R62G708TSCM</td>\n",
              "      <td>439893577</td>\n",
              "      <td>Candace</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>Love the magnet easel... great for moving to d...</td>\n",
              "      <td>4</td>\n",
              "      <td>it works pretty good for moving to different a...</td>\n",
              "      <td>1395964800</td>\n",
              "      <td>03 28, 2014</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A21KH420DK0ICA</td>\n",
              "      <td>439893577</td>\n",
              "      <td>capemaychristy</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>Both sides are magnetic.  A real plus when you...</td>\n",
              "      <td>5</td>\n",
              "      <td>love this!</td>\n",
              "      <td>1359331200</td>\n",
              "      <td>01 28, 2013</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AR29QK6HPFYZ4</td>\n",
              "      <td>439893577</td>\n",
              "      <td>dcrm</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Bought one a few years ago for my daughter and...</td>\n",
              "      <td>5</td>\n",
              "      <td>Daughters love it</td>\n",
              "      <td>1391817600</td>\n",
              "      <td>02 8, 2014</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACCH8EOML6FN5</td>\n",
              "      <td>439893577</td>\n",
              "      <td>DoyZ</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>I have a stainless steel refrigerator therefor...</td>\n",
              "      <td>4</td>\n",
              "      <td>Great to have so he can play with his alphabet...</td>\n",
              "      <td>1399248000</td>\n",
              "      <td>05 5, 2014</td>\n",
              "      <td>Toys_and_Games</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID       asin  ...   reviewTime           label\n",
              "0  A1VXOAVRGKGEAK  439893577  ...  01 29, 2014  Toys_and_Games\n",
              "1   A8R62G708TSCM  439893577  ...  03 28, 2014  Toys_and_Games\n",
              "2  A21KH420DK0ICA  439893577  ...  01 28, 2013  Toys_and_Games\n",
              "3   AR29QK6HPFYZ4  439893577  ...   02 8, 2014  Toys_and_Games\n",
              "4   ACCH8EOML6FN5  439893577  ...   05 5, 2014  Toys_and_Games\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm6KWbuh95tX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LASER = os.environ['LASER']\n",
        "FASTBPE = LASER + '/tools-external/fastBPE/fast'\n",
        "MOSES_BDIR = LASER + '/tools-external/moses-tokenizer/tokenizer/'\n",
        "MOSES_TOKENIZER = MOSES_BDIR + 'tokenizer.perl -q -no-escape -threads 20 -l '\n",
        "MOSES_LC = MOSES_BDIR + 'lowercase.perl'\n",
        "NORM_PUNC = MOSES_BDIR + 'normalize-punctuation.perl -l '\n",
        "DESCAPE = MOSES_BDIR + 'deescape-special-chars.perl'\n",
        "REM_NON_PRINT_CHAR = MOSES_BDIR + 'remove-non-printing-char.perl'\n",
        "MECAB = LASER + '/tools-external/mecab'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9sXKsW1M9Xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from subprocess import check_output\n",
        "def sample_token(string_val, lang='en'):\n",
        "    tok = check_output(\n",
        "                REM_NON_PRINT_CHAR\n",
        "                + '|' + NORM_PUNC + lang\n",
        "                + '|' + DESCAPE\n",
        "                + '|' + MOSES_TOKENIZER + lang\n",
        "                + ('| python3 -m jieba -d ' if lang == 'zh' else '')\n",
        "                + ('|' + MECAB + '/bin/mecab -O wakati -b 50000 ' if lang == 'ja' else ''),\n",
        "                input=string_val,\n",
        "                encoding='UTF-8',\n",
        "                shell=True)\n",
        "    return tok.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT4TrHkYvT0Q",
        "colab_type": "text"
      },
      "source": [
        "### Clean the data as that might cause problems later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faPNpMFclPpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = input_data.reviewText.isnull()==True\n",
        "samp = index[index==True]\n",
        "input_data = input_data.drop(samp.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KID-p2ZpvZP9",
        "colab_type": "code",
        "outputId": "bcedc556-ba58-4513-af3f-66f8759676ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_data.reviewText.isnull().sum() #Value should be always zero"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmGwWzJZNkwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Do the above mentioned operation on all the entries in the column. So,\n",
        "  \n",
        "\"\"\"\n",
        "input_data['tokenized_review'] = input_data.reviewText.apply(sample_token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPBpVwpGROPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bpe_codes = './LASER/models/93langs.fcodes'\n",
        "bpe_vocab = bpe_codes.replace('fcodes', 'fvocab')\n",
        "\n",
        "\n",
        "def apply_bpe(sentence):\n",
        "  sentence = sentence.replace('\"','\\\\\"')\n",
        "  bpe = check_output(\n",
        "      'echo -n \"'+sentence +'\" | '+ FASTBPE + ' applybpe_stream '+  bpe_codes +' '+bpe_vocab,\n",
        "      encoding='UTF-8',\n",
        "      shell=True)\n",
        "  return bpe.strip()\n",
        "\n",
        "\n",
        "#input_data['tokenized_review_bpe'] = input_data.reviewText.apply(bpe_sentences)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEgQx2HgZml4",
        "colab_type": "code",
        "outputId": "1932ecd5-42ab-4051-8e2f-720ecad8bef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tok_sentence = '\"love the magnet easel ... \" slow motion me \"great for moving to different areas ... wish it had some sort of non skid pad on bottom though ...'\n",
        "apply_bpe(tok_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"@@ love the magn@@ et ea@@ sel ... \" slo@@ w motion me \"@@ great for mo@@ ving to different areas ... wish it had some sort of non sk@@ id pad on bot@@ tom though ...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHVv21bCcIXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data['tokenized_review_bpe'] = input_data.tokenized_review.apply(apply_bpe)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoizC9eVsr7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Let's encode the values in here so that we can use them as label encoder later\n",
        "\"\"\"\n",
        "# import labelencoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# instantiate labelencoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "input_data['labels_encoded'] = le.fit_transform(input_data['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB-DB0WB2_Rk",
        "colab_type": "code",
        "outputId": "03ec20c5-5e83-4d89-b6b8-d0b46cc11737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "\n",
        "input_data.to_csv('./preprocessed_output.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-75160cf52e00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./preprocessed_output.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'input_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3fiA2utZEjH",
        "colab_type": "text"
      },
      "source": [
        "# Reading preprocessed output uptil BPE and then converting it into sentence embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stWEpEY7U_mm",
        "colab_type": "code",
        "outputId": "b935b268-7e39-4097-b82e-2b43d622e3e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Trying to apply the sentence encoding so that we can store the entire thing\n",
        "%cd /content/\n",
        "import pandas as pd\n",
        "input_data = pd.read_csv('./preprocessed_output.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMmedeXLU_kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directly copy pasted from stackoverflow \n",
        "# https://stackoverflow.com/questions/35092720/verbosity-pandas-apply"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0jawvqYKJFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Because of the nature in which LASER tends to perform encoding we have to do this extra tweek\n",
        "def to_list(element):\n",
        "  return [element]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijP0eityf6mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data['tokenized_review_bpe_list'] = input_data.tokenized_review_bpe.apply(to_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohTxzwRU_hK",
        "colab_type": "code",
        "outputId": "d3986bca-c4bc-4f06-8427-2493da371066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from pandas import Series\n",
        "\n",
        "def progress_coroutine(print_on = 10):\n",
        "    print (\"Starting progress monitor\")\n",
        "\n",
        "    iterations = 0\n",
        "    while True:\n",
        "        yield\n",
        "        iterations += 1\n",
        "        if (iterations % print_on == 0):\n",
        "            print (\"{} iterations done\".format(iterations))\n",
        "\n",
        "def percentage_coroutine(to_process, print_on_percent = 0.10):\n",
        "    print (\"Starting progress percentage monitor\")\n",
        "\n",
        "    processed = 0\n",
        "    count = 0\n",
        "    print_count = to_process*print_on_percent\n",
        "    while True:\n",
        "        yield\n",
        "        processed += 1\n",
        "        count += 1\n",
        "        if (count >= print_count):\n",
        "            count = 0\n",
        "            pct = (float(processed)/float(to_process))*100\n",
        "\n",
        "            print (\"{}% finished\".format(pct))\n",
        "\n",
        "def trace_progress(func, progress = None):\n",
        "    def callf(*args, **kwargs):\n",
        "        if (progress is not None):\n",
        "            progress.send(None)\n",
        "\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return callf\n",
        "\n",
        "def my_func(i):\n",
        "    return i ** 2\n",
        "\n",
        "data_series = input_data.tokenized_review_bpe_list\n",
        "#co1 = progress_coroutine()\n",
        "co2 = percentage_coroutine(len(data_series))\n",
        "input_data['sentence_embedding'] = data_series.apply(trace_progress(sentence_encoder.encode_sentences, progress = co2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting progress percentage monitor\n",
            "10.004349717268378% finished\n",
            "20.008699434536755% finished\n",
            "30.01304915180513% finished\n",
            "40.01739886907351% finished\n",
            "50.021748586341886% finished\n",
            "60.02609830361026% finished\n",
            "70.03044802087864% finished\n",
            "80.03479773814702% finished\n",
            "90.0391474554154% finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Vw0OaCgf6w",
        "colab_type": "code",
        "outputId": "2c0de7cc-a1aa-4687-db24-9474edcf8240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "  Please let this be here for debugging purpose. The output shape should be (1,1024) ideally\n",
        "\n",
        "\"\"\"\n",
        "# string_input = 'I like the item pri@@ cing . M@@ y grand@@ dau@@ ghter wanted to mark on it but I wanted it just for the let@@ ters .'\n",
        "# sentence = (to_list(string_input))\n",
        "# print(sentence_encoder.encode_sentences(sentence).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb_uW2UKhfs_",
        "colab_type": "code",
        "outputId": "ecfe87af-ff99-4de3-c982-90ff1151fb34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The value should be True\n",
        "len(input_data.sentence_embedding.iloc[0]) == 1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpfv_95F2MqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data = input_data[['sentence_embedding','labels_encoded']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FM5LGWEU_ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data.to_pickle('./preprocessed_sentence_encoded.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXEgP1BoWg5x",
        "colab_type": "text"
      },
      "source": [
        "## The code here basically reads the data from Drive and performs the same set of operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaIEC_bEU_Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx77VUyk5yFe",
        "colab_type": "text"
      },
      "source": [
        "## If you already have the preprocessed data, use it here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw0-djNMYxxY",
        "colab_type": "code",
        "outputId": "6296d80e-3d6d-454b-8810-84ba8532e473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Reading the file from gdrive which is faster than downloading it\n",
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QyyEHMw52rT",
        "colab_type": "code",
        "outputId": "5ca91a1f-d2ab-4c63-fcdc-be328897a09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "%cd /content/\n",
        "input_data = pd.read_csv('/gdrive/My Drive/d_training_concatenated_230k.csv', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytjqgiLurasK",
        "colab_type": "code",
        "outputId": "0ea91636-cab3-46b8-d67e-341f5f0b1fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "input_data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0.1', 'label', 'reviewText', 'tokenized_review',\n",
              "       'tokenized_review_bpe'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBxmvXGoqi27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data.head()\n",
        "#input_data = input_data.drop('Unnamed:0', axis=1)\n",
        "df = input_data\n",
        "df = df[pd.notnull(df['tokenized_review_bpe'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC-JdgYkryls",
        "colab_type": "code",
        "outputId": "06115f60-2ac0-4647-f6bb-9e15fa1066a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.tokenized_review_bpe.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KryRitpr8I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data = df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd3drVZISrtq",
        "colab_type": "text"
      },
      "source": [
        "##  Same set of preprocessing equations that we used for the actual index file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uDG6vLzdS5ho",
        "colab": {}
      },
      "source": [
        "# Because of the nature in which LASER tends to perform encoding we have to do this extra tweek\n",
        "def to_list(element):\n",
        "  return [element]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3UmjrdiMS5h-",
        "colab": {}
      },
      "source": [
        "input_data['tokenized_review_bpe_list'] = input_data.tokenized_review_bpe.apply(to_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YAN8XLWwS5iC",
        "colab": {}
      },
      "source": [
        "from pandas import Series\n",
        "\n",
        "def progress_coroutine(print_on = 10):\n",
        "    print (\"Starting progress monitor\")\n",
        "\n",
        "    iterations = 0\n",
        "    while True:\n",
        "        yield\n",
        "        iterations += 1\n",
        "        if (iterations % print_on == 0):\n",
        "            print (\"{} iterations done\".format(iterations))\n",
        "\n",
        "def percentage_coroutine(to_process, print_on_percent = 0.10):\n",
        "    print (\"Starting progress percentage monitor\")\n",
        "\n",
        "    processed = 0\n",
        "    count = 0\n",
        "    print_count = to_process*print_on_percent\n",
        "    while True:\n",
        "        yield\n",
        "        processed += 1\n",
        "        count += 1\n",
        "        if (count >= print_count):\n",
        "            count = 0\n",
        "            pct = (float(processed)/float(to_process))*100\n",
        "\n",
        "            print (\"{}% finished\".format(pct))\n",
        "\n",
        "def trace_progress(func, progress = None):\n",
        "    def callf(*args, **kwargs):\n",
        "        if (progress is not None):\n",
        "            progress.send(None)\n",
        "\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return callf\n",
        "\n",
        "def my_func(i):\n",
        "    return i ** 2\n",
        "\n",
        "data_series = input_data.tokenized_review_bpe_list\n",
        "co1 = progress_coroutine()\n",
        "co2 = percentage_coroutine(len(data_series))\n",
        "input_data['sentence_embedding'] = data_series.apply(trace_progress(sentence_encoder.encode_sentences, progress = co1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "19526081-de0f-4257-d22a-90fb03aa9277",
        "id": "FW6_Ssr3S5iM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "# The value should be True\n",
        "len(input_data.sentence_embedding.iloc[0]) == 1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-995144687c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'input_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeLXKI4z2CYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop irrelevant columns now\n",
        "input_data = input_data[['sentence_embedding','labels_encoded']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "935c0a91-d997-499f-bf78-21a1e95b74d6",
        "id": "PqkNX211S5iQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "data_series.to_pickle('/gdrive/My Drive/d_training_concatenated_183k_embedded.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVwr0z3eW_iT",
        "colab_type": "text"
      },
      "source": [
        "# If you have sentence embedded dataframe present, use those here directly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGp-uBC9Pwhb",
        "colab_type": "code",
        "outputId": "cf6e4568-1abe-4b94-87d1-f0d9154f0076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Reading the file from gdrive which is faster than downloading it\n",
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BIOsjmBSqRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#input_data.to_csv('/gdrive/My Drive/d_training_concatenated_183k_encoded.pkl')\n",
        "input_data = pd.read_pickle('/gdrive/My Drive/d_training_final.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqEnzjojSqPA",
        "colab_type": "code",
        "outputId": "f135c93c-5265-4aac-8012-7ab2cbe5642b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(input_data.sentence_embedding)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193940"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-ARJLniSqMh",
        "colab_type": "code",
        "outputId": "b326f02b-34e6-4370-8baa-471190338b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "  Leaving this line here because used it to generate the csv file.\n",
        "  Should be refactored in the next iteration\n",
        "\"\"\"\n",
        "# temp_input_data = input_data[:183943]\n",
        "# len(temp_input_data)\n",
        "# temp_input_data.to_csv('/gdrive/My Drive/d_training_concatenated_183k.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Leaving this line here because used it to generate the csv file.\\n  Should be refactored in the next iteration\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obSsZW6dBqrE",
        "colab_type": "code",
        "outputId": "55cccce8-5e14-4b54-abbb-ba1def0fab73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "\"\"\"\n",
        "  Let's encode the values in here so that we can use them as label encoder later\n",
        "\"\"\"\n",
        "# import labelencoder\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# # instantiate labelencoder object\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# input_data['labels_encoded'] = le.fit_transform(input_data['label'])\n",
        "\n",
        "\"\"\"\n",
        "  We are leaving this part here again for completeness since we have a preprocessed dataframe which \n",
        "  has most of the things in place\n",
        "\"\"\"\n",
        "\n",
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_embedding</th>\n",
              "      <th>labels_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0.017418101, 0.003224724, 0.00979801, 0.0071...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.0093318345, -3.4339969e-06, 0.005169349, 0...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0.018201692, -7.0058045e-06, 0.0027392416, 0...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[0.015383401, -2.7567687e-06, -0.0008938909, ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.0031439448, -4.9704126e-05, 0.06903063, 0....</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  sentence_embedding  labels_encoded\n",
              "0  [[0.017418101, 0.003224724, 0.00979801, 0.0071...              20\n",
              "1  [[0.0093318345, -3.4339969e-06, 0.005169349, 0...              17\n",
              "2  [[0.018201692, -7.0058045e-06, 0.0027392416, 0...              16\n",
              "3  [[0.015383401, -2.7567687e-06, -0.0008938909, ...              15\n",
              "4  [[0.0031439448, -4.9704126e-05, 0.06903063, 0....              20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85LV2EV4BqmR",
        "colab_type": "code",
        "outputId": "91fb8fe4-a24f-4d3e-8e30-7abeaa5fe26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The value should be True\n",
        "#len(input_data.sentence_embedding.iloc[0]) == 1 \n",
        "input_data.sentence_embedding.iloc[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwGXxRMJPJUY",
        "colab_type": "text"
      },
      "source": [
        "##Quickly check if both train and validate dataloaders work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jUp4DY8cUl1",
        "colab_type": "code",
        "outputId": "5979e132-24ad-4ce5-ea42-c06eb3cc950e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_embedding</th>\n",
              "      <th>labels_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0.017418101, 0.003224724, 0.00979801, 0.0071...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.0093318345, -3.4339969e-06, 0.005169349, 0...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0.018201692, -7.0058045e-06, 0.0027392416, 0...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[0.015383401, -2.7567687e-06, -0.0008938909, ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.0031439448, -4.9704126e-05, 0.06903063, 0....</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  sentence_embedding  labels_encoded\n",
              "0  [[0.017418101, 0.003224724, 0.00979801, 0.0071...              20\n",
              "1  [[0.0093318345, -3.4339969e-06, 0.005169349, 0...              17\n",
              "2  [[0.018201692, -7.0058045e-06, 0.0027392416, 0...              16\n",
              "3  [[0.015383401, -2.7567687e-06, -0.0008938909, ...              15\n",
              "4  [[0.0031439448, -4.9704126e-05, 0.06903063, 0....              20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikgRo75cfgU1",
        "colab_type": "code",
        "outputId": "fbc4015c-6ff7-4734-d80e-f714a1958de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 1000\n",
        "siamese_train_dataset = TripletDataset(training_mode=True,dataset=input_data,select_column='sentence_embedding')\n",
        "loader = DataLoader(siamese_train_dataset, batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-fdd347f87175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msiamese_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripletDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselect_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentence_embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msiamese_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TripletDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddasqFvxh5QG",
        "colab_type": "code",
        "outputId": "0d06247a-944d-4a21-96ed-212787f0e0e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "for index, (img1,img2,img3) in enumerate(loader):\n",
        "  print (img1.shape)\n",
        "  print(img2.shape)\n",
        "  print(img3.shape)\n",
        "  break\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 1, 1024])\n",
            "torch.Size([1000, 1, 1024])\n",
            "torch.Size([1000, 1, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwJuQJ3XVrfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "siamese_val_dataset = TripletDataset(training_mode=False,dataset=input_data,select_column='sentence_embedding')\n",
        "val_loader = DataLoader(siamese_val_dataset, batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlaBuJNcVrpE",
        "colab_type": "code",
        "outputId": "cd02b9d5-5ed5-444b-fcca-e7847a7dd340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "for index, (img1,img2,img3) in enumerate(val_loader):\n",
        "  print (img1.shape)\n",
        "  print(img2.shape)\n",
        "  print(img3.shape)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 1, 1024])\n",
            "torch.Size([1000, 1, 1024])\n",
            "torch.Size([1000, 1, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R7HfIwQN-JO",
        "colab_type": "text"
      },
      "source": [
        "## Let us drop all the un-necessary columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHOe1eyjN9eE",
        "colab_type": "code",
        "outputId": "625ef825-df0e-4613-da0a-9c7ed987224d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# We used this here: https://stackoverflow.com/questions/45846189/how-to-delete-all-columns-in-dataframe-except-certain-ones\n",
        "input_data = input_data[['sentence_embedding','labels_encoded']]\n",
        "input_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_embedding</th>\n",
              "      <th>labels_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0.009863429, -4.1575836e-06, 0.008913217, 0....</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.039715618, -1.4197368e-05, 0.017486058, 0....</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0.012652903, -2.9125708e-06, 0.0009350272, 0...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[0.014141707, -1.0407556e-05, 0.00032491196, ...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.0115525685, 0.0019211376, 0.008262169, 0.0...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  sentence_embedding  labels_encoded\n",
              "0  [[0.009863429, -4.1575836e-06, 0.008913217, 0....              21\n",
              "1  [[0.039715618, -1.4197368e-05, 0.017486058, 0....              21\n",
              "2  [[0.012652903, -2.9125708e-06, 0.0009350272, 0...              21\n",
              "3  [[0.014141707, -1.0407556e-05, 0.00032491196, ...              21\n",
              "4  [[0.0115525685, 0.0019211376, 0.008262169, 0.0...              21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWPIplWsz8iV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us split the data into train and test sections. This we can use later for our purpose\n",
        "# interestingly, missing out on shuffling would lead to unexpected results\n",
        "# so we need to take care of that as well\n",
        "# This command shuffles the dataset completely\n",
        "input_data = input_data.sample(frac=1).reset_index(drop=True)\n",
        "# now we split it\n",
        "train_split = 0.8\n",
        "last_train_index = int(len(input_data) * train_split)\n",
        "data_train = input_data.iloc[:last_train_index]\n",
        "data_test = input_data.iloc[last_train_index:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWLAenAwz8qd",
        "colab_type": "code",
        "outputId": "4533cc2e-b29d-4a2b-b23b-282c68f7f947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_train.labels_encoded.iloc[-1] == data_test.labels_encoded.iloc[0]  #Indicating that our splits of the data are correct"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koat_Nz1Op49",
        "colab_type": "text"
      },
      "source": [
        "# We first define the simple Triplet Function in here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSJRaTBiOpSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class TripletLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Triplet loss\n",
        "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative, size_average=True):\n",
        "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
        "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
        "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
        "        return losses.mean() if size_average else losses.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR61vY4tM-SW",
        "colab_type": "text"
      },
      "source": [
        "# Modified Siamese Network to be called Triplet Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbJFhGMaM-A3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class TripletNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self): # binary classification so 0/1 shall work\n",
        "      \n",
        "        super(TripletNetwork, self).__init__()\n",
        "\n",
        "        self.input_dim=1024\n",
        "        self.fc = nn.Sequential(nn.Linear(1024, 512),\n",
        "                                  nn.BatchNorm1d(num_features=512),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(),\n",
        "                                  nn.Linear(512,256),\n",
        "                                  nn.BatchNorm1d(num_features=256),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=0.6),\n",
        "                                  nn.Linear(256,64)\n",
        "                               )\n",
        "       \n",
        "    def forward(self, x1, x2, x3):\n",
        "       \n",
        "        \"\"\"\n",
        "          We updated the network now and are directly getting the sentence embeddings\n",
        "        \"\"\"\n",
        "        # These are the embeddings and what we want to achieve is to make\n",
        "        # these embeddings which should be in the same region denoting their language to\n",
        "        # fall a bit away based on the task at hand\n",
        "        output1 = self.fc(x1.cuda())\n",
        "        output2 = self.fc(x2.cuda())\n",
        "        output3 = self.fc(x3.cuda())\n",
        "        \n",
        "        return (output1, output2, output3)\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.encoder.encode_sentences(sentences = x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY-eNwlA81qU",
        "colab_type": "text"
      },
      "source": [
        "# Final Train Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqSjqqbd_5bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRnu-2oaQqkh",
        "colab_type": "code",
        "outputId": "531de7d3-9367-4b1b-c617-a5f931c14561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "siamese_train_dataset = TripletDataset(training_mode=True,dataset=data_train, select_column='sentence_embedding')\n",
        "siamese_test_dataset = TripletDataset(training_mode=False,dataset=data_test, select_column='sentence_embedding')\n",
        "\n",
        "\n",
        "# Putting in the batch sampler here. Again, we need two batch samplers, one for each type\n",
        "\n",
        "train_loader = DataLoader(siamese_train_dataset,  batch_size=40, shuffle=True)\n",
        "val_loader = DataLoader(siamese_test_dataset,  batch_size=40, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-59d837f69c1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msiamese_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripletDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentence_embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msiamese_test_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripletDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentence_embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Putting in the batch sampler here. Again, we need two batch samplers, one for each type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdgDrJGr6i8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "margin = 1.\n",
        "model = TripletNetwork(encoder=sentence_encoder)\n",
        "model.cuda()\n",
        "#loss_fn = OnlineTripletLoss(margin, RandomNegativeTripletSelector(margin))\n",
        "# Fist start with the offline variant\n",
        "loss_fn = TripletLoss(margin)\n",
        "lr = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
        "n_epochs = 20\n",
        "log_interval = 50\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZerJu79ImORc",
        "colab_type": "text"
      },
      "source": [
        "## This is the Colab Integration as it will be useul for our task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JodQfo6mNt4",
        "colab_type": "code",
        "outputId": "4bbbd932-92ad-4dad-ecd8-b75093cea716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Install latest Tensorflow build\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "from tensorflow import summary\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 79.1MB 429kB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 39.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 11.1MB/s \n",
            "\u001b[?25hThe tensorboard module is not an IPython extension.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k86QKp30v0_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete any old logs.... be smart while using this\n",
        "% rm -rf /content/logs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53uZxjiDnDah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% mkdir -p '/content/logs/tensorboard/train/'\n",
        "% mkdir -p '/content/logs/tensorboard/test/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j01oTX8dnDfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "eec2948b-ec9f-40ea-ac66-f81662ece429"
      },
      "source": [
        "import datetime\n",
        "current_time = str(datetime.datetime.now().timestamp())\n",
        "train_log_dir = '/content/logs/tensorboard/train/' + current_time\n",
        "test_log_dir = '/content/logs/tensorboard/test/' + current_time\n",
        "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-902c1f0a206f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_log_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/logs/tensorboard/train/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_log_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/logs/tensorboard/test/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_summary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_log_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_summary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_log_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dw_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accessing local variables before they are created.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[1;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.summary' has no attribute 'create_file_writer'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR6Xw2Mz22Ia",
        "colab_type": "text"
      },
      "source": [
        "## Actual training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-lYpXS_8UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_epoch(val_loader, model, loss_fn, cuda):\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        val_loss = 0\n",
        "        for batch_idx, (img1,img2,img3) in enumerate(val_loader):\n",
        "            \n",
        "            # First let us reshape the tensors\n",
        "            batch_size = img1.shape[0]\n",
        "            img1 = img1.reshape(batch_size,-1)\n",
        "            img2 = img2.reshape(batch_size,-1)\n",
        "            img3 = img3.reshape(batch_size,-1)\n",
        "            # Now we can optimize the remaining terms\n",
        "            \n",
        "            outputs = model(img1,img2,img3) \n",
        "            loss_inputs = outputs\n",
        "\n",
        "            loss_outputs = loss_fn(*loss_inputs)\n",
        "            \n",
        "            val_loss += loss_outputs.item()\n",
        "            \n",
        "    return val_loss/(batch_idx + 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTxnqAvN_5Ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import summary\n",
        "def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval):\n",
        "    \n",
        "\n",
        "    model.train()\n",
        "    losses = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (img1,img2,img3) in enumerate(train_loader):\n",
        "        # First let us reshape the tensors\n",
        "        batch_size = img1.shape[0]\n",
        "        img1 = img1.reshape(batch_size,-1)\n",
        "        img2 = img2.reshape(batch_size,-1)\n",
        "        img3 = img3.reshape(batch_size,-1)\n",
        "        # Now we can optimize the remaining terms\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(img1,img2,img3) \n",
        "        loss_inputs = outputs\n",
        "        \n",
        "        loss_outputs = loss_fn(*outputs) #We assume that target value is not known and hence is None\n",
        "        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
        "        losses.append(loss.item())\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            message = 'Train: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                batch_idx * len(img1), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), np.mean(losses))\n",
        "            \n",
        "            print(message)\n",
        "            losses = []\n",
        "\n",
        "    total_loss /= (batch_idx + 1)\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMPNdk6_RztF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval,\n",
        "        start_epoch=0):\n",
        "    \"\"\"\n",
        "    Loaders, model, loss function and metrics should work together for a given task,\n",
        "    i.e. The model should be able to process data output of loaders,\n",
        "    loss function should process target output of loaders and outputs from the model\n",
        "\n",
        "    Examples: Classification: batch loader, classification model, NLL loss, accuracy metric\n",
        "    Siamese network: Siamese loader, siamese model, contrastive loss\n",
        "    Online triplet learning: batch loader, embedding model, online triplet loss\n",
        "    \"\"\"\n",
        "    for epoch in range(0, start_epoch):\n",
        "        scheduler.step()\n",
        "\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Train stage\n",
        "        train_loss = train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval)\n",
        "        message = 'Epoch: {}/{}. Train set: Average loss: {:.4f}'.format(epoch + 1, n_epochs, train_loss)\n",
        "        with train_summary_writer.as_default():\n",
        "           summary.scalar('loss', train_loss, step=epoch)\n",
        "        print(message)\n",
        "        val_loss = test_epoch(val_loader, model, loss_fn, cuda)\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        message += '\\nEpoch: {}/{}. Validation set: Average loss: {:.4f}'.format(epoch + 1, n_epochs,\n",
        "                                                                                     val_loss)\n",
        "        \n",
        "        torch.save(model.state_dict(), './{}-model.pth'.format(epoch))\n",
        "        \n",
        "        with test_summary_writer.as_default():\n",
        "           summary.scalar('loss', val_loss, step=epoch)        \n",
        "\n",
        "#        print(message)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE7xETdQLNfB",
        "colab_type": "code",
        "outputId": "48bb271c-b2c0-4b69-8414-0daf3e6086d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "cuda = True\n",
        "n_epochs = 200\n",
        "fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda,log_interval)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: [30000/147154 (20%)]\tLoss: 0.359381\n",
            "Train: [32000/147154 (22%)]\tLoss: 0.368391\n",
            "Train: [34000/147154 (23%)]\tLoss: 0.364973\n",
            "Train: [36000/147154 (24%)]\tLoss: 0.290639\n",
            "Train: [38000/147154 (26%)]\tLoss: 0.347265\n",
            "Train: [40000/147154 (27%)]\tLoss: 0.368214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-c65247cc3177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-7705deb7daf7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, start_epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Train stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epoch: {}/{}. Train set: Average loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-106-738f287d02b8>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, loss_fn, optimizer, cuda, log_interval)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# First let us reshape the tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-d87e332fbcef>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#print(\"Computation of the entities are completed\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H95TwXv-rckQ",
        "colab_type": "code",
        "outputId": "c4fc29aa-bd34-4086-c534-ac49eeeac840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorboard --logdir /content/logs/tensorboard"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df5OaEQT02wa",
        "colab_type": "text"
      },
      "source": [
        "# The Code here is to try and implement the online Batch Sampling Selection Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERTjB0zztxnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1c8e26bf-cc3a-4253-c82a-c2f66128c1a1"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7A0tgL80ye6",
        "colab_type": "code",
        "outputId": "4f79e255-322d-43a9-ebdb-aebe677fa3ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "%cd /content/\n",
        "#input_data.to_csv('/gdrive/My Drive/d_training_concatenated_183k_encoded.pkl')\n",
        "input_data = pd.read_pickle('/content/drive/My Drive/d_training_final.pkl')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5NdmsYeyY4o",
        "colab_type": "code",
        "outputId": "3c71acd3-4650-47de-df58-74d5bceb32b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(input_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193940"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-mtMvx0b25bh",
        "colab": {}
      },
      "source": [
        "# Let us split the data into train and test sections. This we can use later for our purpose\n",
        "# interestingly, missing out on shuffling would lead to unexpected results\n",
        "# so we need to take care of that as well\n",
        "# This command shuffles the dataset completely\n",
        "input_data = input_data.sample(frac=1).reset_index(drop=True)\n",
        "# now we split it\n",
        "train_split = 0.8\n",
        "last_train_index = int(len(input_data) * train_split)\n",
        "data_train = input_data.iloc[:last_train_index]\n",
        "data_test = input_data.iloc[last_train_index:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cca1f825-9479-46fb-8d0b-5b17a45143fd",
        "id": "21-ENHTN25b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_train.labels_encoded.iloc[-1] != data_test.labels_encoded.iloc[0]  #Indicating that our splits of the data are correct"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcikqQjD092u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import BatchSampler\n",
        "\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "    \"\"\"\n",
        "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
        "    Returns batches of size n_classes * n_samples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, labels, n_classes, n_samples):\n",
        "        self.labels = labels\n",
        "        self.labels_set = list(set(self.labels.to_numpy()))\n",
        "        self.label_to_indices = {label: np.where(self.labels.to_numpy() == label)[0]\n",
        "                                 for label in self.labels_set}\n",
        "        for l in self.labels_set:\n",
        "            np.random.shuffle(self.label_to_indices[l])\n",
        "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
        "        self.count = 0\n",
        "        self.n_classes = n_classes\n",
        "        self.n_samples = n_samples\n",
        "        self.n_dataset = len(self.labels)\n",
        "        self.batch_size = self.n_samples * self.n_classes\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.count = 0\n",
        "        while self.count + self.batch_size < self.n_dataset:\n",
        "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
        "            indices = []\n",
        "            for class_ in classes:\n",
        "                indices.extend(self.label_to_indices[class_][\n",
        "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
        "                                                                         class_] + self.n_samples])\n",
        "                self.used_label_indices_count[class_] += self.n_samples\n",
        "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
        "                    np.random.shuffle(self.label_to_indices[class_])\n",
        "                    self.used_label_indices_count[class_] = 0\n",
        "            yield indices\n",
        "            self.count += self.n_classes * self.n_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_dataset // self.batch_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJKJcWNgHArF",
        "colab_type": "text"
      },
      "source": [
        "# This is the definition of the Online Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-xIsmzV7Tfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class OnlineTripletLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Online Triplets loss\n",
        "    Takes a batch of embeddings and corresponding labels.\n",
        "    Triplets are generated using triplet_selector object that take embeddings and targets and return indices of\n",
        "    triplets\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin, triplet_selector):\n",
        "        super(OnlineTripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.triplet_selector = triplet_selector\n",
        "\n",
        "    def forward(self, embeddings, target):\n",
        "\n",
        "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
        "\n",
        "        if embeddings.is_cuda:\n",
        "            triplets = triplets.cuda()\n",
        "\n",
        "        ap_distances = (embeddings[triplets[:, 0]] - embeddings[triplets[:, 1]]).pow(2).sum(1)  # .pow(.5)\n",
        "        an_distances = (embeddings[triplets[:, 0]] - embeddings[triplets[:, 2]]).pow(2).sum(1)  # .pow(.5)\n",
        "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
        "\n",
        "        return losses.mean(), len(triplets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2lVJimGIx1O",
        "colab_type": "text"
      },
      "source": [
        "# This is a variation via the Triplet Loader because I could not find any other way out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48TpoQRCJLD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class OnlineTripletDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, select_column, training_mode=True):\n",
        "         \n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.train = training_mode\n",
        "        self.select_column = select_column\n",
        "        self.labels = self.dataset.labels_encoded\n",
        "        if self.train:\n",
        "            self.train_labels = self.dataset.labels_encoded\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "            self.dataset = self.dataset.drop('labels_encoded', axis=1)\n",
        "            self.train_data = self.dataset\n",
        "            self.labels_set = set(self.train_labels.to_numpy())\n",
        "            self.label_to_indices = {label: np.where(self.train_labels.to_numpy() == label)[0]\n",
        "                                     for label in self.labels_set} # redundent in our case if we decide to use numeric labels based on certain sklearn packages\n",
        "\n",
        "        else:\n",
        "            self.test_labels = self.dataset.labels_encoded\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "            self.dataset = self.dataset.drop('labels_encoded', axis=1)\n",
        "            self.test_data = self.dataset\n",
        "            # generate fixed triplets for testing\n",
        "            self.labels_set = set(self.test_labels.to_numpy())\n",
        "            self.label_to_indices = {label: np.where(self.test_labels.to_numpy() == label)[0]\n",
        "                                     for label in self.labels_set}\n",
        "\n",
        "            random_state = np.random.RandomState(42)\n",
        "            \n",
        "            #print(\"Length of the dataset is {}\".format(len(self.test_data)))\n",
        "            \n",
        "            triplets = []\n",
        "            for i in range(len(self.test_data)):\n",
        "                  triplets.append([i,\n",
        "                           random_state.choice(self.label_to_indices[self.test_labels.iloc[i]]),\n",
        "                           random_state.choice(self.label_to_indices[\n",
        "                                                 np.random.choice(\n",
        "                                                     list(self.labels_set - set([self.test_labels.iloc[i]]))\n",
        "                                                 )\n",
        "                                             ])\n",
        "                         ]) \n",
        "                         \n",
        "            self.test_triplets = triplets\n",
        "           \n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            #print(type(self.train_data))\n",
        "            sent1, label1 = self.train_data.iloc[index], self.train_labels.iloc[index]\n",
        "            positive_index = index\n",
        "            while positive_index == index:\n",
        "                positive_index = np.random.choice(self.label_to_indices[label1])\n",
        "            negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
        "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
        "            sent2 = self.train_data.iloc[positive_index]\n",
        "            sent3 = self.train_data.iloc[negative_index]\n",
        "            # Also include the labels under consideration\n",
        "            label2 = self.labels.iloc[positive_index]\n",
        "            label3 = self.labels.iloc[negative_index]\n",
        "        else:\n",
        "            sent1 = self.test_data.iloc[self.test_triplets[index][0]]\n",
        "            sent2 = self.test_data.iloc[self.test_triplets[index][1]]\n",
        "            sent3 = self.test_data.iloc[self.test_triplets[index][2]]\n",
        "            label1 = self.labels.iloc[self.test_triplets[index][0]]\n",
        "            label2 = self.labels.iloc[self.test_triplets[index][1]]\n",
        "            label3 = self.labels.iloc[self.test_triplets[index][2]]\n",
        "        # Filter to select only the required column rather than all\n",
        "        sent1 = sent1[self.select_column]\n",
        "        sent2 = sent2[self.select_column]\n",
        "        sent3 = sent3[self.select_column]\n",
        "        \n",
        "\n",
        "        return ((sent1,label1), (sent2,label2), (sent3,label3))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P99BAFNhZBwG",
        "colab_type": "code",
        "outputId": "4605f736-57c4-439b-f4e7-55d1fd492f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\" \n",
        "  This cell should be basically `True` indicating that the two datasets have all the\n",
        "  labels ie shuffling done earlier was meaninigful\n",
        "\"\"\"\n",
        "set(data_train.labels_encoded) == set(data_test.labels_encoded)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZOD7HvJ3zKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "siamese_train_dataset = OnlineTripletDataset(training_mode=True,dataset=data_train, select_column='sentence_embedding')\n",
        "siamese_test_dataset = OnlineTripletDataset(training_mode=False,dataset=data_test, select_column='sentence_embedding')\n",
        "\n",
        "batch_size = 5\n",
        "# Putting in the batch sampler here. Again, we need two batch samplers, one for each type\n",
        "\n",
        "# We'll create mini batches by sampling labels that will be present in the mini batch and number of examples from each datatype\n",
        "train_batch_sampler = BalancedBatchSampler(data_train.labels_encoded, n_classes=23, n_samples=batch_size) # Number of classes in the current dataset is 23\n",
        "val_batch_sampler = BalancedBatchSampler(data_test.labels_encoded, n_classes=23, n_samples=batch_size) # Number of classes in the current dataset is 23\n",
        "\n",
        "\n",
        "online_train_loader = DataLoader(siamese_train_dataset, batch_sampler=train_batch_sampler)\n",
        "online_val_loader = DataLoader(siamese_test_dataset, batch_sampler=val_batch_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrDgswhZ4HNv",
        "colab_type": "code",
        "outputId": "1b9e5b71-360e-498d-e657-289346e50047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "\"\"\" \n",
        " Quick sanity check for the batch samplers\n",
        " The outpur shall be 23 times batch size ie we have elements from each of the categories\n",
        "\"\"\"\n",
        "\n",
        "for index, (img1,img2,img3) in enumerate(online_train_loader):\n",
        "  print (img1[0].shape)\n",
        "  print (img2[0].shape)\n",
        "  print (img3[0].shape)\n",
        "  break\n",
        "\n",
        "print(\"Let us test the scenario for validation dataloader\")\n",
        "  \n",
        "for index, (img1,img2,img3) in enumerate(online_val_loader):\n",
        "  print (img1[0].shape)\n",
        "  print (img2[0].shape)\n",
        "  print (img3[0].shape)\n",
        "  break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([115, 1, 1024])\n",
            "torch.Size([115, 1, 1024])\n",
            "torch.Size([115, 1, 1024])\n",
            "Let us test the scenario for validation dataloader\n",
            "torch.Size([115, 1, 1024])\n",
            "torch.Size([115, 1, 1024])\n",
            "torch.Size([115, 1, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlDNl66-7Ueo",
        "colab_type": "text"
      },
      "source": [
        "# This is the Triplet Selection code that is being used in this place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzTqQdqS7T2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pdist(vectors):\n",
        "  \"\"\"\n",
        "    This is the basic definition of the distance matrix from a vector\n",
        "  \"\"\"\n",
        "  distance_matrix = -2 * vectors.mm(torch.t(vectors)) + vectors.pow(2).sum(dim=1).view(1, -1) + vectors.pow(2).sum(\n",
        "      dim=1).view(-1, 1)\n",
        "  return distance_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Odz1NjZ4LN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations\n",
        "class FunctionNegativeTripletSelector():\n",
        "    \"\"\"\n",
        "    For each positive pair, takes the hardest negative sample (with the greatest triplet loss value) to create a triplet\n",
        "    Margin should match the margin used in triplet loss.\n",
        "    negative_selection_fn should take array of loss_values for a given anchor-positive pair and all negative samples\n",
        "    and return a negative index for that pair\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin, negative_selection_fn, cpu=False):\n",
        "        super(FunctionNegativeTripletSelector, self).__init__()\n",
        "        self.cpu = cpu\n",
        "        self.margin = margin\n",
        "        self.negative_selection_fn = negative_selection_fn\n",
        "\n",
        "    def get_triplets(self, embeddings, labels):\n",
        "        if self.cpu:\n",
        "            embeddings = embeddings.cpu()\n",
        "        distance_matrix = pdist(embeddings)\n",
        "        distance_matrix = distance_matrix.cpu()\n",
        "        \n",
        "        labels = labels.cpu().data.numpy()\n",
        "        triplets = []\n",
        "        for label in set(labels):\n",
        "            label_mask = (labels == label)\n",
        "            label_indices = np.where(label_mask)[0]\n",
        "            if len(label_indices) < 2:\n",
        "                continue\n",
        "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
        "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
        "            anchor_positives = np.array(anchor_positives)\n",
        "\n",
        "            ap_distances = distance_matrix[anchor_positives[:, 0], anchor_positives[:, 1]]\n",
        "            for anchor_positive, ap_distance in zip(anchor_positives, ap_distances):\n",
        "                loss_values = ap_distance - distance_matrix[torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
        "                loss_values = loss_values.data.cpu().numpy()\n",
        "                hard_negative = self.negative_selection_fn(loss_values)\n",
        "                if hard_negative is not None:\n",
        "                    hard_negative = negative_indices[hard_negative]\n",
        "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative])\n",
        "\n",
        "        if len(triplets) == 0:\n",
        "            triplets.append([anchors_positive[0], anchors_positive[1], negative_indices[0]])\n",
        "\n",
        "        triplets = np.array(triplets)\n",
        "\n",
        "        return torch.LongTensor(triplets)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX7FRICw7HYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hardest_negative(loss_values):\n",
        "    hard_negative = np.argmax(loss_values)\n",
        "    return hard_negative if loss_values[hard_negative] > 0 else None\n",
        "\n",
        "\n",
        "def random_hard_negative(loss_values):\n",
        "    hard_negatives = np.where(loss_values > 0)[0]\n",
        "    return np.random.choice(hard_negatives) if len(hard_negatives) > 0 else None\n",
        "\n",
        "\n",
        "def semihard_negative(loss_values, margin):\n",
        "    semihard_negatives = np.where(np.logical_and(loss_values < margin, loss_values > 0))[0]\n",
        "    return np.random.choice(semihard_negatives) if len(semihard_negatives) > 0 else None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB-fLNLG6i_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def HardestNegativeTripletSelector(margin, cpu=False):\n",
        "  return FunctionNegativeTripletSelector(margin=margin,negative_selection_fn=hardest_negative, cpu=cpu)\n",
        "\n",
        "\n",
        "def RandomNegativeTripletSelector(margin, cpu=False): \n",
        "  return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=random_hard_negative, cpu=cpu)\n",
        "\n",
        "\n",
        "def SemihardNegativeTripletSelector(margin, cpu=False): \n",
        "  return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=lambda x: semihard_negative(x, margin), cpu=cpu)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSMiDjZWSbGe",
        "colab_type": "text"
      },
      "source": [
        "# This train code is for the Online Triplet selection network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXI9oTnwV3vs",
        "colab_type": "text"
      },
      "source": [
        "## Creating new event objects for Tensorboard. Visualisation on previous dashboard possible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccXh8-EOQ_vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch\n",
        "margin = 1.\n",
        "model = TripletNetwork()\n",
        "model.cuda()\n",
        "loss_fn = OnlineTripletLoss(margin,triplet_selector=SemihardNegativeTripletSelector(margin=margin))\n",
        "lr = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
        "n_epochs = 20\n",
        "log_interval = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFoyQ0PNSajZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import summary\n",
        "def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval):\n",
        "    \n",
        "\n",
        "    model.train()\n",
        "    losses = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, ((sent1,label1),(sent2,label2),(sent3,label3)) in enumerate(train_loader):\n",
        "      \n",
        "        labels = []\n",
        "        batch_size = sent1.shape[0]\n",
        "        sent1 = sent1.reshape(batch_size,-1)\n",
        "        sent2 = sent2.reshape(batch_size,-1)\n",
        "        sent3 = sent3.reshape(batch_size,-1)\n",
        "        labels.extend(label1)\n",
        "        labels.extend(label2)\n",
        "        labels.extend(label3)\n",
        "        #print(labels)\n",
        "        labels = torch.Tensor(labels).cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(sent1,sent2,sent3) \n",
        "        loss_inputs = outputs\n",
        "        \n",
        "        # We have three outputs, index 0 shall be for anchor, 1 is positive and 2 negative\n",
        "        # please double check\n",
        "        \n",
        "        loss_inputs = torch.cat((outputs[0],outputs[1], outputs[2]), 0)\n",
        "        \n",
        "        #print()\n",
        "        \n",
        "        loss_outputs = loss_fn(loss_inputs, labels) #We assume that target value is not known and hence is None\n",
        "        \n",
        "        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
        "        losses.append(loss.item())\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            message = 'Train: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                batch_idx * len(img1), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), np.mean(losses))\n",
        "            \n",
        "            print(message)\n",
        "            losses = []\n",
        "\n",
        "    total_loss /= (batch_idx + 1)\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlO5Ja_PXyyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_epoch(val_loader, model, loss_fn, cuda):\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        val_loss = 0\n",
        "        for batch_idx, ((sent1,label1),(sent2,label2),(sent3,label3)) in enumerate(val_loader):\n",
        "            \n",
        "            labels = []\n",
        "            batch_size = sent1.shape[0]\n",
        "            sent1 = sent1.reshape(batch_size,-1)\n",
        "            sent2 = sent2.reshape(batch_size,-1)\n",
        "            sent3 = sent3.reshape(batch_size,-1)\n",
        "            labels.extend(label1)\n",
        "            labels.extend(label2)\n",
        "            labels.extend(label3)\n",
        "        \n",
        "            labels = torch.Tensor(labels).cuda()\n",
        "          \n",
        "            outputs = model(sent1,sent2,sent3) \n",
        "\n",
        "            \n",
        "            loss_inputs = torch.cat((outputs[0],outputs[1], outputs[2]), 0)\n",
        "            \n",
        "\n",
        "            loss_outputs = loss_fn(loss_inputs, labels) #We assume that target value is not known and hence is None\n",
        "            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
        "            \n",
        "            val_loss += loss.item()\n",
        "            \n",
        "    return val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BX4rsUm8053",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval,\n",
        "        start_epoch=0):\n",
        "    \"\"\"\n",
        "    Loaders, model, loss function and metrics should work together for a given task,\n",
        "    i.e. The model should be able to process data output of loaders,\n",
        "    loss function should process target output of loaders and outputs from the model\n",
        "\n",
        "    Examples: Classification: batch loader, classification model, NLL loss, accuracy metric\n",
        "    Siamese network: Siamese loader, siamese model, contrastive loss\n",
        "    Online triplet learning: batch loader, embedding model, online triplet loss\n",
        "    \"\"\"\n",
        "    for epoch in range(0, start_epoch):\n",
        "        scheduler.step()\n",
        "\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Train stage\n",
        "        train_loss = train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval)\n",
        "        message = 'Epoch: {}/{}. Train set: Average loss: {:.4f}'.format(epoch + 1, n_epochs, train_loss)\n",
        "        with train_summary_writer.as_default():\n",
        "           summary.scalar('loss', train_loss, step=epoch)\n",
        "        print(message)\n",
        "        val_loss = test_epoch(val_loader, model, loss_fn, cuda)\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        message += '\\nEpoch: {}/{}. Validation set: Average loss: {:.4f}'.format(epoch + 1, n_epochs,\n",
        "                                                                                     val_loss)\n",
        "        print(message)\n",
        "        torch.save(model.state_dict(), './{}-model.pth'.format(epoch))\n",
        "        \n",
        "        with test_summary_writer.as_default():\n",
        "           summary.scalar('loss', val_loss, step=epoch)        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S01rUUY8802M",
        "colab_type": "code",
        "outputId": "53bcd39e-7634-4a98-cf9f-b101b7b29431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5494
        }
      },
      "source": [
        "cuda = True\n",
        "n_epochs = 30\n",
        "fit(online_train_loader, online_val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda,log_interval)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: [400/155152 (15%)]\tLoss: 0.501999\n",
            "Train: [500/155152 (19%)]\tLoss: 0.500556\n",
            "Train: [600/155152 (22%)]\tLoss: 0.498599\n",
            "Train: [700/155152 (26%)]\tLoss: 0.498965\n",
            "Train: [800/155152 (30%)]\tLoss: 0.501510\n",
            "Train: [900/155152 (33%)]\tLoss: 0.499077\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.500659\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.500450\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.498242\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.497559\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.496821\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.496996\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.498663\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.496408\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.500720\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.500404\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.496622\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.497047\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.500607\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.498410\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.501754\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.495104\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.497693\n",
            "Epoch: 20/30. Train set: Average loss: 0.4992\n",
            "Epoch: 20/30. Train set: Average loss: 0.4992\n",
            "Epoch: 20/30. Validation set: Average loss: 0.4988\n",
            "Train: [0/155152 (0%)]\tLoss: 0.512983\n",
            "Train: [100/155152 (4%)]\tLoss: 0.502889\n",
            "Train: [200/155152 (7%)]\tLoss: 0.495115\n",
            "Train: [300/155152 (11%)]\tLoss: 0.499633\n",
            "Train: [400/155152 (15%)]\tLoss: 0.498521\n",
            "Train: [500/155152 (19%)]\tLoss: 0.496047\n",
            "Train: [600/155152 (22%)]\tLoss: 0.501868\n",
            "Train: [700/155152 (26%)]\tLoss: 0.497914\n",
            "Train: [800/155152 (30%)]\tLoss: 0.497097\n",
            "Train: [900/155152 (33%)]\tLoss: 0.501795\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.496182\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.501159\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.499457\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.502099\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.496666\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.499686\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.498581\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.503591\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.500951\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.499946\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.494265\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.500238\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.497327\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.500080\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.500955\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.502190\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.500341\n",
            "Epoch: 21/30. Train set: Average loss: 0.4994\n",
            "Epoch: 21/30. Train set: Average loss: 0.4994\n",
            "Epoch: 21/30. Validation set: Average loss: 0.4999\n",
            "Train: [0/155152 (0%)]\tLoss: 0.504360\n",
            "Train: [100/155152 (4%)]\tLoss: 0.499703\n",
            "Train: [200/155152 (7%)]\tLoss: 0.497724\n",
            "Train: [300/155152 (11%)]\tLoss: 0.501310\n",
            "Train: [400/155152 (15%)]\tLoss: 0.501502\n",
            "Train: [500/155152 (19%)]\tLoss: 0.501579\n",
            "Train: [600/155152 (22%)]\tLoss: 0.500444\n",
            "Train: [700/155152 (26%)]\tLoss: 0.500596\n",
            "Train: [800/155152 (30%)]\tLoss: 0.501843\n",
            "Train: [900/155152 (33%)]\tLoss: 0.497642\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.501714\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.499634\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.497441\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.499585\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.499225\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.499755\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.494013\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.505947\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.500967\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.504419\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.500151\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.497481\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.495378\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.500294\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.501630\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.497237\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.499653\n",
            "Epoch: 22/30. Train set: Average loss: 0.4999\n",
            "Epoch: 22/30. Train set: Average loss: 0.4999\n",
            "Epoch: 22/30. Validation set: Average loss: 0.4992\n",
            "Train: [0/155152 (0%)]\tLoss: 0.493722\n",
            "Train: [100/155152 (4%)]\tLoss: 0.501293\n",
            "Train: [200/155152 (7%)]\tLoss: 0.500187\n",
            "Train: [300/155152 (11%)]\tLoss: 0.499544\n",
            "Train: [400/155152 (15%)]\tLoss: 0.501766\n",
            "Train: [500/155152 (19%)]\tLoss: 0.497139\n",
            "Train: [600/155152 (22%)]\tLoss: 0.497946\n",
            "Train: [700/155152 (26%)]\tLoss: 0.501862\n",
            "Train: [800/155152 (30%)]\tLoss: 0.502060\n",
            "Train: [900/155152 (33%)]\tLoss: 0.497073\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.492372\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.506066\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.499831\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.501510\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.497330\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.493717\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.496389\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.506068\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.500855\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.498899\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.504116\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.497310\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.498647\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.501518\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.498596\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.498969\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.502750\n",
            "Epoch: 23/30. Train set: Average loss: 0.4999\n",
            "Epoch: 23/30. Train set: Average loss: 0.4999\n",
            "Epoch: 23/30. Validation set: Average loss: 0.4991\n",
            "Train: [0/155152 (0%)]\tLoss: 0.481394\n",
            "Train: [100/155152 (4%)]\tLoss: 0.498618\n",
            "Train: [200/155152 (7%)]\tLoss: 0.498522\n",
            "Train: [300/155152 (11%)]\tLoss: 0.499457\n",
            "Train: [400/155152 (15%)]\tLoss: 0.502611\n",
            "Train: [500/155152 (19%)]\tLoss: 0.498930\n",
            "Train: [600/155152 (22%)]\tLoss: 0.496543\n",
            "Train: [700/155152 (26%)]\tLoss: 0.499765\n",
            "Train: [800/155152 (30%)]\tLoss: 0.500589\n",
            "Train: [900/155152 (33%)]\tLoss: 0.500296\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.498132\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.502915\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.497808\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.501973\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.497450\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.495141\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.501565\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.501407\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.499205\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.504273\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.500661\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.499643\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.499909\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.501226\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.496185\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.500451\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.499717\n",
            "Epoch: 24/30. Train set: Average loss: 0.4999\n",
            "Epoch: 24/30. Train set: Average loss: 0.4999\n",
            "Epoch: 24/30. Validation set: Average loss: 0.5009\n",
            "Train: [0/155152 (0%)]\tLoss: 0.541628\n",
            "Train: [100/155152 (4%)]\tLoss: 0.498626\n",
            "Train: [200/155152 (7%)]\tLoss: 0.497178\n",
            "Train: [300/155152 (11%)]\tLoss: 0.494134\n",
            "Train: [400/155152 (15%)]\tLoss: 0.498793\n",
            "Train: [500/155152 (19%)]\tLoss: 0.493216\n",
            "Train: [600/155152 (22%)]\tLoss: 0.497094\n",
            "Train: [700/155152 (26%)]\tLoss: 0.500498\n",
            "Train: [800/155152 (30%)]\tLoss: 0.497900\n",
            "Train: [900/155152 (33%)]\tLoss: 0.503199\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.504540\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.501417\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.501633\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.495704\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.499877\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.496456\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.500035\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.500679\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.501114\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.502038\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.494737\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.501270\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.498165\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.502792\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.495352\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.503311\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.495321\n",
            "Epoch: 25/30. Train set: Average loss: 0.4992\n",
            "Epoch: 25/30. Train set: Average loss: 0.4992\n",
            "Epoch: 25/30. Validation set: Average loss: 0.4984\n",
            "Train: [0/155152 (0%)]\tLoss: 0.486573\n",
            "Train: [100/155152 (4%)]\tLoss: 0.505905\n",
            "Train: [200/155152 (7%)]\tLoss: 0.499378\n",
            "Train: [300/155152 (11%)]\tLoss: 0.501389\n",
            "Train: [400/155152 (15%)]\tLoss: 0.500639\n",
            "Train: [500/155152 (19%)]\tLoss: 0.496329\n",
            "Train: [600/155152 (22%)]\tLoss: 0.502114\n",
            "Train: [700/155152 (26%)]\tLoss: 0.500230\n",
            "Train: [800/155152 (30%)]\tLoss: 0.497575\n",
            "Train: [900/155152 (33%)]\tLoss: 0.502226\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.498761\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.496299\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.500241\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.504566\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.498251\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.498842\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.495117\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.501229\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.501704\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.499510\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.499297\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.498609\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.499035\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.498106\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.499596\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.503435\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.501765\n",
            "Epoch: 26/30. Train set: Average loss: 0.5000\n",
            "Epoch: 26/30. Train set: Average loss: 0.5000\n",
            "Epoch: 26/30. Validation set: Average loss: 0.4987\n",
            "Train: [0/155152 (0%)]\tLoss: 0.474082\n",
            "Train: [100/155152 (4%)]\tLoss: 0.496992\n",
            "Train: [200/155152 (7%)]\tLoss: 0.500073\n",
            "Train: [300/155152 (11%)]\tLoss: 0.498528\n",
            "Train: [400/155152 (15%)]\tLoss: 0.499187\n",
            "Train: [500/155152 (19%)]\tLoss: 0.494968\n",
            "Train: [600/155152 (22%)]\tLoss: 0.501369\n",
            "Train: [700/155152 (26%)]\tLoss: 0.499602\n",
            "Train: [800/155152 (30%)]\tLoss: 0.502859\n",
            "Train: [900/155152 (33%)]\tLoss: 0.500658\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.496540\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.500892\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.500568\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.502802\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.507634\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.505636\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.499558\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.497923\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.503634\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.500490\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.497370\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.499343\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.500245\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.500987\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.498742\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.497477\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.503241\n",
            "Epoch: 27/30. Train set: Average loss: 0.5001\n",
            "Epoch: 27/30. Train set: Average loss: 0.5001\n",
            "Epoch: 27/30. Validation set: Average loss: 0.5004\n",
            "Train: [0/155152 (0%)]\tLoss: 0.483309\n",
            "Train: [100/155152 (4%)]\tLoss: 0.496612\n",
            "Train: [200/155152 (7%)]\tLoss: 0.498314\n",
            "Train: [300/155152 (11%)]\tLoss: 0.496453\n",
            "Train: [400/155152 (15%)]\tLoss: 0.501047\n",
            "Train: [500/155152 (19%)]\tLoss: 0.497033\n",
            "Train: [600/155152 (22%)]\tLoss: 0.500143\n",
            "Train: [700/155152 (26%)]\tLoss: 0.500127\n",
            "Train: [800/155152 (30%)]\tLoss: 0.500828\n",
            "Train: [900/155152 (33%)]\tLoss: 0.497948\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.496744\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.499264\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.499224\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.498109\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.494286\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.497074\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.497773\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.495857\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.496758\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.493797\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.503553\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.496423\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.495199\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.497571\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.503591\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.496045\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.497080\n",
            "Epoch: 28/30. Train set: Average loss: 0.4981\n",
            "Epoch: 28/30. Train set: Average loss: 0.4981\n",
            "Epoch: 28/30. Validation set: Average loss: 0.4990\n",
            "Train: [0/155152 (0%)]\tLoss: 0.497005\n",
            "Train: [100/155152 (4%)]\tLoss: 0.494902\n",
            "Train: [200/155152 (7%)]\tLoss: 0.498980\n",
            "Train: [300/155152 (11%)]\tLoss: 0.503371\n",
            "Train: [400/155152 (15%)]\tLoss: 0.498153\n",
            "Train: [500/155152 (19%)]\tLoss: 0.503994\n",
            "Train: [600/155152 (22%)]\tLoss: 0.495511\n",
            "Train: [700/155152 (26%)]\tLoss: 0.502143\n",
            "Train: [800/155152 (30%)]\tLoss: 0.496668\n",
            "Train: [900/155152 (33%)]\tLoss: 0.499636\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.501636\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.495945\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.501972\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.496327\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.492268\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.497897\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.497798\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.497109\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.499592\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.499255\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.501226\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.503891\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.504283\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.499220\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.502540\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.497979\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.498668\n",
            "Epoch: 29/30. Train set: Average loss: 0.4993\n",
            "Epoch: 29/30. Train set: Average loss: 0.4993\n",
            "Epoch: 29/30. Validation set: Average loss: 0.5008\n",
            "Train: [0/155152 (0%)]\tLoss: 0.513807\n",
            "Train: [100/155152 (4%)]\tLoss: 0.497438\n",
            "Train: [200/155152 (7%)]\tLoss: 0.497598\n",
            "Train: [300/155152 (11%)]\tLoss: 0.501261\n",
            "Train: [400/155152 (15%)]\tLoss: 0.500399\n",
            "Train: [500/155152 (19%)]\tLoss: 0.497347\n",
            "Train: [600/155152 (22%)]\tLoss: 0.497136\n",
            "Train: [700/155152 (26%)]\tLoss: 0.496886\n",
            "Train: [800/155152 (30%)]\tLoss: 0.503554\n",
            "Train: [900/155152 (33%)]\tLoss: 0.499664\n",
            "Train: [1000/155152 (37%)]\tLoss: 0.502189\n",
            "Train: [1100/155152 (41%)]\tLoss: 0.504152\n",
            "Train: [1200/155152 (44%)]\tLoss: 0.496653\n",
            "Train: [1300/155152 (48%)]\tLoss: 0.497588\n",
            "Train: [1400/155152 (52%)]\tLoss: 0.495165\n",
            "Train: [1500/155152 (56%)]\tLoss: 0.497575\n",
            "Train: [1600/155152 (59%)]\tLoss: 0.497347\n",
            "Train: [1700/155152 (63%)]\tLoss: 0.499604\n",
            "Train: [1800/155152 (67%)]\tLoss: 0.502246\n",
            "Train: [1900/155152 (70%)]\tLoss: 0.501328\n",
            "Train: [2000/155152 (74%)]\tLoss: 0.499458\n",
            "Train: [2100/155152 (78%)]\tLoss: 0.494519\n",
            "Train: [2200/155152 (82%)]\tLoss: 0.501810\n",
            "Train: [2300/155152 (85%)]\tLoss: 0.501302\n",
            "Train: [2400/155152 (89%)]\tLoss: 0.499487\n",
            "Train: [2500/155152 (93%)]\tLoss: 0.502363\n",
            "Train: [2600/155152 (96%)]\tLoss: 0.499512\n",
            "Epoch: 30/30. Train set: Average loss: 0.4994\n",
            "Epoch: 30/30. Train set: Average loss: 0.4994\n",
            "Epoch: 30/30. Validation set: Average loss: 0.4984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqIjnEpERaOG",
        "colab_type": "text"
      },
      "source": [
        "## Experimental Section of applying Softmax on the embedding space to see the output. This is bit of a change from the normal operation of our Triplet Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEJsZLi3RZkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassificationNet(nn.Module):\n",
        "  \n",
        "\n",
        "  def __init__(self, embedding_network, num_classes):\n",
        "    super(ClassificationNet, self).__init__()\n",
        "    self.embedding_network = embedding_network #We would like to freeze these embeddings\n",
        "    self.num_classes = num_classes\n",
        "    self.nonlinear = nn.ReLU()\n",
        "    self.fc1 = nn.Linear(64, 64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, self.num_classes)\n",
        "    # Freeze the weights of this network\n",
        "    \"\"\" This attempt is to first allow classification network to train\"\"\"\n",
        "    for param in self.embedding_network.fc.parameters():\n",
        "           param.requires_grad = False\n",
        "    \n",
        "  \n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.embedding_network.fc(x)\n",
        "    x = self.fc1(self.nonlinear(x))\n",
        "    x = self.fc2(self.nonlinear(x))\n",
        "    x = self.fc3(self.nonlinear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgCvK3yUUVlw",
        "colab_type": "text"
      },
      "source": [
        "### Dummy dataset generation for training the FC and softmax layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX8B_3GoT9c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to define a specific dataloader in this case, which shall be frankly, quite simple and dummy\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class SoftmaxDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, select_column):\n",
        "         \n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.train_labels = self.dataset.labels_encoded\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "        self.dataset = self.dataset.drop('labels_encoded', axis=1)\n",
        "        self.train_data = self.dataset\n",
        "        self.select_column = select_column\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        #print(type(self.train_data))\n",
        "        selected_frame, label = self.train_data.iloc[index], self.train_labels.iloc[index]\n",
        "        str_data = selected_frame[self.select_column]\n",
        "\n",
        "        return str_data, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy6Nq9ZnlJPc",
        "colab_type": "text"
      },
      "source": [
        "## overfit on a smaller dataset but only for initial evaluation. Ignore later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irnA5T-T_TVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "miniature_data_train = data_train[:10000]\n",
        "miniature_data_test = data_test[:500]\n",
        "# Change the next cell with the correct values\n",
        "batch_size = 10\n",
        "num_epochs=30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V7jVh1KkoEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "softmax_train_dataset = SoftmaxDataset(dataset=miniature_data_train,select_column='sentence_embedding')\n",
        "softmax_test_dataset = SoftmaxDataset(dataset=miniature_data_test,select_column='sentence_embedding')\n",
        "# Now the dataloaders need to be defined as well\n",
        "classification_train_loader = DataLoader(softmax_train_dataset, batch_size=batch_size,shuffle=True)\n",
        "classification_test_loader = DataLoader(softmax_test_dataset, batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT4YawdSkoA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36fc3668-5c56-485e-cf94-9b30ff509d6a"
      },
      "source": [
        "len(data_train)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBeET4QrnUzg",
        "colab_type": "text"
      },
      "source": [
        "##Actual data loader for the model that we plan to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC0nL-sYSOcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global declarations\n",
        "num_classes=23\n",
        "num_epochs = 40\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1d19029c-3358-4681-facd-a99fe7aae504",
        "id": "MjSwcL7J0zZm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Load a pre-existing model \n",
        "PATH = '/content/5-model.pth'\n",
        "model = TripletNetwork()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.cuda()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TripletNetwork(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.6)\n",
              "    (8): Linear(in_features=256, out_features=64, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzXYFUDYRZtZ",
        "colab_type": "code",
        "outputId": "96c89536-45a4-48e1-f7af-408eaf3336a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "num_classes = 23\n",
        "net = ClassificationNet(embedding_network=model, num_classes=num_classes)\n",
        "net.cuda()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationNet(\n",
              "  (embedding_network): TripletNetwork(\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Dropout(p=0.5)\n",
              "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (6): ReLU()\n",
              "      (7): Dropout(p=0.6)\n",
              "      (8): Linear(in_features=256, out_features=64, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (nonlinear): ReLU()\n",
              "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=23, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4kYkHpsRaoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptV1nJq2YM4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "softmax_train_dataset = SoftmaxDataset(dataset=data_train,select_column='sentence_embedding')\n",
        "softmax_test_dataset = SoftmaxDataset(dataset=data_test,select_column='sentence_embedding')\n",
        "# Now the dataloaders need to be defined as well\n",
        "classification_train_loader = DataLoader(softmax_train_dataset, batch_size=batch_size,shuffle=True)\n",
        "classification_test_loader = DataLoader(softmax_test_dataset, batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bg6zVkhzbess",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "a0fe644d-a301-4874-9a1b-70e14149a345"
      },
      "source": [
        "import datetime\n",
        "from tensorflow import summary\n",
        "%load_ext tensorboard\n",
        "current_time = str(datetime.datetime.now().timestamp())\n",
        "train_log_dir = '/content/logs/tensorboard/train/classifier/' + current_time\n",
        "test_log_dir = '/content/logs/tensorboard/test/classifier/' + current_time\n",
        "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard module is not an IPython extension.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-f8d4886f6a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_log_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/logs/tensorboard/train/classifier/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_log_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/logs/tensorboard/test/classifier/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_summary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_log_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_summary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_log_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dw_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accessing local variables before they are created.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[1;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.summary' has no attribute 'create_file_writer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXkjJP4dQ0m1",
        "colab_type": "code",
        "outputId": "914a9972-7d9a-4a10-d690-a460d6199e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1311
        }
      },
      "source": [
        "# Next we need to train this network in order to learn the weights of the fc layer and cross entropy weights\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(classification_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        #reshape the input to align\n",
        "        batch_size = inputs.shape[0]\n",
        "        inputs = inputs.reshape(batch_size,-1)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Write the scalars\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).cpu().sum().item()\n",
        "    print(\"loss is {}\".format(running_loss/total))   \n",
        "    print('Accuracy of the network on the train samples: {} '.format((100 * correct / total)))\n",
        "#     with train_summary_writer.as_default():\n",
        "#        summary.scalar('accuracy', 100 * correct / total, step=epoch)\n",
        "#        summary.scalar('loss', running_loss / total, step=epoch)\n",
        "    # Now this is the section for testing the model in the same epoch\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_val = 0\n",
        "    with torch.no_grad():\n",
        "        for data in classification_test_loader:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.cuda()\n",
        "            batch_size = inputs.shape[0]\n",
        "            inputs = inputs.reshape(batch_size,-1)\n",
        "            # Next the evaluation\n",
        "            outputs = net(inputs)\n",
        "            labels = labels.cuda()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_val = loss_val + loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).cpu().sum().item()\n",
        "            \n",
        "#     with test_summary_writer.as_default():\n",
        "#         summary.scalar('accuracy', 100 * correct / total, step=epoch)\n",
        "#         summary.scalar('loss', loss_val / total, step=epoch)\n",
        "\n",
        "    print('Accuracy of the network on the test samples: %d %%' % (\n",
        "        100 * correct / total))\n",
        "    print(\"loss validation set is {}\".format(loss_val/total)) \n",
        "    torch.save(net.state_dict(), '/content/{}-classifier.pth'.format(epoch))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss is 0.014489773709303547\n",
            "Accuracy of the network on the train samples: 54.62127462101681 \n",
            "Accuracy of the network on the test samples: 55 %\n",
            "loss validation set is 0.01393008095045071\n",
            "loss is 0.013745051500071222\n",
            "Accuracy of the network on the train samples: 56.437558007631225 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013835222155971357\n",
            "loss is 0.01368317836287637\n",
            "Accuracy of the network on the train samples: 56.83136537073322 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013697030913821198\n",
            "loss is 0.013637078862387186\n",
            "Accuracy of the network on the train samples: 56.91708775910075 \n",
            "Accuracy of the network on the test samples: 57 %\n",
            "loss validation set is 0.013637336212064085\n",
            "loss is 0.013622913992124033\n",
            "Accuracy of the network on the train samples: 56.88550582654429 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013766390978644604\n",
            "loss is 0.013612702436652198\n",
            "Accuracy of the network on the train samples: 56.98025162421367 \n",
            "Accuracy of the network on the test samples: 57 %\n",
            "loss validation set is 0.013646355817167246\n",
            "loss is 0.013596631238494224\n",
            "Accuracy of the network on the train samples: 57.0337475507889 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013717220049488603\n",
            "loss is 0.013619771872068837\n",
            "Accuracy of the network on the train samples: 57.00667732288336 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013671805262504146\n",
            "loss is 0.013597506995580731\n",
            "Accuracy of the network on the train samples: 56.92546663916675 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013661267496918211\n",
            "loss is 0.013567494490677836\n",
            "Accuracy of the network on the train samples: 57.118825409920596 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013670702653409673\n",
            "loss is 0.013583861527672696\n",
            "Accuracy of the network on the train samples: 57.03181396308136 \n",
            "Accuracy of the network on the test samples: 57 %\n",
            "loss validation set is 0.013561844761204176\n",
            "loss is 0.01354439933507224\n",
            "Accuracy of the network on the train samples: 57.10786841291121 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013596208987192259\n",
            "loss is 0.013537425371120305\n",
            "Accuracy of the network on the train samples: 57.17425492420336 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013694577648232275\n",
            "loss is 0.013547515467990977\n",
            "Accuracy of the network on the train samples: 57.1091574713829 \n",
            "Accuracy of the network on the test samples: 56 %\n",
            "loss validation set is 0.013587130840825115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-ed740016d454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-c474277d6a85>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(type(self.train_data))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mselected_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mstr_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2859\u001b[0m                                                       \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2860\u001b[0m                                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2861\u001b[0;31m                                                       dtype=new_values.dtype)\n\u001b[0m\u001b[1;32m   2862\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 262\u001b[0;31m                                       raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    570\u001b[0m                         \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;31m# don't coerce Index types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, take_fast_path, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    702\u001b[0m                                        isinstance(subarr, np.ndarray))):\n\u001b[1;32m    703\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_extension_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             subarr = construct_1d_ndarray_preserving_na(subarr, dtype,\n\u001b[1;32m    706\u001b[0m                                                         copy=copy)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_type\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \"\"\"\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \"\"\"\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCCategorical\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         if isinstance(dtype, (ABCSeries, ABCIndexClass,\n\u001b[0;32m--> 101\u001b[0;31m                               ABCDataFrame, np.dtype)):\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_typ'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCnOhz2Yg3T6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "ea093cc3-103d-44e6-d0d2-956340992657"
      },
      "source": [
        "# First load the best model based on the classification scenario above\n",
        "net = ClassificationNet(embedding_network=model, num_classes=num_classes)\n",
        "PATH = '/content/5-classifier.pth'\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "net.cuda()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationNet(\n",
              "  (embedding_network): TripletNetwork(\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Dropout(p=0.5)\n",
              "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (6): ReLU()\n",
              "      (7): Dropout(p=0.6)\n",
              "      (8): Linear(in_features=256, out_features=64, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (nonlinear): ReLU()\n",
              "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=23, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsGspogEg3dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Still not ready. Please refer to the KNN part for now\n",
        "all_labels = []\n",
        "all_predictions=[]\n",
        "with torch.no_grad():\n",
        "        for data in classification_test_loader:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.cuda()\n",
        "            batch_size = inputs.shape[0]\n",
        "            inputs = inputs.reshape(batch_size,-1)\n",
        "            # Next the evaluation\n",
        "            outputs = net(inputs)\n",
        "            labels = labels.cuda()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_val = loss_val + loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            for idx in range(batch_size):\n",
        "                all_predictions.append(predicted[idx].item())\n",
        "                all_labels.append(labels[idx].item())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IOcTdmFInnH",
        "colab": {}
      },
      "source": [
        "labels = list(set(data_train.labels_encoded))\n",
        "cm = confusion_matrix(all_labels, all_predictions, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "364b8ff8-0260-483b-e624-40bb8363e08e",
        "id": "JClpBpSJK-sD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + get_all_labels())\n",
        "ax.set_yticklabels([''] + get_all_labels())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAEQCAYAAAAOHFvbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFMDNpbbrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ba5ffa04-cc26-4fed-efba-a6d6c159d446",
        "id": "83WzcFdcK-sJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt     \n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=False, ax = ax, fmt='g', cmap='Greens'); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels([''] + get_all_labels());\n",
        "ax.yaxis.set_ticklabels([''] + get_all_labels());"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAGeCAYAAABrfpGJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmcwYkQf1TCaTGSP+P47cptYTFduBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2daa71f5-d1d6-4a6c-bbd5-ec92750332a2",
        "id": "sTu_7QLyK-sN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "print(classification_report(all_labels, all_predictions,labels=labels, target_names=get_all_labels()))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             precision    recall  f1-score   support\n",
            "\n",
            "      Amazon Instant Videos       0.57      0.70      0.63      1615\n",
            "               Android Apps       0.66      0.72      0.69      1611\n",
            "                 Automotive       0.40      0.49      0.44      1672\n",
            "                       Baby       0.63      0.69      0.66      1548\n",
            "                     Beauty       0.65      0.63      0.64      1604\n",
            "              CDs and Vinyl       0.47      0.42      0.44      1508\n",
            "Cell Phones and Accessories       0.50      0.53      0.51      1572\n",
            "   Clothing, Shoes, Jewelry       0.64      0.70      0.67      1579\n",
            "              Digital Music       0.70      0.74      0.72      1604\n",
            "                Electronics       0.36      0.33      0.34      1587\n",
            "        Grocery and Gourmet       0.68      0.74      0.71      1585\n",
            "   Health and Personal Care       0.30      0.26      0.28      1619\n",
            "           Home and Kitchen       0.46      0.44      0.45      1627\n",
            "                     Kindle       0.81      0.80      0.81      1577\n",
            "              Movies and TV       0.59      0.53      0.56      1639\n",
            "        Musical Instruments       0.58      0.53      0.55      1643\n",
            "            Office Products       0.71      0.68      0.69      3222\n",
            "               Patio Garden       0.46      0.47      0.47      1642\n",
            "               Pet Supplies       0.62      0.62      0.62      1960\n",
            "           Sports, Outdoors       0.26      0.24      0.25      1580\n",
            "  Tool and Home Improvement       0.36      0.27      0.31      1596\n",
            "             Toys_and_Games       0.63      0.70      0.66      1608\n",
            "                Video Games       0.79      0.76      0.78      1590\n",
            "\n",
            "                   accuracy                           0.57     38788\n",
            "                  macro avg       0.56      0.56      0.56     38788\n",
            "               weighted avg       0.56      0.57      0.57     38788\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jElqeitX7QCQ",
        "colab_type": "text"
      },
      "source": [
        "# Finally here we try and implement the 1-Nearest classification process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2klJSDDVUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c1bf6c2f-9edc-4a43-c26c-5df99ce0b0a6"
      },
      "source": [
        "# Load a pre-existing model \n",
        "PATH = '/content/5-model.pth'\n",
        "model = TripletNetwork()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.cuda()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TripletNetwork(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.6)\n",
              "    (8): Linear(in_features=256, out_features=64, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y4ChZ6L85qA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First of all, our model shall be the one we trained for embeddings in the \n",
        "# 60 dimensional space using Triplet loss. So,\n",
        "embedding_model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y07EHij5G7TR",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 100\n",
        "softmax_train_dataset = SoftmaxDataset(dataset=data_train,select_column='sentence_embedding')\n",
        "softmax_test_dataset = SoftmaxDataset(dataset=data_test,select_column='sentence_embedding')\n",
        "# Now the dataloaders need to be defined as well\n",
        "classification_train_loader = DataLoader(softmax_train_dataset, batch_size=batch_size,shuffle=True)\n",
        "classification_test_loader = DataLoader(softmax_test_dataset, batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxkf2Kad8iTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us save the embedding of all elements in the train_data as well as their index\n",
        "# this can be used later for our purpose\n",
        "embedding_space = []\n",
        "for i, data in enumerate(classification_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda()\n",
        "        batch_size = inputs.shape[0]\n",
        "        inputs = inputs.reshape(batch_size,-1)\n",
        "        labels = labels.cuda()\n",
        "        embeddings = embedding_model.fc(inputs)\n",
        "        for index,tensor in enumerate(embeddings):\n",
        "           embedding_space.append((labels[index],tensor))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vrATUP_LQ_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec6fc16b-d76b-47cc-be67-14c581ff5f24"
      },
      "source": [
        "dist = [space for index,space in embedding_space[:-1]]\n",
        "result = torch.stack(dist, dim=0)\n",
        "result.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([155151, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN3wtiUuLRHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "def k_nearest_neighbour(distance_embeddings, vector, k=3):   \n",
        "    updated_result = torch.norm((distance_embeddings - vector),p=2,dim=1)\n",
        "    values, indices = torch.topk(updated_result,k=k ,largest=False)\n",
        "    candidate_indexes = []\n",
        "    for index in indices:\n",
        "      candidate_indexes.append((embedding_space[index][0]).item())\n",
        "    return Counter(candidate_indexes).most_common(1)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMlN9hFQ_pdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86e49872-e454-4c87-b555-eec6b9994e8d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "all_labels = []\n",
        "all_predictions=[]\n",
        "for data in classification_test_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.cuda()\n",
        "    batch_size = inputs.shape[0]\n",
        "    inputs = inputs.reshape(batch_size,-1)\n",
        "    # Next the evaluation\n",
        "    \n",
        "    output = embedding_model.fc(inputs)\n",
        "    for idx,query in enumerate(output):\n",
        "        predicted = k_nearest_neighbour(result, query, 1)\n",
        "        all_predictions.append(predicted)\n",
        "        correct += (predicted == labels[idx])\n",
        "        all_labels.append(labels[idx].item())\n",
        "    total += labels.size(0)\n",
        "    correct = correct.cpu().sum()\n",
        "print('Accuracy of the network on the test samples: %d %%' % (\n",
        "        100 * correct /total))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test samples: 45 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6dTNg9X_C5P",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating the Micro and Macro F1 scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMYjLzYq_CFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score, confusion_matrix, classification_report\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUVFVx9_B_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5bcb856-7102-4c97-f6c5-d3f3994db6ea"
      },
      "source": [
        "f1_score(all_labels, all_predictions, average='micro') "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44565329483345373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Qw9O4BBu1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "825d9e04-6268-4ef0-c8e3-194fd7d242a8"
      },
      "source": [
        "f1_score(all_labels, all_predictions, average='macro') "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4401489228289628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_tN-b-SBLPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = list(set(data_train.labels_encoded))\n",
        "cm = confusion_matrix(all_labels, all_predictions, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYrGlrsnDJiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8f010d79-acc9-4150-98a1-33be3f886917"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + get_all_labels())\n",
        "ax.set_yticklabels([''] + get_all_labels())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAEQCAYAAAAOHFvbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPM+snHPO1bz/H6jqi/6jR5hhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Qt2zWlEhnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "503424e1-aaaf-45c0-bc6f-1bd95bda8325"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt     \n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=False, ax = ax, fmt='g', cmap='Greens'); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels([''] + get_all_labels());\n",
        "ax.yaxis.set_ticklabels([''] + get_all_labels());"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAGeCAYAAABrfpGJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBKJ9BBxUI9EIpEe4v8DOPh0Gs2alREAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZvX13V9A4bZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7364534c-161b-4874-dbf6-398eac540700"
      },
      "source": [
        "accuracy_score(all_labels, all_predictions)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4456532948334537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SbT8LFAGBM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "8b083568-e971-4591-d4f1-6ffee1f784e8"
      },
      "source": [
        "print(classification_report(all_labels, all_predictions,labels=labels, target_names=get_all_labels()))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             precision    recall  f1-score   support\n",
            "\n",
            "      Amazon Instant Videos       0.48      0.47      0.48      1615\n",
            "               Android Apps       0.59      0.59      0.59      1611\n",
            "                 Automotive       0.29      0.26      0.27      1672\n",
            "                       Baby       0.53      0.54      0.53      1548\n",
            "                     Beauty       0.50      0.51      0.50      1604\n",
            "              CDs and Vinyl       0.34      0.36      0.35      1508\n",
            "Cell Phones and Accessories       0.38      0.39      0.39      1572\n",
            "   Clothing, Shoes, Jewelry       0.55      0.54      0.54      1579\n",
            "              Digital Music       0.60      0.60      0.60      1604\n",
            "                Electronics       0.24      0.24      0.24      1587\n",
            "        Grocery and Gourmet       0.59      0.59      0.59      1585\n",
            "   Health and Personal Care       0.17      0.17      0.17      1619\n",
            "           Home and Kitchen       0.32      0.32      0.32      1627\n",
            "                     Kindle       0.73      0.73      0.73      1577\n",
            "              Movies and TV       0.43      0.44      0.43      1639\n",
            "        Musical Instruments       0.44      0.43      0.43      1643\n",
            "            Office Products       0.57      0.57      0.57      3222\n",
            "               Patio Garden       0.33      0.32      0.32      1642\n",
            "               Pet Supplies       0.50      0.50      0.50      1960\n",
            "           Sports, Outdoors       0.12      0.12      0.12      1580\n",
            "  Tool and Home Improvement       0.20      0.20      0.20      1596\n",
            "             Toys_and_Games       0.54      0.55      0.55      1608\n",
            "                Video Games       0.68      0.69      0.69      1590\n",
            "\n",
            "                   accuracy                           0.45     38788\n",
            "                  macro avg       0.44      0.44      0.44     38788\n",
            "               weighted avg       0.45      0.45      0.45     38788\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}