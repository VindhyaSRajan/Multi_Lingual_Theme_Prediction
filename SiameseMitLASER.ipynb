{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiameseMitLASER",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmay5/NLP-Praktikum/blob/development/SiameseMitLASER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sScywYm8EJhe",
        "colab_type": "code",
        "outputId": "90429e47-7bae-41dc-f3f2-df0ed4dc93cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqSjJNruoa8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUcKCcufznUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')\n",
        "# %cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bENmrfgZLusD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install torch==1.0.1 -f https://download.pytorch.org/whl/cu100/stable # CUDA 10.0 build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFppkR1CAEg4",
        "colab_type": "code",
        "outputId": "a5db8c1e-b1ab-4019-da44-ee3a1aa510db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip3 install torchvision\n",
        "!pip install nltk\n",
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkVYLPcL3iTA",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SphmC-tGZeLP",
        "colab_type": "text"
      },
      "source": [
        "Code for preprocessing the text and other cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTXhvxZHXRIL",
        "colab_type": "text"
      },
      "source": [
        "Setting up of the Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jACju1PFOBXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1s2hwjaWi_g",
        "colab_type": "text"
      },
      "source": [
        "Include Torch vision in here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6BpPi7aWctf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_path = os.path.join(config['result']['filepath'], config['result']['filename'])\n",
        "result.to_csv(res_path,header=False,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3FwhbOyhwHA",
        "colab_type": "text"
      },
      "source": [
        "##Extra Section that will come in handy later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wUDuuzC3knQ",
        "colab_type": "text"
      },
      "source": [
        "# This is an attempt to include the LASER multi lingual embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mngRKDEg3x2h",
        "colab_type": "code",
        "outputId": "70f57436-9d69-4ede-ab3a-1846aa0614e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/ceshine/LASER.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LASER'...\n",
            "remote: Enumerating objects: 504, done.\u001b[K\n",
            "remote: Total 504 (delta 0), reused 0 (delta 0), pack-reused 504\u001b[K\n",
            "Receiving objects: 100% (504/504), 2.56 MiB | 17.36 MiB/s, done.\n",
            "Resolving deltas: 100% (130/130), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_8LAr8c6Wyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -rf \\\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Akm1QeP4lea",
        "colab_type": "code",
        "outputId": "41d4fd00-0803-4dba-caef-02d0ac3d1a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%env LASER=/content/LASER\n",
        "!echo $LASER\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: LASER=/content/LASER\n",
            "/content/LASER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo67QGwc7m7F",
        "colab_type": "code",
        "outputId": "e7796ee4-fc5b-47d2-81ff-c015ea9805c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxeDCC74lhZ",
        "colab_type": "code",
        "outputId": "47684d84-92d2-42b6-ff4d-cbb7c584ef2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd LASER"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjFh5jFf4lmg",
        "colab_type": "code",
        "outputId": "34d390f0-ef84-4a2c-e4e1-66aa72d0c40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ADRwFZ4lp8",
        "colab_type": "code",
        "outputId": "51eedbef-7969-4fe8-bf98-770a50fe4f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!bash install_models.sh"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading networks\n",
            " - creating directory /content/LASER/models\n",
            " - bilstm.eparl21.2018-11-19.pt\n",
            " - eparl21.fcodes\n",
            " - eparl21.fvocab\n",
            " - bilstm.93langs.2018-12-26.pt\n",
            " - 93langs.fcodes\n",
            " - 93langs.fvocab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5F_sNpe4lkm",
        "colab_type": "code",
        "outputId": "c673241c-e407-42cb-f84b-cd3c3972076b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "source": [
        "!bash install_external_tools.sh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing external tools\n",
            " - creating directory /content/LASER/tools-external/moses-tokenizer/tokenizer\n",
            " - download tokenizer/tokenizer.perl\n",
            " - download tokenizer/detokenizer.perl\n",
            " - download tokenizer/normalize-punctuation.perl\n",
            " - download tokenizer/remove-non-printing-char.perl\n",
            " - download tokenizer/deescape-special-chars.perl\n",
            " - download tokenizer/lowercase.perl\n",
            " - download tokenizer/basic-protected-patterns\n",
            " - creating directory /content/LASER/tools-external/moses-tokenizer/share/nonbreaking_prefixes\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ca\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.cs\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.de\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.el\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.en\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.es\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.fi\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.fr\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ga\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.hu\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.is\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.it\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.lt\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.lv\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.nl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.pl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.pt\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ro\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ru\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sk\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sl\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.sv\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.ta\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.yue\n",
            " - download share/nonbreaking_prefixes/nonbreaking_prefix.zh\n",
            " - download fastBPE software from github\n",
            "--2019-06-02 16:12:43--  https://github.com/glample/fastBPE/archive/master.zip\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/glample/fastBPE/zip/master [following]\n",
            "--2019-06-02 16:12:43--  https://codeload.github.com/glample/fastBPE/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.253.121\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.253.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [ <=>                ]   8.88K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-06-02 16:12:43 (584 KB/s) - ‘master.zip’ saved [9091]\n",
            "\n",
            "Archive:  master.zip\n",
            "87eeb4dc5dd1542c2346d18b35aad6942bd04c6f\n",
            "   creating: fastBPE-master/\n",
            "  inflating: fastBPE-master/LICENSE  \n",
            "  inflating: fastBPE-master/README.md  \n",
            "   creating: fastBPE-master/fastBPE/\n",
            "  inflating: fastBPE-master/fastBPE/fastBPE.hpp  \n",
            "  inflating: fastBPE-master/fastBPE/fastBPE.pyx  \n",
            "  inflating: fastBPE-master/fastBPE/main.cc  \n",
            "  inflating: fastBPE-master/setup.py  \n",
            " - compiling\n",
            "\u001b[01m\u001b[Kg++:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kfast.cc: No such file or directory\n",
            "\u001b[01m\u001b[Kg++:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kno input files\n",
            "compilation terminated.\n",
            "ERROR: compilation failed, please install manually\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq9RVwqi8pyM",
        "colab_type": "code",
        "outputId": "a20d45f9-0cdc-442c-ffca-53ed064c889d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd tools-external/fastBPE/\n",
        "! g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER/tools-external/fastBPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpraUBs38jZO",
        "colab_type": "code",
        "outputId": "b1c3db4f-c697-45a5-e656-23d1bcd2a966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd ../../tasks/similarity/\n",
        "! ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LASER/tasks/similarity\n",
            "README.md  wmt.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVjP99krE02v",
        "colab_type": "code",
        "outputId": "3e09775a-0dde-47a6-86a1-38de555fef4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "! apt install libopenblas-base libomp-dev"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-base is already the newest version (0.2.20+ds-4).\n",
            "libopenblas-base set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 1s (334 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 130911 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdgEtRK5AN9g",
        "colab_type": "code",
        "outputId": "10bf95e3-223d-4520-a7a1-b7fd66d4fb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "! pip install faiss"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faiss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/1c/4ae6cb87cf0c09c25561ea48db11e25713b25c580909902a92c090b377c0/faiss-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from faiss) (1.16.4)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBPIo9wj9GSg",
        "colab_type": "code",
        "outputId": "da85c89e-005c-462d-b014-e772215f20a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "% cd ./tasks/similarity\n",
        "! bash wmt.sh"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: './tasks/similarity'\n",
            "/content/LASER/tasks/similarity\n",
            " - Download WMT data\n",
            "LASER: similarity search\n",
            "\n",
            "Processing:\n",
            " - loading encoder /content/LASER/models/bilstm.93langs.2018-12-26.pt\n",
            " - creating directory embed\n",
            " - Tokenizer: newstest2012.cs in language cs  \n",
            " - fast BPE: processing newstest2012.tok.cs\n",
            " - Encoder: newstest2012.bpe.cs to newstest2012.enc.cs\n",
            " - Encoder: 3003 sentences in 3s\n",
            " - embedding: ./embed/newstest2012.enc.cs 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            " - Tokenizer: newstest2012.de in language de  \n",
            " - fast BPE: processing newstest2012.tok.de\n",
            " - Encoder: newstest2012.bpe.de to newstest2012.enc.de\n",
            " - Encoder: 3003 sentences in 2s\n",
            " - embedding: ./embed/newstest2012.enc.de 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            " - Tokenizer: newstest2012.en in language en  \n",
            " - fast BPE: processing newstest2012.tok.en\n",
            " - Encoder: newstest2012.bpe.en to newstest2012.enc.en\n",
            " - Encoder: 3003 sentences in 2s\n",
            " - embedding: ./embed/newstest2012.enc.en 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            " - Tokenizer: newstest2012.es in language es  \n",
            " - fast BPE: processing newstest2012.tok.es\n",
            " - Encoder: newstest2012.bpe.es to newstest2012.enc.es\n",
            " - Encoder: 3003 sentences in 2s\n",
            " - embedding: ./embed/newstest2012.enc.es 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            " - Tokenizer: newstest2012.fr in language fr  \n",
            " - fast BPE: processing newstest2012.tok.fr\n",
            " - Encoder: newstest2012.bpe.fr to newstest2012.enc.fr\n",
            " - Encoder: 3003 sentences in 2s\n",
            " - embedding: ./embed/newstest2012.enc.fr 3003 examples of dim 1024\n",
            " - creating FAISS index\n",
            "Confusion matrix:\n",
            "langs   cs       de       en       es       fr       avg     \n",
            "cs     0.00%    0.70%    0.90%    0.67%    0.77%    0.76%\n",
            "de     0.83%    0.00%    1.17%    0.93%    1.03%    0.99%\n",
            "en     0.93%    1.27%    0.00%    0.83%    1.07%    1.02%\n",
            "es     0.53%    0.77%    0.97%    0.00%    0.57%    0.71%\n",
            "fr     0.50%    0.90%    1.13%    0.60%    0.00%    0.78%\n",
            "avg    0.70%    0.91%    1.04%    0.76%    0.86%    1.07%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sS0FP2kG-cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample feasibility check\n",
        "# % cd ../../source/\n",
        "\n",
        "import os\n",
        "import sys\n",
        "LASER = os.environ['LASER']\n",
        "# now include the extra files in the source\n",
        "sys.path.append(LASER + '/source')\n",
        "sys.path.append(LASER + '/source/lib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39VFH-l3G-l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from embed import SentenceEncoder, EncodeLoad, EncodeFile\n",
        "from text_processing import Token, BPEfastApply\n",
        "from indexing import IndexCreate, IndexSearchMultiple, IndexPrintConfusionMatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLAqI6hNbCtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tnCKLFUbC2s",
        "colab_type": "code",
        "outputId": "c198f42d-f3af-4d5c-b311-e5b2f88516c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/LASER/tasks/similarity'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKRw4tSWb1jW",
        "colab_type": "text"
      },
      "source": [
        "## These are the steps to replicate results of the LSTM file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvPCpy5Ucnaa",
        "colab_type": "code",
        "outputId": "6d51fced-ab10-468a-a5c0-70f7628d5b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN4E6iNobC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# Training data\n",
        "train_en_sp = pd.read_csv('cikm_english_train_20180516.txt', sep='\t', header=None, error_bad_lines=False)\n",
        "train_sp_en = pd.read_csv('cikm_spanish_train_20180516.txt', sep='\t', header=None, error_bad_lines=False)\n",
        "\n",
        "train_en_sp.columns = ['english1', 'spanish1', 'english2', 'spanish2', 'result']\n",
        "train_sp_en.columns = ['spanish3', 'english3', 'spanish4', 'english4', 'result']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0n9Wyq-bCyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sp_sp = pd.read_csv('cikm_test_a_20180516.txt', sep='\t', header=None, error_bad_lines=False)\n",
        "test_sp_sp.columns = ['spanish5', 'spanish6']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERcXRM7_cIUM",
        "colab_type": "code",
        "outputId": "a9736d83-58b1-4ed0-83d0-5a238450440c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_en = pd.DataFrame(pd.concat([train_en_sp['english1'], train_en_sp['english2'], \n",
        "                                   train_sp_en['english3'], train_sp_en['english4']], axis=0))\n",
        "all_en.columns = ['english']\n",
        "all_en = all_en.reset_index()\n",
        "all_en = all_en.drop(columns='index')\n",
        "print(all_en.shape)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42800, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96vcmA5bcIcR",
        "colab_type": "code",
        "outputId": "58f03360-a896-4fe4-955d-55b52839d18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_sp = pd.DataFrame(pd.concat([train_en_sp['spanish1'], train_en_sp['spanish2'], train_sp_en['spanish3'], \n",
        "                                   train_sp_en['spanish4'],test_sp_sp['spanish5'], test_sp_sp['spanish6']], axis=0))\n",
        "all_sp.columns = ['spanish']\n",
        "all_sp = all_sp.reset_index()\n",
        "all_sp = all_sp.drop(columns='index')\n",
        "print(all_sp.shape)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(52800, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMN7XNdxdlG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us go ahead and save these files so that they can be used later by the Tokennization process\n",
        "import csv\n",
        "all_en.to_csv('all_en.txt',header=None, index=None, sep=' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTVFwYk_cIZ6",
        "colab_type": "code",
        "outputId": "f93ff74b-04b5-4b7b-92fb-d0c4a3925cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Many of the LASER components are already in the path so we can directly use them then\n",
        "from text_processing import Token\n",
        "Token(os.path.join('all_en.txt'),\n",
        "          'all_en.tok',\n",
        "          lang='en',\n",
        "          romanize= False,\n",
        "          lower_case=True,\n",
        "          verbose=True, over_write=False)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Tokenizer: all_en.txt in language en  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHVv21bCcIXf",
        "colab_type": "code",
        "outputId": "a99e993e-d865-422b-ca5c-72563d98cfff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from text_processing import BPEfastApply\n",
        "\n",
        "BPEfastApply('all_en.tok',     \n",
        "            'all_en.bpe',\n",
        "             './LASER/models/93langs.fcodes',\n",
        "              verbose=True, over_write=False)\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - fast BPE: processing all_en.tok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3ZY3F5ZbCwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = '/content/LASER/models/'\n",
        "sentence_encoder = SentenceEncoder(\n",
        "    str(MODEL_PATH + \"bilstm.93langs.2018-12-26.pt\"),\n",
        "    max_sentences=None,\n",
        "    max_tokens=10000,\n",
        "    cpu=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP9GvdEQEhSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class Siamese_nlp(nn.Module):\n",
        "    def __init__(self,  encoder, fc_dim, num_classes=1): # binary classification so 0/1 shall work\n",
        "        super(Siamese_nlp, self).__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.fc_dim = fc_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.encoder.hidden_size = 1024 # This is fixed for the LASER encoder by construction\n",
        "        \n",
        "        \n",
        "        self.input_dim = 2  * self.encoder.hidden_size # since we concatinate the two sentences together\n",
        "  \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, int(self.input_dim/2)),\n",
        "            nn.Linear(int(self.input_dim/2), self.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, s1, s2):\n",
        "        \n",
        "        encoded_sentence_1 = self.encoder.encode_sentences(sentences = s1)\n",
        "        encoded_sentence_2 = self.encoder.encode_sentences(sentences = s2)\n",
        "        \n",
        "        # utilize these two encoded vectors\n",
        "        features = torch.cat((torch.from_numpy(encoded_sentence_1),torch.from_numpy(encoded_sentence_2)), dim=0)\n",
        "        # features = v1-v2\n",
        "        features = features.cuda()\n",
        "        #print(\"size of the feature is {}\".format(features.shape))\n",
        "        features = features.reshape(-1)\n",
        "        output = self.classifier(features)\n",
        "        #print(\"One successful run\")\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhUfdh4YPift",
        "colab_type": "code",
        "outputId": "14e1e05d-9bcc-4b5a-a40b-b757f9a488f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# model\n",
        "siamese = Siamese_nlp(encoder=sentence_encoder, fc_dim=100) #fc_dim value is arbitary here\n",
        "siamese.cuda()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Siamese_nlp(\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (1): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqaw0k_sMuV-",
        "colab_type": "text"
      },
      "source": [
        "## Generate the Spanish sentences on which we shall train and evaluate our system\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ6dFNYhMttK",
        "colab_type": "code",
        "outputId": "0e1ce44a-2552-4433-cd25-fa4400500f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "df_train_en_sp = pd.read_csv('./cikm_english_train_20180516.txt', sep='\t', header=None,\n",
        "                                 error_bad_lines=False)\n",
        "df_train_sp_en = pd.read_csv('./cikm_spanish_train_20180516.txt', sep='\t', header=None,\n",
        "                             error_bad_lines=False)\n",
        "df_train_en_sp.columns = ['english1', 'spanish1', 'english2', 'spanish2', 'result']\n",
        "df_train_sp_en.columns = ['spanish1', 'english1', 'spanish2', 'english2', 'result']\n",
        "train1 = pd.DataFrame(pd.concat([df_train_en_sp['spanish1'], df_train_sp_en['spanish1']], axis=0))\n",
        "train2 = pd.DataFrame(pd.concat([df_train_en_sp['spanish2'], df_train_sp_en['spanish2']], axis=0))\n",
        "train_data = pd.concat([train1, train2], axis=1).reset_index()\n",
        "train_data = train_data.drop(['index'], axis=1)\n",
        "result = pd.DataFrame(pd.concat([df_train_en_sp['result'], df_train_sp_en['result']], axis=0)).reset_index()\n",
        "result = result.drop(['index'], axis=1)\n",
        "# pd.get_dummies(result['result']).head()\n",
        "train_data['result'] = result\n",
        "\n",
        "# Evaluation data\n",
        "test_data = pd.read_csv('./cikm_test_a_20180516.txt', sep='\t', header=None, error_bad_lines=False)\n",
        "test_data.columns = ['spanish1', 'spanish2']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_data.replace('', np.nan, inplace=True)\n",
        "dirty_data = train_data[train_data.isnull().any(axis=1)]\n",
        "\n",
        "train_data = train_data.dropna()\n",
        "test_data.replace('', np.nan, inplace=True)\n",
        "test_data = test_data.dropna()\n",
        "print ('Train sample count:', train_data.shape[0], 'Test sample count:', test_data.shape[0])\n",
        "\n",
        "train_data.columns = ['s1', 's2', 'label']\n",
        "test_data.columns = ['s1', 's2']\n",
        "\n",
        "train_data.to_csv(\"spanish_train.csv\", index=False)\n",
        "test_data.to_csv(\"spanish_test.csv\", index=False)\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train sample count: 21400 Test sample count: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkqGHlSkMtot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BhJMYBGEhO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class myDS_train(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        # Assign vocabularies.\n",
        "        self.s1 = df['s1']\n",
        "        self.s2 = df['s2']\n",
        "        self.label = df['label'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence_1 = self.s1.iloc[idx]\n",
        "        sentence_2 = self.s2.iloc[idx]\n",
        "        label = float(self.label[idx])\n",
        "\n",
        "        return sentence_1, sentence_2, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inqgccItDK62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myDS_test(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        # Assign vocabularies.\n",
        "        self.s1 = df['s1']\n",
        "        self.s2 = df['s2']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.s1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Split sentence into words.\n",
        "        sentence_1 = self.s1.iloc[idx]\n",
        "        sentence_2 = self.s2.iloc[idx]\n",
        "        \n",
        "        return sentence_1, sentence_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG03Ab3dMsj7",
        "colab_type": "code",
        "outputId": "2c7732fe-86c2-49b8-e420-c8853fa0c4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\"\"\" Read Data \"\"\"\n",
        "\n",
        "train_data = pd.read_csv('spanish_train.csv', sep=',')\n",
        "test_data = pd.read_csv('spanish_test.csv', sep=',')\n",
        "\n",
        "# split dataset\n",
        "msk = np.random.rand(len(train_data)) < 0.8\n",
        "train = train_data[msk]\n",
        "valid = train_data[~msk]\n",
        "\n",
        "# dataset\n",
        "trainDS = myDS_train(train)\n",
        "validDS = myDS_train(valid) # Since this is still labeled data that we have\n",
        "\n",
        "print ('Data size:',train_data.shape[0], test_data.shape[0])"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size: 21400 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV7MIs173AJG",
        "colab_type": "code",
        "outputId": "52e825f9-ee7d-4be5-ddac-756fb52e1e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Quickly check if csv file has everything in place\n",
        "train_data.head()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hola, hago clic en el producto recibido</td>\n",
              "      <td>Compré un producto y no he recibido un correo ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>¡Hola! Cerré la disputa el 21 de mayo de 2017 ...</td>\n",
              "      <td>No obtuve el reembolso de mi dinero. Han pasad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ordené de España a España ahora que mandan el ...</td>\n",
              "      <td>Mi pedido llegó pero el color es diferente al ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¿Debo pagar impuestos personalizados?</td>\n",
              "      <td>Cómo pagar los derechos de aduana</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No recibí mi pedido?</td>\n",
              "      <td>Mi pedido muestra que no he pagado, pero lo hice</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  s1  ... label\n",
              "0            hola, hago clic en el producto recibido  ...     0\n",
              "1  ¡Hola! Cerré la disputa el 21 de mayo de 2017 ...  ...     0\n",
              "2  Ordené de España a España ahora que mandan el ...  ...     0\n",
              "3              ¿Debo pagar impuestos personalizados?  ...     1\n",
              "4                               No recibí mi pedido?  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yA5D8Ki3ANY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1daa9d86-a387-4364-c5d9-8672423cf21b"
      },
      "source": [
        "len(train_data['s1'].iloc[0]) ==  len(train_data['s2'].iloc[0])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxB0qkjO3AG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5l-FZdh3ABw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA3D3dwoO0gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "import torch\n",
        "def create_optimizer(optimizer_type, network=siamese, learning_rate = 1e-3):\n",
        "    optimizer = None\n",
        "    if optimizer_type == 'sgd':\n",
        "        optimizer = torch.optim.SGD(filter(lambda x: x.requires_grad, network.parameters()), lr=learning_rate)\n",
        "    elif optimizer_type == 'adam':\n",
        "        optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, network.parameters()), lr=learning_rate)\n",
        "    elif optimizer_type == 'adadelta':\n",
        "        optimizer = torch.optim.Adadelta(filter(lambda x: x.requires_grad, network.parameters()), lr=learning_rate)\n",
        "    elif optimizer_type == 'rmsprop':\n",
        "        optimizer = torch.optim.RMSprop(filter(lambda x: x.requires_grad, network.parameters()), lr=learning_rate)\n",
        "    return optimizer    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g01ex4oXSyFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = create_optimizer(optimizer_type='adam', network=siamese, learning_rate=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4oKrtovR3NS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss func\n",
        "from torch.autograd import Variable\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUvD9wlbR3K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# log info\n",
        "train_log_string = '%s :: Epoch %i :: Iter %i / %i :: train loss: %0.4f'\n",
        "valid_log_string = '%s :: Epoch %i :: valid loss: %0.4f\\n'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRhz4FqYTjBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 40\n",
        "ckpt_path = '/content/sample.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH6PTZ2yR3Hb",
        "colab_type": "code",
        "outputId": "b07b7cf4-57b9-4bf0-c38c-445822880a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "# save every epoch for visualization\n",
        "train_loss_record = []\n",
        "valid_loss_record = []\n",
        "best_record = 10.0\n",
        "\n",
        "# training\n",
        "print ('Experiment: Siamese_lstm take 01 \\n')\n",
        "\n",
        "    \n",
        "for epoch in range(num_epochs):\n",
        "    print ('Start Epoch{} Training...'.format(epoch))\n",
        "\n",
        "    # loss\n",
        "    train_loss = []\n",
        "    train_loss_sum = []\n",
        "    # dataloader\n",
        "    train_dataloader = DataLoader(dataset=trainDS, shuffle=True, num_workers=2, batch_size=1)\n",
        "\n",
        "    siamese.train() #set it in the training mode\n",
        "    \n",
        "    for idx, data in enumerate(train_dataloader, 0):\n",
        "\n",
        "        # get data\n",
        "        s1, s2, label = data\n",
        "        # putting the data into cuda\n",
        "        #s1 = torch.from_numpy(np.array(s1))\n",
        "        #s2 = torch.from_numpy(np.array(s2))\n",
        "        label = torch.tensor(label.data, dtype=torch.float)\n",
        "#         s1 = s1.cuda()\n",
        "#         s2 = s2.cuda()\n",
        "        label = label.cuda()\n",
        "        \n",
        "        # clear gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        \n",
        "        # input\n",
        "        output = siamese(s1, s2)\n",
        "        #print(output)\n",
        "        #output = output.squeeze(0)\n",
        "        # Obtain the maximum index now\n",
        "        #logit = torch.max(output) # First index is the value and the second is the location of occurance of maximum\n",
        "        #samp = logit.cpu().numpy()\n",
        "        #output_list.append(samp)\n",
        "        #output = torch.from_numpy(np.asarray(output_list))\n",
        "        \n",
        "        #output = output.cuda()\n",
        "        # Get the shape of output and label just to check\n",
        "        \n",
        "\n",
        "        # loss backward\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.data.cpu())\n",
        "        train_loss_sum.append(loss.data.cpu())\n",
        "\n",
        "        # Every once and a while check on the loss\n",
        "        if ((idx + 1) % 5000) == 0:\n",
        "            print(train_log_string % (datetime.now(), epoch, idx + 1, len(train), np.mean(train_loss)))\n",
        "            train_loss = []\n",
        "\n",
        "    # Record at every epoch\n",
        "    print ('Train Loss at epoch{}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
        "    train_loss_record.append(np.mean(train_loss_sum))\n",
        "\n",
        "    # Valid\n",
        "    print ('Epoch{} Validating...'.format(epoch))\n",
        "\n",
        "    # loss\n",
        "\n",
        "    \n",
        "    valid_loss = []\n",
        "    # dataloader\n",
        "    valid_dataloader = DataLoader(dataset=validDS, shuffle=True, num_workers=2, batch_size=1)\n",
        "    \n",
        "    siamese.eval() # putting the model in evaluation mode\n",
        "\n",
        "    for idx, data in enumerate(valid_dataloader, 0):\n",
        "        # get data\n",
        "        s1, s2, label = data\n",
        "\n",
        "        # putting the data into cuda\n",
        "        #s1 = torch.from_numpy(np.array(s1))\n",
        "        #s2 = torch.from_numpy(np.array(s2))\n",
        "        label = torch.tensor(label.data, dtype=torch.float)\n",
        "        #print(\"something something meri jaan, tell me something meri jaan\")\n",
        "#         s1 = s1.cuda()\n",
        "#         s2 = s2.cuda()\n",
        "        label = label.cuda()\n",
        "        \n",
        "        # input\n",
        "        output = siamese(s1, s2)\n",
        "        #output = output.squeeze(0)\n",
        "        # To get the maximum index from this output as the prediction of the network\n",
        "        #output = torch.max(output)[1] # First index is the value and the second is the location of occurance of maximum\n",
        "        \n",
        "        # loss\n",
        "        loss = criterion(output, label)\n",
        "        valid_loss.append(loss.data.cpu())\n",
        "        \n",
        "\n",
        "    print(valid_log_string % (datetime.now(), epoch, np.mean(valid_loss)))\n",
        "    # Record\n",
        "    valid_loss_record.append(np.mean(valid_loss))\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "    # Keep track of best record\n",
        "    if np.mean(valid_loss) < best_record:\n",
        "        best_record = np.mean(valid_loss)\n",
        "        # save the best model\n",
        "        state_dict = {\n",
        "            'epoch': epoch,\n",
        "            'siamese': siamese.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }\n",
        "        torch.save(state_dict, ckpt_path)\n",
        "        print ('Model saved!\\n')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment: Siamese_lstm take 01 \n",
            "\n",
            "Start Epoch0 Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-a6b862966096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#output = output.squeeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-0ef6b172a4f3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s1, s2)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mencoded_sentence_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mencoded_sentence_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# utilize these two encoded vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LASER/source/embed.py\u001b[0m in \u001b[0;36mencode_sentences\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_kind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LASER/source/embed.py\u001b[0m in \u001b[0;36m_process_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentemb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LASER/source/embed.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_tokens, src_lengths)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mpacked_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_cells\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# unpack outputs and apply dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_packed\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n\u001b[0;32m--> 525\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLr0qFou-6tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(train_loss_record)\n",
        "plt.plot(valid_loss_record)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruvk-1IkDK2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN_y2Bf5bCqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG19Q85QYMGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbbKc9g4YMEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1g8DqAbYL_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBYzPcejcJnC",
        "colab_type": "text"
      },
      "source": [
        "## This is the code section for trying Triplet Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP-YgYTWcQWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class TripletDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, training_mode=True):\n",
        "         \n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.train = training_mode\n",
        "\n",
        "        if self.train:\n",
        "            self.train_labels = self.dataset.label\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "            self.dataset = self.dataset.drop('label', axis=1)\n",
        "            self.train_data = self.dataset\n",
        "            self.labels_set = set(self.train_labels.to_numpy())\n",
        "            self.label_to_indices = {label: np.where(self.train_labels.to_numpy() == label)[0]\n",
        "                                     for label in self.labels_set} # redundent in our case if we decide to use numeric labels based on certain sklearn packages\n",
        "\n",
        "        else:\n",
        "            self.test_labels = self.dataset.label\n",
        "            # Drop the labels column so that remaining features form part of the training set\n",
        "            self.dataset = self.dataset.drop('label', axis=1)\n",
        "            self.test_data = self.dataset\n",
        "            # generate fixed triplets for testing\n",
        "            self.labels_set = set(self.test_labels.to_numpy())\n",
        "            self.label_to_indices = {label: np.where(self.test_labels.to_numpy() == label)[0]\n",
        "                                     for label in self.labels_set}\n",
        "\n",
        "            random_state = np.random.RandomState(29)\n",
        "\n",
        "            triplets = [[i,\n",
        "                         random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
        "                         random_state.choice(self.label_to_indices[\n",
        "                                                 np.random.choice(\n",
        "                                                     list(self.labels_set - set([self.test_labels[i].item()]))\n",
        "                                                 )\n",
        "                                             ])\n",
        "                         ]\n",
        "                        for i in range(len(self.test_data))]\n",
        "            self.test_triplets = triplets\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            #print(type(self.train_data))\n",
        "            img1, label1 = self.train_data.iloc[index], self.train_labels.iloc[index]\n",
        "            positive_index = index\n",
        "            while positive_index == index:\n",
        "                positive_index = np.random.choice(self.label_to_indices[label1])\n",
        "            negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
        "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
        "            img2 = self.train_data.iloc[positive_index]\n",
        "            img3 = self.train_data.iloc[negative_index]\n",
        "        else:\n",
        "            img1 = self.test_data.iloc[self.test_triplets[index][0]]\n",
        "            img2 = self.test_data.iloc[self.test_triplets[index][1]]\n",
        "            img3 = self.test_data.iloc[self.test_triplets[index][2]]\n",
        "\n",
        "        img1 = img1['reviews.text']\n",
        "        img2 = img2['reviews.text']\n",
        "        img3 = img3['reviews.text']\n",
        "        #print(img1)\n",
        "        #print(img2)\n",
        "        #print(img3)\n",
        "\n",
        "        return (img1, img2, img3)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzVaHR7VcQlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "input_data = pd.read_csv('review.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ9OuN6fnEjE",
        "colab_type": "code",
        "outputId": "6a82a6dc-196d-4a43-d292-f762720877e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "input_data.columns"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'dateAdded', 'dateUpdated', 'name', 'asins', 'brand',\n",
              "       'categories', 'primaryCategories', 'imageURLs', 'keys', 'manufacturer',\n",
              "       'manufacturerNumber', 'reviews.date', 'reviews.dateAdded',\n",
              "       'reviews.dateSeen', 'reviews.doRecommend', 'reviews.id',\n",
              "       'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs',\n",
              "       'reviews.text', 'reviews.title', 'reviews.username', 'sourceURLs'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImQg2ouIupGA",
        "colab_type": "code",
        "outputId": "5c9fec21-c09b-43e5-92c3-542bffa5f8d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "input_data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateAdded</th>\n",
              "      <th>dateUpdated</th>\n",
              "      <th>name</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primaryCategories</th>\n",
              "      <th>imageURLs</th>\n",
              "      <th>keys</th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>manufacturerNumber</th>\n",
              "      <th>reviews.date</th>\n",
              "      <th>reviews.dateAdded</th>\n",
              "      <th>reviews.dateSeen</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.numHelpful</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.sourceURLs</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>sourceURLs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2017-09-03T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-27T00:00:00Z,2017-09-18T00:00:00Z,2017...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5442403/review...</td>\n",
              "      <td>I thought it would be as big as small paper bu...</td>\n",
              "      <td>Too small</td>\n",
              "      <td>llyyue</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2017-06-06T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-27T00:00:00Z,2017-07-07T00:00:00Z,2017...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5442403/review...</td>\n",
              "      <td>This kindle is light and easy to use especiall...</td>\n",
              "      <td>Great light reader. Easy to use at the beach</td>\n",
              "      <td>Charmi</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2018-04-20T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-27T00:00:00Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>https://reviews.bestbuy.com/3545/5442403/revie...</td>\n",
              "      <td>Didnt know how much i'd use a kindle so went f...</td>\n",
              "      <td>Great for the price</td>\n",
              "      <td>johnnyjojojo</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2017-11-02T17:33:31.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-10-09T00:00:00Z</td>\n",
              "      <td>True</td>\n",
              "      <td>177283626.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
              "      <td>I am 100 happy with my purchase. I caught it o...</td>\n",
              "      <td>A Great Buy</td>\n",
              "      <td>Kdperry</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2018-04-24T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-27T00:00:00Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>https://reviews.bestbuy.com/3545/5442403/revie...</td>\n",
              "      <td>Solid entry level Kindle. Great for kids. Gift...</td>\n",
              "      <td>Solid entry-level Kindle. Great for kids</td>\n",
              "      <td>Johnnyblack</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ...                                         sourceURLs\n",
              "0  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "1  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "2  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "3  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "4  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY_gevdXu8ZV",
        "colab_type": "text"
      },
      "source": [
        "### We would use review.text as the input and use it to predict review.primaryCategories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfzKSTw5vMvP",
        "colab_type": "code",
        "outputId": "4f23a24a-1d6f-4d3d-8666-4a46ce9539ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "input_data.primaryCategories.describe()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count            5000\n",
              "unique              4\n",
              "top       Electronics\n",
              "freq             3276\n",
              "Name: primaryCategories, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbUHtUzLl-T1",
        "colab_type": "code",
        "outputId": "073fec7d-240b-4faa-b03f-53e963f2d12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "input_data = input_data.rename(columns={'primaryCategories':'label'})\n",
        "input_data.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateAdded</th>\n",
              "      <th>dateUpdated</th>\n",
              "      <th>name</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>label</th>\n",
              "      <th>imageURLs</th>\n",
              "      <th>keys</th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>manufacturerNumber</th>\n",
              "      <th>reviews.date</th>\n",
              "      <th>reviews.dateAdded</th>\n",
              "      <th>reviews.dateSeen</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.numHelpful</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.sourceURLs</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>sourceURLs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2017-09-03T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-27T00:00:00Z,2017-09-18T00:00:00Z,2017...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5442403/review...</td>\n",
              "      <td>I thought it would be as big as small paper bu...</td>\n",
              "      <td>Too small</td>\n",
              "      <td>llyyue</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2017-06-06T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-27T00:00:00Z,2017-07-07T00:00:00Z,2017...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5442403/review...</td>\n",
              "      <td>This kindle is light and easy to use especiall...</td>\n",
              "      <td>Great light reader. Easy to use at the beach</td>\n",
              "      <td>Charmi</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2018-04-20T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-27T00:00:00Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>https://reviews.bestbuy.com/3545/5442403/revie...</td>\n",
              "      <td>Didnt know how much i'd use a kindle so went f...</td>\n",
              "      <td>Great for the price</td>\n",
              "      <td>johnnyjojojo</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2017-11-02T17:33:31.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-10-09T00:00:00Z</td>\n",
              "      <td>True</td>\n",
              "      <td>177283626.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
              "      <td>I am 100 happy with my purchase. I caught it o...</td>\n",
              "      <td>A Great Buy</td>\n",
              "      <td>Kdperry</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>2017-03-03T16:56:05Z</td>\n",
              "      <td>2018-10-25T16:36:31Z</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Computers,Electronics Features,Tablets,Electro...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://pisces.bbystatic.com/image2/BestBuy_US...</td>\n",
              "      <td>allnewkindleereaderblack6glarefreetouchscreend...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B00ZV9PXP2</td>\n",
              "      <td>2018-04-24T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-27T00:00:00Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>https://reviews.bestbuy.com/3545/5442403/revie...</td>\n",
              "      <td>Solid entry level Kindle. Great for kids. Gift...</td>\n",
              "      <td>Solid entry-level Kindle. Great for kids</td>\n",
              "      <td>Johnnyblack</td>\n",
              "      <td>https://www.newegg.com/Product/Product.aspx%25...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ...                                         sourceURLs\n",
              "0  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "1  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "2  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "3  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "4  AVqVGZNvQMlgsOJE6eUY  ...  https://www.newegg.com/Product/Product.aspx%25...\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikgRo75cfgU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 5\n",
        "siamese_train_dataset = TripletDataset(training_mode=True,dataset=input_data)\n",
        "\n",
        "loader = DataLoader(siamese_train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddasqFvxh5QG",
        "colab_type": "code",
        "outputId": "2f5f4859-122c-4ba0-9fe0-77fdd05dfdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "for index, (img1,img2,img3) in enumerate(loader):\n",
        "  print (img1)\n",
        "  print(img2)\n",
        "  print(img3)\n",
        "  break\n",
        "  "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Love this tablet for streaming, facebook, games and general web surfing. The apps are available on the amazon underground, not google playstore, so some apps that you may be used to using, may not be available on amazon underground. Overall, great tablet for the price. Would recommend.', \"It's a good starter tablet, to bad it runs on the Amazon OS.\", \"I bought this tablet for my son. He damaged the previous one but it was good for his purpose. He loves to play the Minecraft app and can read a book with ease. I don't have a tablet for myself. If I did, I would get the Fire. All I would really need it for would be to surf the Web and use the apps. For the price, u can't go wrong.\", 'This is one of the best products we have every purchased. Plays any songs, give directions, weather and the sound quality is EXCELLENT!', \"I bought this for my daughter. It's a little limited in what it can do, but she loves it. She's a little too young to understand the games, but she loves watching cartoons on it.\")\n",
            "('For the price the tablet can not be beat. I use this over my ipads that i have. There is nothing i cant do with this tablet', 'I bought this item as a gift for a relative in her mid teens and so far no complaints.', 'Works very well. Cheaper than an iPad and works great for apps and video.', 'nice item, and cute. the tablet is difficult to navigate', 'We like the battery endurance. The new 8\" screen is great too.')\n",
            "('Used it and looks very paper like. They integrated the simplest form of an e reader, which makes it stand out for its use.', 'The new Kindle is a great gift and fantastic entertainment idea.', 'Great size, easy to use and it has a sleek look that is attractive.', 'Gift for a relative they said they loved the gift.', 'Having a great experience using the Alexa Echo plus product.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faPNpMFclPpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df5OaEQT02wa",
        "colab_type": "text"
      },
      "source": [
        "# The Code here is to try and implement the online Batch Sampling Selection Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcikqQjD092u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import BatchSampler\n",
        "\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "    \"\"\"\n",
        "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
        "    Returns batches of size n_classes * n_samples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, labels, n_classes, n_samples):\n",
        "        self.labels = labels\n",
        "        self.labels_set = list(set(self.labels.to_numpy()))\n",
        "        self.label_to_indices = {label: np.where(self.labels.to_numpy() == label)[0]\n",
        "                                 for label in self.labels_set}\n",
        "        for l in self.labels_set:\n",
        "            np.random.shuffle(self.label_to_indices[l])\n",
        "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
        "        self.count = 0\n",
        "        self.n_classes = n_classes\n",
        "        self.n_samples = n_samples\n",
        "        self.n_dataset = len(self.labels)\n",
        "        self.batch_size = self.n_samples * self.n_classes\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.count = 0\n",
        "        while self.count + self.batch_size < self.n_dataset:\n",
        "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
        "            indices = []\n",
        "            for class_ in classes:\n",
        "                indices.extend(self.label_to_indices[class_][\n",
        "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
        "                                                                         class_] + self.n_samples])\n",
        "                self.used_label_indices_count[class_] += self.n_samples\n",
        "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
        "                    np.random.shuffle(self.label_to_indices[class_])\n",
        "                    self.used_label_indices_count[class_] = 0\n",
        "            yield indices\n",
        "            self.count += self.n_classes * self.n_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_dataset // self.batch_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ljIvSqt3YiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll create mini batches by sampling labels that will be present in the mini batch and number of examples from each class\n",
        "train_batch_sampler = BalancedBatchSampler(input_data.label, n_classes=4, n_samples=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZOD7HvJ3zKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "siamese_train_dataset = TripletDataset(training_mode=True,dataset=input_data)\n",
        "online_train_loader = DataLoader(siamese_train_dataset, batch_sampler=train_batch_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrDgswhZ4HNv",
        "colab_type": "code",
        "outputId": "d4cb0fdf-7a2f-4413-c575-5716590a1946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "for index, (img1,img2,img3) in enumerate(online_train_loader):\n",
        "  print (img1)\n",
        "  print(img2)\n",
        "  print(img3)\n",
        "  break"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('This kindle allows me to download several books. It easily fits in a purse and is light weight', \"The Kindle is great for reading on the go when I can't carry around a lot of books.\", \"OK, I was so unsure of this Kindle because it does not have all of the bells and whistles of the others. BUT I am very happy with it. I love my Kindle! I have managed to read a book a week on it sicnce I got if for Christmas. I have been reading the free books on Kindle. There are so many to pick from. While home, I download the books that I want to read and then while I am in the car or waiting at the DMV, I just pull of the book and read. It remembers where I am in the book. This Kindle does not have the back light. I was nervous about that but so far this has not been a problem because the light it has is fine for me. When I am reading in the car, I enlarge the font and it makes seeing the words easier for me. That is the most important factor for me because I can get car sick if I read while riding in the car but with the larger font I don't have that problem. I wear glasses with bifocals and holding this seems to be more comfortable than a book because I can hold it up if I need to. The size is perfect! Again, I can enlarge the font so the smaller screen size really has nothing to do with the readability. Love it!!\", 'Easy to use wide variety of functions awesome price', 'Love how user friendly the Kindle Fire is, for any age..', 'Got this on sale for a great price and is a great product.', 'Small & without audio but easy to use. Able to connect to Amazon account & Goodreads account easily. The only thing I hate is that I have to keep restarting it if I want to get out of a ebook that I‚Äôm currently reading', 'Fought it for a long time, but Kindle is awesome. The newer version with adjustable light is best for me.', 'makes reading easier and more enjoyable in that I can see a whole page at one time. The protective cover that Best Buy sell was a disappointment in that it covered the On/Off switch and did not hold the tablet very well so that I had to find another cover from another source.', 'I purchased this as a replacement for my older Kindle. It is excellent as always but I also noticed very little new features or updates since my last Kindle model. Would have liked some more design, form factor, or feature changes. That being said, it fits the bill and is amazingly light, so I have no other complaints.', \"My wife loves to read, but she was always hesitant to try ebooks. She used to think that ebooks could never have the same tactile feel as a physical book. I talked her into it by telling her its lighter, easier to hold, can hold thousands of books and if she hated it we can return it. But she loves ebooks now and doesnt want to go back. She also found out that Amazon has a lot of books which cost nothing, namely classics and such...I think. If you like to read in the dark then get the paperwhite version. The LED's are a nice touch.\", 'I love this product it is so easy to use It has a clear picture', \"Didnt know how much i'd use a kindle so went for the lower end. im happy with it, even if its a little dark\", 'I like this ereader. It is a little small, but you can increase the font.', \"I originally got the lower end Kindle, took it back and upgraded. The light really is a must. I can't believe how much more I'm reading now that I have it, and there are TONS of free books out there if you know where to look. Best. Purchase. EVER.\", 'Love my kindle fire, takes awesome pictures and its convenient for on the go.', \"I purchased this Kindle for my wife because her Kindle Fire gives off too much glare to use in sunny conditions. Besides being able to use it while riding in the car during daytime, the biggest advantage she found is that it is significantly lighter than the Fire. Since she reads for hours on end that is a big plus. The main drawback is that the graphics aren't as clear with this reader. All in all, it was money well spent.\", 'I bought this Tablet for my Wife. She uses it every day. It is very usefulto her. She uses it in place of a computer. She watches movies on it.The Graphics are excellent.', \"For books games and internet it's perfectSound is a ittle weak\", 'love the big screen, clear pictures and fast loading. battery lasts long. I use it every day !', 'Good features and quality. Would be nice if it worked better in low light. Should have stepped up for the backlit one. This is nice if your conditions are bright.', 'Excellent product very good piece strongly recommend', 'Had problem with cutting off device. Good easy read', 'I particularly like the fact that the text shows up and you can see it well outside on a sunny day. I use it with Kindle Unlimited.', 'Great table does everything that i need it for. Great resolution and screen for reading books', \"With a little tweaking you can install Playstore without rooting. It's a great tablet, excellent color, fast, and battery lasts a very long time.\", 'Small and easy to use for children when traveling.', 'My kids like it very much! The price is low. The tablet is light weighted.', 'Was gift fot my daughter. she seems to enjoy very much.', 'No instructions on adding the memory card and how to move things to the card vs on internally.', 'My other one last for two years. Than went out. My daughter loves it', 'I HAVE BOTH THE ECHO AND THE TAP, THEY ARE SPECTACULAR', 'Love love love my kindle fire. Had the original and then bought and iPad then bought this kindle and I am wondering why I even bought the iPad. Will not switch again. I will stick with my kindle.', \"My granddaughter loved her tablet and the color. It's amazing how easy it is for her to use, perfect birthday gift\", 'My 76 year old mom loves this! She now has something to do while waiting in doctors offices - loves to read, do crosswords, etc.', \"This is great tablet. Its great for people who don't need a lot of apts. or store a lot on it. Doesn't over heat. Light weight.\", \"It's a good tab for the kids, keeps them busy. Wish the speed was faster.\", \"I love my new Amazon Fire tablet it's great!! The perfect size to fit in my purse so that I can take it with me. I would definitely recommend to a friend.\", 'This is a pretty cool little device. Im able to download books through wireless and read them later at my convenience. Only drawback is I wish it had more storage. But for the price, it works good.', \"I reviewed a lot of tablets before I bought this one. It is the first one I have ever purchased. I am no tech geek and it was pretty easy to figure out how to use it. I mostly bought it for and use it for: reading e-mail, facebook, and browsing the internet. I really like it and use it more than my laptop. But, if I need to do anything detailed, I use my laptop. Overall it's a great tablet for a beginner, and you can't beat the price.\", 'Lighter weight than my old kindle fire. Easier to carry with me.', \"The Fire HD8 strikes an excellent balance between performance and price. It has many of the features you'd want in a tablet for a fraction of the cost. Works flawlessly for reading and video streaming.\", 'This is a cheap tablet but really worth for the price. I bought this when it is on sale for $69 + $40 for 128 GB SD card, you have a great tablet when plenty of space. I used ipad for a while but i think it is so overpriced . This tablet is a deal !!!', 'I enjoy taking photos with me and having enough videos to keep the kids entertained. On the fence go with the larger storage.', 'We replaced and aging fire HDX. She noticed the WiFi connection is improved and the screen is larger. She prefers this to my iPad Air', \"It's a perfect gift for young adult during the holiday session.\", 'Husband loves the 8\" tablet. The screen is big enough to view what he is reading', 'This was the first tablet we purchased for our kids and love it.', 'very easy to use I live my fire the best purchase I have made in months', 'Good tablet for basic needs. Screens resolution is pretty good. Mostly using for reading and sometimes for watching movies/shows. Great feature is the possibility to use the card to expand the memory. Good product for great price!', 'This Echo Show comes in handy. I use it almost as much as I thought I would. I am still learning all that it can do, but my favorite part is the screen. It‚Äôs not a huge deal, but if I could change one thing it would be a detachable power cable instead of hardwired.', 'I like how it has the screen but I do like the echo plus better. Both gets the job done', 'I. Like the visual with this echo although I think I would have enjoyed it more if this was my first and only alexa', 'The device works well mechanically, however, the software needs a lot of work. Half of my commands are not understood and I have cameras linked up to it that‚Äôs rarely recognized.', 'We use echo almost every day. It is fun to ask questions. The music is great. We check the weather and listen to NPRnews', 'A nice \"next step\" in the Alexa repertoire; easy to set up and to use.', 'I got this to work with my Arlo Pro camera, and it works well. I am able to have my camera for driveway and front door come up on command. I hate that I cannot get my Samsung TV to come on with a verbal request. I guess I will have to buy the plug for it. This was very easy to set up. Downloaded the app, and plugged it in, viola it walks you through the setup.', 'Works great! I bought 2, 1 for the kitchen and 1 for master bath.', 'My dad uses this as a speaker for the tv ...and loves it. He does use it in the traditional Alexa way...but the speaker option he discovered is an added benefit.', 'We love it! The whole family likes to ask questions.', \"I love all of my Amazon echo devices. Right now it doesn't allow YouTube, but hopefully they will reach an agreement and fix that.\", 'We purchased 3 of the Eco Plus and out two adult children really like their Eco Plus. They are having a lot of fun with it we are still learning', 'Very easy to set up! Easy to connect with multiple Amazon Echo Dots, as well as multiple smart home products.', 'Echo Plus is everything I expected and more. Plus easy to set up.', 'Love it . Easy to use. No problems setting it up!!!!', 'Long time Alexa user. The video screen just takes it to the next level great product', \"Purchased the Echo Plus and couldn't be more pleased. Easy to use.\", 'We are enjoying our amazon echo show. Alexa is so amazing answering questions and a variety of music!!!!', \"I've had an Amazon Echo and Dot for over a year now. I really wanted to develop the Smart Device usage around my house and when the upgraded Echo i just had to have it. It is a great device. I use the drop in feature to communicate with others in the house, especially when they are upstairs, without having to yell. The smart hub is amazing. Attaching to smart devices is much more seamless than with the 1st gen echo. Just got it so time will tell, but the 2nd gen Echo devices are worth it.\", \"I upgraded from Echo and have no regrets. I didn't liked design from day 1 but after mounting on the wall the screen looks good. I like it more then I except it. Much easier for reordering or shopping on Amazon.\", 'I was skeptical about the Amazon Echo products. Why would I need this? I bought the Echo Dot first and was hooked. Bought this Echo Plus for smart home integration. Since then, I have bought a bunch of smart bulbs and plan on more \"things\", I bought an Echo Spot, too. You do not need an Echo product, but they are fun, practical and cool. Can\\'t live without it now!', \"This is a helpful addition to the home. It's great to be able to set timers, play music, and check the news all hands free.\", 'Perfect start for smart home.works perfect with Echo', 'I love having this in my kitchen, it has replaced my ipad that i used to use.', 'Love it. It‚Äôs a lot of fun. Great speakers too provides a lot of great information and fun too!', 'The new design, compared to my old kindle paperwhite and voyage, looked weird when I first got my Kindle Oasis. After I used it for a while (5 hours), I felt the design was kind of make sense. When I hold it with one hand (right hand), the centre of gravity position was right in my hand, so there was less change that I drop the kindle on my face(when I was laying on my bed, it happened a lot with my kindle voyage)', \"I purchased this as a gift for my wife and she loves it. She has an older Kindle, and she can't believe how much better the Oasis is.\", 'Almost feels like reading a book in a light comforting way. Easy to carry around. Great on eyes and reading is enjoyable', \"I have had every kindle since the first and this is by far the best. The screen was already great on the Voyage but the front light on this screen is more white and more evenly distributed. Physical page turn buttons are so much better than none or the haptic feedback type. They didn't include the automatically adaptive front light for some reason but I don't think I'll miss it much as I was always wont to fiddle with it on the Voyage anyway.But this device made me smile as soon as I held it for the first time because it has a larger bezel that you can really grip comfortably without touching the screen. Maybe this isn't a big deal for most, but that is exactly why I spent the money to get this device.The other thing I was hoping for was the ability to use the upper page turn button to go forward and this device does that and even better because it is software configurable.The cover is very small and light and doesn't add much bulk like the Voyage Origami case does. The only downside is that it doesn't work as a hands free stand for reading.(I still wish it was waterproof)\", \"I got oasis yesterday, very lighweight compared to voyager, screen size comparable, like having actual page turn button, touchscreen seems kinda slow, the on/off button on top is improvement from back of voyager. cover does seem kind of flimsy, but supposed to be leather so will see how it holds up. finding it easier to hold with cover on, then removed. cover doesn't have separate charge port, so all charging is done thru kindle.\", \"Its a great ereader but a little pricy. It has the same specs as the Voyage as far as pixels and procesor, which costs less. The only difference between this and the Voyage, is that it's much lighter, it's brighter (LEDs), and a longer battery life if you're using the cover. I've noticed the battery life drains much faster without the cover, but you'll still be able to read for hours without it. You would think it be water resistant, hence the name but it isn't. But then I don't plan on reading when it's raining or outside or while taking a bath. Overall, it's the best ereader Amazon currently has to offer but if you don't mind the price tag and want the best, then go for it! Voyage is still not a bad option though\", 'Wife love it, reads a lot and this is her go to reader.', \"Small, light, but comfortable to hold with either hand. If you keep it in airplane mode with medium lighting, the battery last for weeks. Lovin' it so far.\", 'Even when I‚Äôm outside in bright sunlight, the words of the book I‚Äôm reading are still crystal clear. That alone makes the Kindle Oasis worth what it cost me.The Kindle Oasis wakes up in just seconds, and any book I choose instantly opens, ready to be read.It is the perfect size and isn‚Äôt heavy or bulky. I really do read for hours at a time. Sometimes I pace the floor while I read. Sometimes I‚Äôm on my elliptical machine when I read. And sometimes I‚Äôm sitting down. No matter what I‚Äôm doing, the Kindle Oasis remains comfortable to hold, and it is always easy on my eyes.When I receive a book that is in PDF, most of the time I can enlarge the words. If it won‚Äôt allow me to enlarge the words, I can change the orientation of the page and the words are automatically larger. I am able to make notes on the book if needed, and I can highlight words and/or passages.My merlot leather cover is attractive. When I flip it open, it is just like opening the cover of a book.How to Make the Battery LastOn the Kindle Oasis page, it says that its ‚Äúdual-battery charging system delivers months of battery life.‚Äù This was a huge thing for me. Instead of having to charge my tablet almost every day, I would be able to read for months without charging the Kindle!Is this how my Oasis has performed? Well, not so much. There are conditions that have to be met for the charge on your Oasis to last for two months.First, you have to limit your reading to thirty minutes a day. That one is impossible for me. There are days that I am only able to read for thirty minutes, but they don‚Äôt occur very often. My Kindle goes everywhere with me, and I use just about every spare moment to read.Second, the wireless needs to be turned off. That one is easy to do but not always easy to remember. The only time the wireless needs to be on is to download one or more books.Third, this is based on your light setting at 10. That is way too low for me. I keep my light setting anywhere from 16 to 18.I don‚Äôt limit my reading to thirty minutes a day, and I try to remember to keep my wireless turned off. My light setting is kept anywhere from 16 to 18, and I put my Kindle to sleep the second I‚Äôm done reading. So how long does a single charge last me? Ten days is the longest a charge has lasted me so far, but it would have kept a charge for several more days if I had remembered to turn my wireless off. Once I succeed in keeping my wireless off, I will let you know how long the charge lasts.Now, I don‚Äôt plug it in to charge as soon as the charge on the cover gets low. I allow my cover charge to go as low as it will possibly go and then the Kindle battery will start to drain since it can no longer charge from the cover. I allow it to drain down to about 50% before I plug the cover and Kindle into my computer to charge.The one thing that surprised me was that everything on the Oasis is in black and white. For some reason, I thought that maybe the book covers would appear in color. But since I bought the Oasis to read books on, color isn‚Äôt needed.Special offers do appear on my screen but only when my Kindle is going to sleep or waking up. They aren‚Äôt a distraction, and to be honest, they are kind of fun to look at. You can pay a higher price so they won‚Äôt appear on your Kindle if you would rather not see them.I asked myself some questions once I had my Kindle and knew just how it worked. If I had known before I bought my Kindle Oasis that the charge wouldn‚Äôt last for months, would I still have bought it? Yes, I would have. If I had known that everything would appear in black and white, would I still have bought it? Yes, I would have.', \"This kindle is awesome. I love the design of it. Nothing software wise that was different than my other kindle but the way it's designed makes it much more comfortable and easier to read. The only reason I didn't give it five stars was because of the price. If it were cheaper, this kindle would have been five stars no doubt.\", 'The new Kindle is a great gift and fantastic entertainment idea.', \"Got me reading again! Love the merlot cover. This one is the smallest of all the kindle products I believe, and that's a big reason I picked. Also the lightest I believe. Battery life is forever.Two negative points are the Amazon logo in the cover, and the fact you can't do inverted text (black background white text).Those 2 points dropped it from 4 to 5 star for me.Still highly recommended.\", 'I like this so much more than the Voyage. The shape makes for easier holding. I only wish this devise was maybe 2 inches taller then it would look like a real book', \"Replacing older reader without a light and traveling overseas soon. With electronics in the cabin under scrutiny, this very small and very lightweight reader fits the bill! Perfect in small purses and large pockets. I can read without annoying seatmate with cabin overhead seat light. Easy to hold in either hand and screen adjusts for whichever direction you're holding it.\", 'Kindles are an excellent device for all book lovers', 'I have used Kindle e-readers since Amazon introduced them years ago. All are good products and each new model has been a worthwhile upgrade. The Oasis is no exception, even from the highly touted Voyage model. It is expensive but the lightweight design, improved backlighting and battery cover are worth the additional expense for someone who reads frequently. This is definitely a good investment!', 'Bought for my wife to upgrade from the original Kindle that she has worn out. Big step up from the original and should be good for another 8-10 years.', \"When they first announced the Kindle Oasis, I did not have much of a desire to upgrade from my 1st generation Kindle Paperwhite. Just as I felt when they announced the Voyage.I read a lot, so my Kindle travels with me throughout the day most of the time. I have never had an issue with battery life, I have only had it get really low a few times (typically when I was traveling). So again, I originally did not see a lot of the value to the Oasis.As the reviews for the Oasis came out, I started to realize what I did not like about my Paperwhite, and I began to have an interest in upgrading my Paperwhite to the either the Oasis or possibly the Voyage. The main thing I noticed is that I took my Paperwhite out of the Amazon case quite a lot, especially when I was in a seated position. This slight reduction in weight made it much more comfortable to hold for longer reading sessions. I had some other minor issues with my Paperwhite, like when reading in the dark, I couldn't find an adjustment for the light that I preferred (5 was a little too dim and 6 was a brighter than I needed). I decided to pass on the Voyage because I really did not like the case options and the pressure sensitive page turn option.Now that I have the Oasis, I definitely think it was worth it for me. I really appreciate the reduced weight when the cover is off (not to mention the ease of removing the cover compared to the Paperwhite). It provides the same reading experience, although I did get a resolution upgrade compared to my older Paperwhite, which is a plus.The Oasis is really comfortable in my hand, which helps me forget that it is there. When I was holding my Paperwhite with my left hand, at times I would accidentally go back a page, which drove me crazy even though its just a minor inconvenience.I have the black model because it was the only option available unless I was willing to wait a few more months. The build quality of the Oasis and its case is very nice, just like with the Paperwhite and the amazon leather case for it. The only concern I have is how well it will protect the Kindle. I will update the review if I find this to be a problem.I loved my Paperwhite, and I will recommend it to anyone looking to upgrade from an older Kindle or buying one for the first time. It definitely is great and the better buy, but I am glad I decided to order the Oasis. The reduced weight, ergonomic design, and page turn buttons make it worth the added cost.\", \"This is my third Kindle. The best differentiator is the form factor. Definite improvement over the paperwhite. Also like having the page-turn buttons back. Case is very cool indeed. If you can get past the jump in price (remember you're not having to buy the case separately), it's a quality product to have.\", \"This is my 4th kindle and is easily the best one I've ever had. It is very comfortable to hold and is very compact. I was surprised how small it is but has the same screen size as my other kindles. It may look costly at first but remember you are getting a cover with additional battery.\", 'Easy to handle. Light weight. I like that it automatically shuts off when the cover is closed.', 'This is the best kindle ereader yet. The size and weight make it perfect for comfortable reading. You will find yourself reading more books than ever with it.', 'Very nice Kindle with a great Battery life. My old kindle was not able to upgrade so I got the new Kindle and very pleased with the product. Arrived as promised from BESTBUY.COM.', 'This is not an upgrade by any means! My three year old kindle outperformed Oasis.Battery life better than a week with the lights on lowest setting Magnetic connector is poorly designed and grows weak Two pieces to keep up with; unsnaps constantly Amazon Customer Services promises it will resolved in an update')\n",
            "('I bought this device for my wife. She has been using a Kindle Fire 7.I wanted something with a bigger screen for her.She likes it very much.', 'It is difficult to understand the instructions. I am still working on it.', 'I bought this device for my wife. She has been using a Kindle Fire 7.I wanted something with a bigger screen for her.She likes it very much.', 'Good e-reader, with an improved design, light-weight', 'UI is not smooth, it flickers sometimes. Overall a thumbs up from me', \"I liked my really old one a bit better. It broke after 5 years suddenly. The screen failed. I had to pay over 20 bucks extra to get rid of the ads to Amazon. I wasn't aware of this when I first bought so it was more expensive than expected.\", 'This is a great product and i would recommend it to anyone that enjoys reading.', \"I liked my really old one a bit better. It broke after 5 years suddenly. The screen failed. I had to pay over 20 bucks extra to get rid of the ads to Amazon. I wasn't aware of this when I first bought so it was more expensive than expected.\", 'Love the bigger screen but do think this Fire HD 10TH runs a little slow. My last Fire HD was not as slow.', 'I bought this device for my wife. She has been using a Kindle Fire 7.I wanted something with a bigger screen for her.She likes it very much.', 'This kindle has made life easier by adding the micro sd card slot to enhance the memory capacity up to 128gb more than it has built in, makes it easy to switch cards so you can have your whole library on hand without slowing down the overall processing capability', 'slower than my last kindle. the power button is not easy accesible when in a case.', 'Great table does everything that i need it for. Great resolution and screen for reading books', 'Used it and looks very paper like. They integrated the simplest form of an e reader, which makes it stand out for its use.', \"This Fire 10 is so much better than my old Kindle Fire HD that I now wonder why I waited so long to upgrade. The 10' display is awesome and the speed is very good. All the Amazon apps from my old Kindle were immediately loaded onto my new one and adding the others through the Kindle app store was quick and easy.\", \"Sales guy didn't have much knowledge about the Kindle. He wasn't very helpful in getting me started.\", 'I am reading positive reviews and wish I could say the same. Best Buy is great, so this is not a reflection on them, just our experience with the product. We have had this product for just over one month and I have had to contact Amazon Support, perform factory resets to get content to show up, and the device is poorly designed as the SD card pops out constantly, which messes with DRM, and does you no good if this happens when you are not connected to the Internet to fix it. We are returning, and spending the extra money for an iPad. Will not purchase another kindle device unfortunately just based on this experience. If you just use the device for reading, maybe this is for you, but trying to download information to SD card and actually being able to access it has been beyond frustrating, as well as having to do factory resets so content owned/ already purchased on Amazon would show up on the device in the library.', 'I had the 4th generation. I am quite happy with the upgrade. Good battery life', 'I bought this device for my wife. She has been using a Kindle Fire 7.I wanted something with a bigger screen for her.She likes it very much.', 'My gf loved it and uses it all the time. She gets books she wanted to follow up on', 'Love the tablet, not only for reading (upgrade from Kindle) but for searching the Internet, email, etc. And I can take it anywhere. Cheaper than an iPAD and does enough for what I need.', 'What is there to say, but that I love it. Functions well, and lasts a long time.', 'Tablet is easy to work with only can be slow to come up on certain sites', 'Wish it had its own onternet connection but other than that great purchase', 'I was very impressed with the functionality of my Amazon Echo. Very useful to have around the house and for the discounted price, it a steal!', 'I love that the tap is rechargeable and portable. Sounds is great! I highly recommend the tap!', \"I'm was so pleased with this tablet, I bought a second one for my father. We both love it.\", 'Great product for when you are on the go.great sound', 'My grandaughter is enjoying this tablet. I would recommend to all parents for their young kids.', 'I use my kindle on a daily basis. It is a good size for reading in bed.', 'Very nice tablet. Durable if dropped. My grand daughter loves it.', 'This tablet has a lot of features, it really makes it worth the money if you have an Amazon Prime account.', 'THe tablet with an added protective case has so far held up better than other tablets I have tried and the parental controls are great. I can also add educational apps that I want.', 'Great tablet! My son really likes it to read and also to play games!', 'Love my kindle! At the price it is the best value in tech right now!', 'I have two kids and they both love it. Its also nice because it is already setup for them.', 'This is a great tablet. Great for the price. Very fast and easy to use.', 'For the price the tablet can not be beat. I use this over my ipads that i have. There is nothing i cant do with this tablet', 'i have had not issues with my purchase. i found a great cover for it on line on amazon and use it every night. thank you for your service.', 'I am using it for my 3 year old and she loves it..', 'I especially like the Amazon has a system to convert pdf to kindle format. Some of the things I read (journal articles) are in pdf format and I can email them to my kindle email and it shows up on my kindle with kindle format (larger text). You can find your kindel email at your account information. Only thing, I would have like a screen little larger.', \"I am pleasantly surprised at how well this works. I bought the e reader and it didn't work so I was nervous buying this kindle. But it works great and my son loves it!\", 'Good and fast for kids does have very good control of parents on that', 'Replacement tablet for my wife - no complaints! She watches Netflix on it a lot.', 'I purchased two for my grandchildren. They carry the Kindle with them everywhere they go. Great purchase!', 'Too proprietary, the apps my daughter liked I could not install on it for her so basically it was worthless for me and I returned it.', 'Great quality, great price and best of all has good sound.', 'Fantastic tablet fire one is great. Small and portable', 'I had a Kindle Fire and upgraded to the 5th generation. Could not be more pleased with this tablet.', \"You get what you pay for Was not to happy but for a 3 year old it's ok\", 'I purchased this for my husbandHe had been waiting for it for a long timeHe owns Alexa and loved iti do too', 'I take 1 star off, because I had problems to syncing it with my W-FI.', \"I had been looking for the product for a while. After much research, I bought it and I am not disappointed. It is a great product. I can tell I won't be bored learning all that the echo show can do. If you're thinking about buying it, just go for it.\", 'Can use many differents apps from the Echo Show. Awesome product!', 'Alexa is great and even better with a screen to show you all your searches and videos', 'Great device for music and face time calls. The sound is crisp and clear. Many options with the Echo Show', 'The Alexa works well and turns my lights on and off for me in bed, and plays my playlist for when I sleep. Very nice for the bedroom.', 'Great Echo!! Friend really liked it!! It really does what he wants it to do and he connected his lights to the device. Everything works well.', 'Not going to lie - we haven‚Äôt even opened it yet. Planning on getting it all setup tomorrow night. I did see it at the store though & it was incredible', 'This Amazon Echo is very user friendly, and provides hours of entertainment, with anything from recipes, news, videos, and Amazon music with the lyrics is like having your own Karaoke.', 'Awesome product and cool design and a great color I would recommend to a friend', 'This is a great device when used with Ring camera and Hue lighting.', 'Very happy with amazon not hesitating to integrate their products with third party integration.‚ÄùCrestron', 'I think these products are great. I enjoy using them.', 'Worthless, except as a regular echo and a poor excuse for video chat. I love my echo devices, bathroom, pool, kitchen, other places where I may need hands free, voice activated music and info. My wife bought me the \\'newest, hottest\\' thing. I was skeptical but then thought I would use it to help on a project. Me \"Alexa find videos on f450 drone\" Alexa \"YouTube is not available\". Amazon won\\'t directly sell chrome products, youtube won\\'t play on echo show. Further testing shows the video call is more limited than iPhone or Android apps for video. So the most useful thing now is the same voice functions that my echos and dots perform. Unless I want to make all of my video calls and check the weather from a device I can move no more than 3 feet from an outlet.', 'Alexa does a lot of fun things but you must enable various apps. She gives funny answers to funny question. However, she is not a complete internet surfer, many things she has no answer.', \"alexa is awesome and screen makes her even better can't wait to get another\", 'I bought this for my finance.i bought it for Christmas he left bed it', 'Nice device. Good to enable drop in conversations. Some flash briefings. But overall still a little limited in effective use of video', 'We struggled with a surprise Christmas gift this year. The store sales rep suggested this and it was a hit!', 'I bought this device for my wife and she loves it. Plays videos for cooking. 1 on gift list. For sure.', 'The echo show works great for home automation. Being able to see your security cameras or drop in on your home through the echos camera are great features.', 'I love being able to use Alexa. She is an amazing AI. Until the robots rebel against the human kind I think it‚Äôs worth it.', 'I love my Alexa Show. It can answer most of my questions and I use it for recipes and listening to music. I use it everyday.', 'This is the best assistant from Amazon, with the completion of the screen you can also see images from cameras and other devices!Simply awesome!', 'Even when I‚Äôm outside in bright sunlight, the words of the book I‚Äôm reading are still crystal clear. That alone makes the Kindle Oasis worth what it cost me.The Kindle Oasis wakes up in just seconds, and any book I choose instantly opens, ready to be read.It is the perfect size and isn‚Äôt heavy or bulky. I really do read for hours at a time. Sometimes I pace the floor while I read. Sometimes I‚Äôm on my elliptical machine when I read. And sometimes I‚Äôm sitting down. No matter what I‚Äôm doing, the Kindle Oasis remains comfortable to hold, and it is always easy on my eyes.When I receive a book that is in PDF, most of the time I can enlarge the words. If it won‚Äôt allow me to enlarge the words, I can change the orientation of the page and the words are automatically larger. I am able to make notes on the book if needed, and I can highlight words and/or passages.My merlot leather cover is attractive. When I flip it open, it is just like opening the cover of a book.How to Make the Battery LastOn the Kindle Oasis page, it says that its ‚Äúdual-battery charging system delivers months of battery life.‚Äù This was a huge thing for me. Instead of having to charge my tablet almost every day, I would be able to read for months without charging the Kindle!Is this how my Oasis has performed? Well, not so much. There are conditions that have to be met for the charge on your Oasis to last for two months.First, you have to limit your reading to thirty minutes a day. That one is impossible for me. There are days that I am only able to read for thirty minutes, but they don‚Äôt occur very often. My Kindle goes everywhere with me, and I use just about every spare moment to read.Second, the wireless needs to be turned off. That one is easy to do but not always easy to remember. The only time the wireless needs to be on is to download one or more books.Third, this is based on your light setting at 10. That is way too low for me. I keep my light setting anywhere from 16 to 18.I don‚Äôt limit my reading to thirty minutes a day, and I try to remember to keep my wireless turned off. My light setting is kept anywhere from 16 to 18, and I put my Kindle to sleep the second I‚Äôm done reading. So how long does a single charge last me? Ten days is the longest a charge has lasted me so far, but it would have kept a charge for several more days if I had remembered to turn my wireless off. Once I succeed in keeping my wireless off, I will let you know how long the charge lasts.Now, I don‚Äôt plug it in to charge as soon as the charge on the cover gets low. I allow my cover charge to go as low as it will possibly go and then the Kindle battery will start to drain since it can no longer charge from the cover. I allow it to drain down to about 50% before I plug the cover and Kindle into my computer to charge.The one thing that surprised me was that everything on the Oasis is in black and white. For some reason, I thought that maybe the book covers would appear in color. But since I bought the Oasis to read books on, color isn‚Äôt needed.Special offers do appear on my screen but only when my Kindle is going to sleep or waking up. They aren‚Äôt a distraction, and to be honest, they are kind of fun to look at. You can pay a higher price so they won‚Äôt appear on your Kindle if you would rather not see them.I asked myself some questions once I had my Kindle and knew just how it worked. If I had known before I bought my Kindle Oasis that the charge wouldn‚Äôt last for months, would I still have bought it? Yes, I would have. If I had known that everything would appear in black and white, would I still have bought it? Yes, I would have.', 'Very nice Kindle with a great Battery life. My old kindle was not able to upgrade so I got the new Kindle and very pleased with the product. Arrived as promised from BESTBUY.COM.', \"I got oasis yesterday, very lighweight compared to voyager, screen size comparable, like having actual page turn button, touchscreen seems kinda slow, the on/off button on top is improvement from back of voyager. cover does seem kind of flimsy, but supposed to be leather so will see how it holds up. finding it easier to hold with cover on, then removed. cover doesn't have separate charge port, so all charging is done thru kindle.\", \"This is my 4th kindle and is easily the best one I've ever had. It is very comfortable to hold and is very compact. I was surprised how small it is but has the same screen size as my other kindles. It may look costly at first but remember you are getting a cover with additional battery.\", 'This is the best kindle ereader yet. The size and weight make it perfect for comfortable reading. You will find yourself reading more books than ever with it.', \"Small, light, but comfortable to hold with either hand. If you keep it in airplane mode with medium lighting, the battery last for weeks. Lovin' it so far.\", \"I have had every kindle since the first and this is by far the best. The screen was already great on the Voyage but the front light on this screen is more white and more evenly distributed. Physical page turn buttons are so much better than none or the haptic feedback type. They didn't include the automatically adaptive front light for some reason but I don't think I'll miss it much as I was always wont to fiddle with it on the Voyage anyway.But this device made me smile as soon as I held it for the first time because it has a larger bezel that you can really grip comfortably without touching the screen. Maybe this isn't a big deal for most, but that is exactly why I spent the money to get this device.The other thing I was hoping for was the ability to use the upper page turn button to go forward and this device does that and even better because it is software configurable.The cover is very small and light and doesn't add much bulk like the Voyage Origami case does. The only downside is that it doesn't work as a hands free stand for reading.(I still wish it was waterproof)\", 'I like this so much more than the Voyage. The shape makes for easier holding. I only wish this devise was maybe 2 inches taller then it would look like a real book', \"I purchased this as a gift for my wife and she loves it. She has an older Kindle, and she can't believe how much better the Oasis is.\", 'Very nice Kindle with a great Battery life. My old kindle was not able to upgrade so I got the new Kindle and very pleased with the product. Arrived as promised from BESTBUY.COM.', 'This is not an upgrade by any means! My three year old kindle outperformed Oasis.Battery life better than a week with the lights on lowest setting Magnetic connector is poorly designed and grows weak Two pieces to keep up with; unsnaps constantly Amazon Customer Services promises it will resolved in an update', 'Bought for my wife to upgrade from the original Kindle that she has worn out. Big step up from the original and should be good for another 8-10 years.', \"Replacing older reader without a light and traveling overseas soon. With electronics in the cabin under scrutiny, this very small and very lightweight reader fits the bill! Perfect in small purses and large pockets. I can read without annoying seatmate with cabin overhead seat light. Easy to hold in either hand and screen adjusts for whichever direction you're holding it.\", 'The new Kindle is a great gift and fantastic entertainment idea.', 'Bought for my wife to upgrade from the original Kindle that she has worn out. Big step up from the original and should be good for another 8-10 years.', 'Even when I‚Äôm outside in bright sunlight, the words of the book I‚Äôm reading are still crystal clear. That alone makes the Kindle Oasis worth what it cost me.The Kindle Oasis wakes up in just seconds, and any book I choose instantly opens, ready to be read.It is the perfect size and isn‚Äôt heavy or bulky. I really do read for hours at a time. Sometimes I pace the floor while I read. Sometimes I‚Äôm on my elliptical machine when I read. And sometimes I‚Äôm sitting down. No matter what I‚Äôm doing, the Kindle Oasis remains comfortable to hold, and it is always easy on my eyes.When I receive a book that is in PDF, most of the time I can enlarge the words. If it won‚Äôt allow me to enlarge the words, I can change the orientation of the page and the words are automatically larger. I am able to make notes on the book if needed, and I can highlight words and/or passages.My merlot leather cover is attractive. When I flip it open, it is just like opening the cover of a book.How to Make the Battery LastOn the Kindle Oasis page, it says that its ‚Äúdual-battery charging system delivers months of battery life.‚Äù This was a huge thing for me. Instead of having to charge my tablet almost every day, I would be able to read for months without charging the Kindle!Is this how my Oasis has performed? Well, not so much. There are conditions that have to be met for the charge on your Oasis to last for two months.First, you have to limit your reading to thirty minutes a day. That one is impossible for me. There are days that I am only able to read for thirty minutes, but they don‚Äôt occur very often. My Kindle goes everywhere with me, and I use just about every spare moment to read.Second, the wireless needs to be turned off. That one is easy to do but not always easy to remember. The only time the wireless needs to be on is to download one or more books.Third, this is based on your light setting at 10. That is way too low for me. I keep my light setting anywhere from 16 to 18.I don‚Äôt limit my reading to thirty minutes a day, and I try to remember to keep my wireless turned off. My light setting is kept anywhere from 16 to 18, and I put my Kindle to sleep the second I‚Äôm done reading. So how long does a single charge last me? Ten days is the longest a charge has lasted me so far, but it would have kept a charge for several more days if I had remembered to turn my wireless off. Once I succeed in keeping my wireless off, I will let you know how long the charge lasts.Now, I don‚Äôt plug it in to charge as soon as the charge on the cover gets low. I allow my cover charge to go as low as it will possibly go and then the Kindle battery will start to drain since it can no longer charge from the cover. I allow it to drain down to about 50% before I plug the cover and Kindle into my computer to charge.The one thing that surprised me was that everything on the Oasis is in black and white. For some reason, I thought that maybe the book covers would appear in color. But since I bought the Oasis to read books on, color isn‚Äôt needed.Special offers do appear on my screen but only when my Kindle is going to sleep or waking up. They aren‚Äôt a distraction, and to be honest, they are kind of fun to look at. You can pay a higher price so they won‚Äôt appear on your Kindle if you would rather not see them.I asked myself some questions once I had my Kindle and knew just how it worked. If I had known before I bought my Kindle Oasis that the charge wouldn‚Äôt last for months, would I still have bought it? Yes, I would have. If I had known that everything would appear in black and white, would I still have bought it? Yes, I would have.', \"This kindle is awesome. I love the design of it. Nothing software wise that was different than my other kindle but the way it's designed makes it much more comfortable and easier to read. The only reason I didn't give it five stars was because of the price. If it were cheaper, this kindle would have been five stars no doubt.\", 'Almost feels like reading a book in a light comforting way. Easy to carry around. Great on eyes and reading is enjoyable', \"I got oasis yesterday, very lighweight compared to voyager, screen size comparable, like having actual page turn button, touchscreen seems kinda slow, the on/off button on top is improvement from back of voyager. cover does seem kind of flimsy, but supposed to be leather so will see how it holds up. finding it easier to hold with cover on, then removed. cover doesn't have separate charge port, so all charging is done thru kindle.\", \"This kindle is awesome. I love the design of it. Nothing software wise that was different than my other kindle but the way it's designed makes it much more comfortable and easier to read. The only reason I didn't give it five stars was because of the price. If it were cheaper, this kindle would have been five stars no doubt.\", \"I have had every kindle since the first and this is by far the best. The screen was already great on the Voyage but the front light on this screen is more white and more evenly distributed. Physical page turn buttons are so much better than none or the haptic feedback type. They didn't include the automatically adaptive front light for some reason but I don't think I'll miss it much as I was always wont to fiddle with it on the Voyage anyway.But this device made me smile as soon as I held it for the first time because it has a larger bezel that you can really grip comfortably without touching the screen. Maybe this isn't a big deal for most, but that is exactly why I spent the money to get this device.The other thing I was hoping for was the ability to use the upper page turn button to go forward and this device does that and even better because it is software configurable.The cover is very small and light and doesn't add much bulk like the Voyage Origami case does. The only downside is that it doesn't work as a hands free stand for reading.(I still wish it was waterproof)\", \"When they first announced the Kindle Oasis, I did not have much of a desire to upgrade from my 1st generation Kindle Paperwhite. Just as I felt when they announced the Voyage.I read a lot, so my Kindle travels with me throughout the day most of the time. I have never had an issue with battery life, I have only had it get really low a few times (typically when I was traveling). So again, I originally did not see a lot of the value to the Oasis.As the reviews for the Oasis came out, I started to realize what I did not like about my Paperwhite, and I began to have an interest in upgrading my Paperwhite to the either the Oasis or possibly the Voyage. The main thing I noticed is that I took my Paperwhite out of the Amazon case quite a lot, especially when I was in a seated position. This slight reduction in weight made it much more comfortable to hold for longer reading sessions. I had some other minor issues with my Paperwhite, like when reading in the dark, I couldn't find an adjustment for the light that I preferred (5 was a little too dim and 6 was a brighter than I needed). I decided to pass on the Voyage because I really did not like the case options and the pressure sensitive page turn option.Now that I have the Oasis, I definitely think it was worth it for me. I really appreciate the reduced weight when the cover is off (not to mention the ease of removing the cover compared to the Paperwhite). It provides the same reading experience, although I did get a resolution upgrade compared to my older Paperwhite, which is a plus.The Oasis is really comfortable in my hand, which helps me forget that it is there. When I was holding my Paperwhite with my left hand, at times I would accidentally go back a page, which drove me crazy even though its just a minor inconvenience.I have the black model because it was the only option available unless I was willing to wait a few more months. The build quality of the Oasis and its case is very nice, just like with the Paperwhite and the amazon leather case for it. The only concern I have is how well it will protect the Kindle. I will update the review if I find this to be a problem.I loved my Paperwhite, and I will recommend it to anyone looking to upgrade from an older Kindle or buying one for the first time. It definitely is great and the better buy, but I am glad I decided to order the Oasis. The reduced weight, ergonomic design, and page turn buttons make it worth the added cost.\", \"I have had every kindle since the first and this is by far the best. The screen was already great on the Voyage but the front light on this screen is more white and more evenly distributed. Physical page turn buttons are so much better than none or the haptic feedback type. They didn't include the automatically adaptive front light for some reason but I don't think I'll miss it much as I was always wont to fiddle with it on the Voyage anyway.But this device made me smile as soon as I held it for the first time because it has a larger bezel that you can really grip comfortably without touching the screen. Maybe this isn't a big deal for most, but that is exactly why I spent the money to get this device.The other thing I was hoping for was the ability to use the upper page turn button to go forward and this device does that and even better because it is software configurable.The cover is very small and light and doesn't add much bulk like the Voyage Origami case does. The only downside is that it doesn't work as a hands free stand for reading.(I still wish it was waterproof)\", \"Got me reading again! Love the merlot cover. This one is the smallest of all the kindle products I believe, and that's a big reason I picked. Also the lightest I believe. Battery life is forever.Two negative points are the Amazon logo in the cover, and the fact you can't do inverted text (black background white text).Those 2 points dropped it from 4 to 5 star for me.Still highly recommended.\")\n",
            "(\"We finally decided to try the Echo system, after months and months of debate. We purchased the Echo Plus & an Echo Dot. The Plus easily handles our main two floors and the Dot handles our upstairs. The Plus's speakers are incredible for its size. We both agree we made the right choice to get the Plus.\", 'The echo show works very well with Bluetooth and WiFi. Great sound and screen. Recommend to anyone', \"This kindle is awesome. I love the design of it. Nothing software wise that was different than my other kindle but the way it's designed makes it much more comfortable and easier to read. The only reason I didn't give it five stars was because of the price. If it were cheaper, this kindle would have been five stars no doubt.\", \"I got oasis yesterday, very lighweight compared to voyager, screen size comparable, like having actual page turn button, touchscreen seems kinda slow, the on/off button on top is improvement from back of voyager. cover does seem kind of flimsy, but supposed to be leather so will see how it holds up. finding it easier to hold with cover on, then removed. cover doesn't have separate charge port, so all charging is done thru kindle.\", 'Fantastic sound from such a small speaker, excellent! Not as impressed with its other potential capabilities- more difficult to set those up & get all the various apps needed to do things like get weather, order items, etc.. Wish it came with more pre installed I guess.', 'The show has some nice features but the audio quality isn‚Äôt the best for the price point. I got mine on sale and am just using it for a bedroom alarm clock. I can read the time without my glasses.I still use my Sonos Play 1 to listen to my sleep playlist and ny other music. Unless I missed something it seems like if I set the volume low at night to listen to music to go to sleep my alarm will not be loud enough. So I don‚Äôt use the Show for music much.', 'Bought for my wife to upgrade from the original Kindle that she has worn out. Big step up from the original and should be good for another 8-10 years.', 'Best Buy associate explained product very well. Easy to use', 'I have several home automation devices and the Echo Plus controls all of them. I was so happy with automation, I bought an Echo Dot and Echo Tap.', 'Very neat item, fun to talk to. Easy set up to use.', 'I was surprised on how easy it was to use. I bought it for my mother and she totally loves it, and I do too!', 'Blue is beautiful & allows grand-daughter to be able to tell which one is hers. Loves the piano program and challenging herself to play as much of the song as she can. Nice size for traveling with.', 'I have this model Kindle and purchased another for a gift.He is not very savy but Kindle makes it sooo easy, he is happy.Such an easy tablet!', 'Love the echo show & the ability to communicate with smaller children without any effort or cell phones.', 'The new design, compared to my old kindle paperwhite and voyage, looked weird when I first got my Kindle Oasis. After I used it for a while (5 hours), I felt the design was kind of make sense. When I hold it with one hand (right hand), the centre of gravity position was right in my hand, so there was less change that I drop the kindle on my face(when I was laying on my bed, it happened a lot with my kindle voyage)', 'I bought this second Kindle for the larger storage space and love all the extra stuff I can do now.', 'Thoughts of being able to have the Echo \"grow\" as I added to the list of tasks, excited me. Including the latest app, having it to recognize my smartphone\\'s contact list to place and to receive calls. However, the Echo I purchased does not link up to my Samsung smartphone. Disappointed is a understatement.', \"Got me reading again! Love the merlot cover. This one is the smallest of all the kindle products I believe, and that's a big reason I picked. Also the lightest I believe. Battery life is forever.Two negative points are the Amazon logo in the cover, and the fact you can't do inverted text (black background white text).Those 2 points dropped it from 4 to 5 star for me.Still highly recommended.\", \"I had an older version of a Kindle e-reader that allowed me to download books on the go, but I felt like something was missing. Several upgrades later, I got this for a gift, and I think it basically includes everything that was missing. It is so lightweight and compact that I can easily slip it into my purse or use it with one hand. It has backlighting that doesn't disturb my sleeping husband or create a light so bright that it is distracting- it's just the right amount of light needed to read in different ligths. It can self-adjust from reading in a dark room to reading outside on a bright day.\", 'I like this so much more than the Voyage. The shape makes for easier holding. I only wish this devise was maybe 2 inches taller then it would look like a real book', 'Excellent value for my 3 yr old, everything you need plus HD and the wife can order off amazon prime, so happy wife and kid for the price cant beat it, 2nd one I have owned....', 'I like the looks of the Echo Plus and the sound from the speakers is something I didn‚Äôt expect to be as nice as it is. I‚Äôm using it to tune into my favorite radio station, answer any question I have to look up on the internet and assist me with lighting. I am considering another for a different room.', 'Does the trick. This is a good tablet for the price.', 'WORTH IT I LOVED WELL INVESTED MONEY. ALEXA HELPING ME A LOT, REMINDERS, LISTEN TO MUSIC AND MAKING MY HOUSE SMARTER, SIMPLY AND EASY, NO REGRETS:-)', 'Easy to handle. Light weight. I like that it automatically shuts off when the cover is closed.', 'Love the bigger screen but do think this Fire HD 10TH runs a little slow. My last Fire HD was not as slow.', 'Great sound and amazing options. Love this!!! Great replacement for original echo', 'My son loves it. He now wants to add more for Alexa to use.', 'I purchased this product because I love to read and buying books got costly. With this product I can read all I want for 10.00 a month', 'Wife love it, reads a lot and this is her go to reader.', 'I have used Kindle e-readers since Amazon introduced them years ago. All are good products and each new model has been a worthwhile upgrade. The Oasis is no exception, even from the highly touted Voyage model. It is expensive but the lightweight design, improved backlighting and battery cover are worth the additional expense for someone who reads frequently. This is definitely a good investment!', 'This product is great. I wish there was a way to play music from my phone other than Bluetooth only.', 'My wife said I‚Äôm developing a ‚ÄúStar Trek‚Äù home...while I‚Äôm still learning what all I can do with this over the regular Echo, I am looking forward to getting my Ring Doorbell installed! Great product, I can rave enough about them!!!', 'Such a great product. I like that it is very small and fit in my purse. I like that the battery last for a very long time.', \"I was hesitant on purchasing this new echo but I'm glad I did. I really like having the feedback on the screen and seeing results in addition to the voice. Using it for weather, recipes and anything that can be displayed is a big help. The echo show responds fairly fast and looks great in my kitchen counter. A definite winner on this one.\", 'Echo plus seems to work as they say. I have it running two lights so far. Plan on setting up seven more. Nice product.', 'I like the contrast it is easy to read on outside.', 'Purchased this for my mother for her birthday. She loves it. The large screen is what she wanted most.', 'Alexa show is ok same technology as a tablet except voice activated', \"love all the fun things you can do with Alexa. And she's learning more everyday!\", \"Got me reading again! Love the merlot cover. This one is the smallest of all the kindle products I believe, and that's a big reason I picked. Also the lightest I believe. Battery life is forever.Two negative points are the Amazon logo in the cover, and the fact you can't do inverted text (black background white text).Those 2 points dropped it from 4 to 5 star for me.Still highly recommended.\", 'I wondered about buying one before making the decision - now even after just a few weeks I wonder how I managed. It has some gimmicky things yes but also can help out with a lot of very useful ideas such as weather, traffic and lists. Would recommend one to anyone', 'Love my kindle ! I enjoy reading everyday and I can easily throw in my bag with out it adding any weight .', 'The new Kindle is a great gift and fantastic entertainment idea.', 'I have used Kindle e-readers since Amazon introduced them years ago. All are good products and each new model has been a worthwhile upgrade. The Oasis is no exception, even from the highly touted Voyage model. It is expensive but the lightweight design, improved backlighting and battery cover are worth the additional expense for someone who reads frequently. This is definitely a good investment!', 'This is the best kindle ereader yet. The size and weight make it perfect for comfortable reading. You will find yourself reading more books than ever with it.', \"This is my third Kindle. The best differentiator is the form factor. Definite improvement over the paperwhite. Also like having the page-turn buttons back. Case is very cool indeed. If you can get past the jump in price (remember you're not having to buy the case separately), it's a quality product to have.\", \"When they first announced the Kindle Oasis, I did not have much of a desire to upgrade from my 1st generation Kindle Paperwhite. Just as I felt when they announced the Voyage.I read a lot, so my Kindle travels with me throughout the day most of the time. I have never had an issue with battery life, I have only had it get really low a few times (typically when I was traveling). So again, I originally did not see a lot of the value to the Oasis.As the reviews for the Oasis came out, I started to realize what I did not like about my Paperwhite, and I began to have an interest in upgrading my Paperwhite to the either the Oasis or possibly the Voyage. The main thing I noticed is that I took my Paperwhite out of the Amazon case quite a lot, especially when I was in a seated position. This slight reduction in weight made it much more comfortable to hold for longer reading sessions. I had some other minor issues with my Paperwhite, like when reading in the dark, I couldn't find an adjustment for the light that I preferred (5 was a little too dim and 6 was a brighter than I needed). I decided to pass on the Voyage because I really did not like the case options and the pressure sensitive page turn option.Now that I have the Oasis, I definitely think it was worth it for me. I really appreciate the reduced weight when the cover is off (not to mention the ease of removing the cover compared to the Paperwhite). It provides the same reading experience, although I did get a resolution upgrade compared to my older Paperwhite, which is a plus.The Oasis is really comfortable in my hand, which helps me forget that it is there. When I was holding my Paperwhite with my left hand, at times I would accidentally go back a page, which drove me crazy even though its just a minor inconvenience.I have the black model because it was the only option available unless I was willing to wait a few more months. The build quality of the Oasis and its case is very nice, just like with the Paperwhite and the amazon leather case for it. The only concern I have is how well it will protect the Kindle. I will update the review if I find this to be a problem.I loved my Paperwhite, and I will recommend it to anyone looking to upgrade from an older Kindle or buying one for the first time. It definitely is great and the better buy, but I am glad I decided to order the Oasis. The reduced weight, ergonomic design, and page turn buttons make it worth the added cost.\", 'I bought this for our kitchen where we enjoy cooking and congregating. Streaming music is great and you can search for recipes just by asking Alexa.', 'Amazon has made another great product! The ‚Äúshow‚Äù goes perfectly in the kitchen! Recipes, music,weather! All done hands free!! Fast set up!', \"I was initially going to just get the Amazon Kindle but I thought this gives me a tablet and a easy way to read books. I buy e-college texts. It has helped me so much!! I'm so happy I invested my money in this.\", 'My kid love this tablet!! The setup was so easy, and the amazon store has a bunch of educational apps! That my kid can enjoy playing and learning!!', \"I bought it for my 2 year old and he loves it. It's easy to use and the perfect size for his hands.\", 'Great hardware for the price, similar to the ipads', 'The kids love it. They ask it silly questions which to my amazement it has an answer. I really like for the music aspect. Just tell it a song and it finds it', \"I love my new Kindle. The size is perfect. It fits right in my purse. Easy to navigate and I love the touch screen. I am able to read outside without a glare. Only flaw is that it is not backlit, so in order to read in the dark I need a book light. I don't mind that so much, I just wish kindle would come out with a case for this Kindle with a built in book light like they did for the first generation Kindle.\", 'Not the fanciest tablet, but it definitely gets the job done! Bought as a gift for a friend that wanted an e-reader and he loves it!', \"In my opinion it's very slow for internet use. Good for our 5 yr old to use but we purchased this for her to do online curriculums, which is almost impossible to do with this tablet because of the speed. Our internet connection is great with every other laptop and computer in the house.\", \"This is really good if you read a lot, doesn't strain your eyes and very light weight. Only demerit is - cant use in night if there is not enough light.\", 'Family is using and loving the Tap more every day. Great to find out quick information like weather, general questions and sports scores. The battery life is awesome only having to charge it every two-three days depending on usage and we use it. Excellent wifi connectivity and seamless Bluetooth connection. Use it all over the house.', \"Small, light, but comfortable to hold with either hand. If you keep it in airplane mode with medium lighting, the battery last for weeks. Lovin' it so far.\", 'My fianc√©e really enjoyes it! I would definitely recommend.', \"I'm an avid reader. The Kindle is my go to for ease. It fits in my purse or knitting bag and stays charged for days.\", 'I purchased this Kindle for my daughter and she really enjoys using it !!', 'Purchased this for a gift for my mother who is a amazon fanatic she loves it ! Made her christmas this year', 'Love the tablet, not only for reading (upgrade from Kindle) but for searching the Internet, email, etc. And I can take it anywhere. Cheaper than an iPAD and does enough for what I need.', 'Easy to handle. Light weight. I like that it automatically shuts off when the cover is closed.', 'Both my 2 year old and my 4 year old love this tablet!', \"Very easy to use and does everything I need it to do. Would have given it 5 stars but it hasn't changed enough from the last Kindle that I purchased several years ago.\", 'This is the best kindle ereader yet. The size and weight make it perfect for comfortable reading. You will find yourself reading more books than ever with it.', 'The new design, compared to my old kindle paperwhite and voyage, looked weird when I first got my Kindle Oasis. After I used it for a while (5 hours), I felt the design was kind of make sense. When I hold it with one hand (right hand), the centre of gravity position was right in my hand, so there was less change that I drop the kindle on my face(when I was laying on my bed, it happened a lot with my kindle voyage)', \"OK, I was so unsure of this Kindle because it does not have all of the bells and whistles of the others. BUT I am very happy with it. I love my Kindle! I have managed to read a book a week on it sicnce I got if for Christmas. I have been reading the free books on Kindle. There are so many to pick from. While home, I download the books that I want to read and then while I am in the car or waiting at the DMV, I just pull of the book and read. It remembers where I am in the book. This Kindle does not have the back light. I was nervous about that but so far this has not been a problem because the light it has is fine for me. When I am reading in the car, I enlarge the font and it makes seeing the words easier for me. That is the most important factor for me because I can get car sick if I read while riding in the car but with the larger font I don't have that problem. I wear glasses with bifocals and holding this seems to be more comfortable than a book because I can hold it up if I need to. The size is perfect! Again, I can enlarge the font so the smaller screen size really has nothing to do with the readability. Love it!!\", 'This e-reader meets all expectations and has a good feel to it.', \"Easy to navigate. Daughter loves it. It's lightweigh and its just what she needed for this avid reader.\", 'Bought for my wife to upgrade from the original Kindle that she has worn out. Big step up from the original and should be good for another 8-10 years.', 'I love the Echo Show and this is the 3rd one I have purchased (two were presents for family at Christmas). This one was for me. I love being able to hear music, connect with family via video and ask Alexa questions. Best purchase I could have made!', 'The Echo and the plus are great for people not wanting to run wires. And the waterpik was all we wanted', 'Fought it for a long time, but Kindle is awesome. The newer version with adjustable light is best for me.', 'Got it when it was on sale. Totally fall in love with it. Bring with it me everywhere.', \"The Echo Plus was demonstrated for us at Best Buy. We were a bit skeptical but bought to check it out. Wow! are we impressed! We tell it to turn on and turn off our lights in the living room, family room, and bedroom. Also it can dim the lights more than once. Need the local weather forecast, just ask. Want to listen to Christmas music? Yes, again. Want to know the distance to someplace or the population of some city or country, yes! We're still discovering what it can do and it seems limitless. Absolutely love this!!\", 'I bought this for my niece and she loves it. We take it everywhere.', 'The speaker is loud enough to cover my room but I still connect external speakers. The hub portion of the device works well, although I wish it had more capabilities when it comes to controlling hue lighting.', \"The Amazon fire HD10 is one of the best deals on the market. I've had a IPad and would rather have the HD10! It's what-1/3 of the price of a IPad and just as good, if not better\", 'asesome!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', 'great for the elderly, makes life a lot easier for everyone', 'I use this every day on my commute. Great battery life, no backlight but very readable with normal lighting. I like the built in dictionary. Email yourself pdf or mobi files for easy transfers.', 'I have several Kindles so knew what to expect. It is a great reading device and I keep several in different locations.', 'Better and faster than Kindle 7\". Great performance for the price.', 'Good e-reader, with an improved design, light-weight', 'i purchased this to go along with my smart lights. it links up right away. i am satasified with this purchase.', 'It is goodagood and accurate..it is very convienient.', 'Bought this for my cousins and he absolutely loves it.', 'I am very satisfied with my purchase my girlfriend is very happy', 'It is a great buy. The sound is great quality. Deliveres what I need for a comfortable house', \"Easy to navigate. Daughter loves it. It's lightweigh and its just what she needed for this avid reader.\", 'Love my new kindle, thought the screen would be too large but after using it a few days, all is good. Very thin , got a case for it, I now feel at home with it. Do not like the \"new\" lock screen lock to open the tablet at all, its tiny and hard to \"unlock\" most always taking several times to swipe it just right.', 'Enjoying using Alexa.... and love the smart home features.', 'The item is a great tablet for basic uses such as email, youtube, and facebook.', 'I love my Amazon Fire tablet it does exactly what I needed to do.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe0DulhxG_kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJKJcWNgHArF",
        "colab_type": "text"
      },
      "source": [
        "## This is the definition of the Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-xIsmzV7Tfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class OnlineTripletLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Online Triplets loss\n",
        "    Takes a batch of embeddings and corresponding labels.\n",
        "    Triplets are generated using triplet_selector object that take embeddings and targets and return indices of\n",
        "    triplets\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin, triplet_selector):\n",
        "        super(OnlineTripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.triplet_selector = triplet_selector\n",
        "\n",
        "    def forward(self, embeddings, target):\n",
        "\n",
        "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
        "\n",
        "        if embeddings.is_cuda:\n",
        "            triplets = triplets.cuda()\n",
        "\n",
        "        ap_distances = (embeddings[triplets[:, 0]] - embeddings[triplets[:, 1]]).pow(2).sum(1)  # .pow(.5)\n",
        "        an_distances = (embeddings[triplets[:, 0]] - embeddings[triplets[:, 2]]).pow(2).sum(1)  # .pow(.5)\n",
        "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
        "\n",
        "        return losses.mean(), len(triplets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR61vY4tM-SW",
        "colab_type": "text"
      },
      "source": [
        "## modified Siamese Network to be called Triplet Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbJFhGMaM-A3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class TripletNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self,  encoder,fc_dim, num_classes=2): # binary classification so 0/1 shall work\n",
        "      \n",
        "        super(TripletNetwork, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.input_dim = 2  * self.encoder.hidden_size # since we concatinate the two sentences together\n",
        "        self.num_classes = num_classes\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, int(self.input_dim/2)),\n",
        "            nn.Linear(int(self.input_dim/2), self.num_classes)\n",
        "        )\n",
        "       \n",
        "    def forward(self, x1, x2, x3):\n",
        "        encoding_1 = self.encoder.encode_sentences(sentences = x1)\n",
        "        encoding_2 = self.encoder.encode_sentences(sentences = x2)\n",
        "        encoding_3 = self.encoder.encode_sentences(sentences = x3)\n",
        "        print(encoding_1.shape)\n",
        "        \n",
        "        # Major changes needed here\n",
        "        # Earlier we used to convert this section into a concatinated vector and then use it\n",
        "        # We need to understand how that would affect our model at this point of time\n",
        "        output1 = self.classifier(torch.from_numpy(encoding_1).cuda())\n",
        "        output2 = self.classifier(torch.from_numpy(encoding_2).cuda())\n",
        "        output3 = self.classifier(torch.from_numpy(encoding_3).cuda())\n",
        "        \n",
        "        return output1, output2, output3\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.encoder.encode_sentences(sentences = x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlDNl66-7Ueo",
        "colab_type": "text"
      },
      "source": [
        "## This is the Triplet Selection code that is being used in this place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzTqQdqS7T2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pdist(vectors):\n",
        "  \"\"\"\n",
        "    This is the basic definition of the distance matrix from a vector\n",
        "  \"\"\"\n",
        "  distance_matrix = -2 * vectors.mm(torch.t(vectors)) + vectors.pow(2).sum(dim=1).view(1, -1) + vectors.pow(2).sum(\n",
        "      dim=1).view(-1, 1)\n",
        "  return distance_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Odz1NjZ4LN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations\n",
        "class FunctionNegativeTripletSelector():\n",
        "    \"\"\"\n",
        "    For each positive pair, takes the hardest negative sample (with the greatest triplet loss value) to create a triplet\n",
        "    Margin should match the margin used in triplet loss.\n",
        "    negative_selection_fn should take array of loss_values for a given anchor-positive pair and all negative samples\n",
        "    and return a negative index for that pair\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin, negative_selection_fn, cpu=True):\n",
        "        super(FunctionNegativeTripletSelector, self).__init__()\n",
        "        self.cpu = cpu\n",
        "        self.margin = margin\n",
        "        self.negative_selection_fn = negative_selection_fn\n",
        "\n",
        "    def get_triplets(self, embeddings, labels):\n",
        "        if self.cpu:\n",
        "            embeddings = embeddings.cpu()\n",
        "        distance_matrix = pdist(embeddings)\n",
        "        distance_matrix = distance_matrix.cpu()\n",
        "\n",
        "        labels = labels.cpu().data.numpy()\n",
        "        triplets = []\n",
        "\n",
        "        for label in set(labels):\n",
        "            label_mask = (labels == label)\n",
        "            label_indices = np.where(label_mask)[0]\n",
        "            if len(label_indices) < 2:\n",
        "                continue\n",
        "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
        "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
        "            anchor_positives = np.array(anchor_positives)\n",
        "\n",
        "            ap_distances = distance_matrix[anchor_positives[:, 0], anchor_positives[:, 1]]\n",
        "            for anchor_positive, ap_distance in zip(anchor_positives, ap_distances):\n",
        "                loss_values = ap_distance - distance_matrix[torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
        "                loss_values = loss_values.data.cpu().numpy()\n",
        "                hard_negative = self.negative_selection_fn(loss_values)\n",
        "                if hard_negative is not None:\n",
        "                    hard_negative = negative_indices[hard_negative]\n",
        "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative])\n",
        "\n",
        "        if len(triplets) == 0:\n",
        "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
        "\n",
        "        triplets = np.array(triplets)\n",
        "\n",
        "        return torch.LongTensor(triplets)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX7FRICw7HYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hardest_negative(loss_values):\n",
        "    hard_negative = np.argmax(loss_values)\n",
        "    return hard_negative if loss_values[hard_negative] > 0 else None\n",
        "\n",
        "\n",
        "def random_hard_negative(loss_values):\n",
        "    hard_negatives = np.where(loss_values > 0)[0]\n",
        "    return np.random.choice(hard_negatives) if len(hard_negatives) > 0 else None\n",
        "\n",
        "\n",
        "def semihard_negative(loss_values, margin):\n",
        "    semihard_negatives = np.where(np.logical_and(loss_values < margin, loss_values > 0))[0]\n",
        "    return np.random.choice(semihard_negatives) if len(semihard_negatives) > 0 else None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB-fLNLG6i_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def HardestNegativeTripletSelector(margin, cpu=False):\n",
        "  return FunctionNegativeTripletSelector(margin=margin,negative_selection_fn=hardest_negative, cpu=cpu)\n",
        "\n",
        "\n",
        "def RandomNegativeTripletSelector(margin, cpu=False): \n",
        "  return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=random_hard_negative, cpu=cpu)\n",
        "\n",
        "\n",
        "def SemihardNegativeTripletSelector(margin, cpu=False): \n",
        "  return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=lambda x: semihard_negative(x, margin), cpu=cpu)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY-eNwlA81qU",
        "colab_type": "text"
      },
      "source": [
        "### Final Train Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqSjqqbd_5bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdgDrJGr6i8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "margin = 1.\n",
        "model = TripletNetwork(encoder=sentence_encoder, fc_dim=100)\n",
        "model.cuda()\n",
        "loss_fn = OnlineTripletLoss(margin, RandomNegativeTripletSelector(margin))\n",
        "lr = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
        "n_epochs = 20\n",
        "log_interval = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-lYpXS_8UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_epoch(val_loader, model, loss_fn, cuda, metrics):\n",
        "    with torch.no_grad():\n",
        "        for metric in metrics:\n",
        "            metric.reset()\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(val_loader):\n",
        "            target = target if len(target) > 0 else None\n",
        "            if not type(data) in (tuple, list):\n",
        "                data = (data,)\n",
        "            if cuda:\n",
        "                data = tuple(d.cuda() for d in data)\n",
        "                if target is not None:\n",
        "                    target = target.cuda()\n",
        "\n",
        "            outputs = model(*data)\n",
        "\n",
        "            if type(outputs) not in (tuple, list):\n",
        "                outputs = (outputs,)\n",
        "            loss_inputs = outputs\n",
        "            if target is not None:\n",
        "                target = (target,)\n",
        "                loss_inputs += target\n",
        "\n",
        "            loss_outputs = loss_fn(*loss_inputs)\n",
        "            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            for metric in metrics:\n",
        "                metric(outputs, target, loss_outputs)\n",
        "\n",
        "    return val_loss, metrics\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTxnqAvN_5Ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics):\n",
        "    for metric in metrics:\n",
        "        metric.reset()\n",
        "\n",
        "    model.train()\n",
        "    losses = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (img1,img2,img3) in enumerate(train_loader):\n",
        "#         target = target if len(target) > 0 else None\n",
        "#         if not type(data) in (tuple, list):\n",
        "#             data = (data,)\n",
        "#         if cuda:\n",
        "#             data = tuple(d.cuda() for d in data)\n",
        "#             if target is not None:\n",
        "#                 target = target.cuda()\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(img1,img2,img3)\n",
        "        print(type(outputs))\n",
        "        if type(outputs) not in (tuple, list):\n",
        "            outputs = (outputs,)\n",
        "\n",
        "        loss_inputs = outputs\n",
        "#         if target is not None:\n",
        "#             target = (target,)\n",
        "#             loss_inputs += target\n",
        "\n",
        "        loss_outputs = loss_fn(*loss_inputs)\n",
        "        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
        "        losses.append(loss.item())\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        for metric in metrics:\n",
        "            metric(outputs, None, loss_outputs) #Using default value for the time being\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            message = 'Train: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                batch_idx * len(data[0]), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), np.mean(losses))\n",
        "            for metric in metrics:\n",
        "                message += '\\t{}: {}'.format(metric.name(), metric.value())\n",
        "\n",
        "            print(message)\n",
        "            losses = []\n",
        "\n",
        "    total_loss /= (batch_idx + 1)\n",
        "    return total_loss, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BX4rsUm8053",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[],\n",
        "        start_epoch=0):\n",
        "    \"\"\"\n",
        "    Loaders, model, loss function and metrics should work together for a given task,\n",
        "    i.e. The model should be able to process data output of loaders,\n",
        "    loss function should process target output of loaders and outputs from the model\n",
        "\n",
        "    Examples: Classification: batch loader, classification model, NLL loss, accuracy metric\n",
        "    Siamese network: Siamese loader, siamese model, contrastive loss\n",
        "    Online triplet learning: batch loader, embedding model, online triplet loss\n",
        "    \"\"\"\n",
        "    for epoch in range(0, start_epoch):\n",
        "        scheduler.step()\n",
        "\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        scheduler.step()\n",
        "\n",
        "        # Train stage\n",
        "        train_loss, metrics = train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics)\n",
        "\n",
        "        message = 'Epoch: {}/{}. Train set: Average loss: {:.4f}'.format(epoch + 1, n_epochs, train_loss)\n",
        "        for metric in metrics:\n",
        "            message += '\\t{}: {}'.format(metric.name(), metric.value())\n",
        "\n",
        "          #TODO: As POC commenting out a few things. Please check later  \n",
        "#         val_loss, metrics = test_epoch(val_loader, model, loss_fn, cuda, metrics)\n",
        "#         val_loss /= len(val_loader)\n",
        "\n",
        " #       message += '\\nEpoch: {}/{}. Validation set: Average loss: {:.4f}'.format(epoch + 1, n_epochs,\n",
        " #                                                                                val_loss)\n",
        "        for metric in metrics:\n",
        "            message += '\\t{}: {}'.format(metric.name(), metric.value())\n",
        "\n",
        "        print(message)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRy2uSArJFhQ",
        "colab_type": "text"
      },
      "source": [
        "## Metric that has been used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcGNmpTjJFE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageNonzeroTripletsMetric():\n",
        "    '''\n",
        "    Counts average number of nonzero triplets found in minibatches\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.values = []\n",
        "\n",
        "    def __call__(self, outputs, target, loss):\n",
        "        self.values.append(loss[1])\n",
        "        return self.value()\n",
        "\n",
        "    def reset(self):\n",
        "        self.values = []\n",
        "\n",
        "    def value(self):\n",
        "        return np.mean(self.values)\n",
        "\n",
        "    def name(self):\n",
        "        return 'Average nonzero triplets'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S01rUUY8802M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "2404ca00-fa4f-4a52-e85f-88425edffe95"
      },
      "source": [
        " \"\"\"online_test_loader\"\"\"\n",
        "val_loader=None\n",
        "cuda = True\n",
        "fit(online_train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda,log_interval, metrics=[AverageNonzeroTripletsMetric()])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(99, 1024)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-b71f69e19376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monline_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAverageNonzeroTripletsMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-90-f89e7c7d6bed>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics, start_epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Train stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epoch: {}/{}. Train set: Average loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-09847c3cbb90>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-1f93509a52db>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, x3)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mencoding_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [99 x 1024], m2: [2048 x 1024] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:268"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egKhffCwJLPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe754761-ac45-479b-f806-4fb6aad7fbf9"
      },
      "source": [
        "\n",
        "sentences = [\"jibber jagber either thither whither whither\", \"jibber jagber either thither\"]\n",
        "print(sentence_encoder.encode_sentences(sentences=sentences[0]).shape)\n",
        "print(sentence_encoder.encode_sentences(sentences=sentences[1]).shape)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(44, 1024)\n",
            "(28, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}